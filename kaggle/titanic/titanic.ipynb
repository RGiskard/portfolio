{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuraciones iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "options(scipen = 999, repr.plot.width=4, repr.plot.height= 4, warn = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instalación y carga de paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list.of.packages <- c('ggplot2', 'VIM', 'mice', 'mlbench', 'caret', 'caretEnsemble', 'gbm', 'ipred', 'FSelector',\n",
    "                     'Matrix')\n",
    "\n",
    "new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\n",
    "if(length(new.packages)) install.packages(new.packages, repos = \"https://cran.r-project.org\")\n",
    "\n",
    "library(ggplot2)\n",
    "library(VIM)\n",
    "library(mice)\n",
    "library(mlbench)\n",
    "library(caret)\n",
    "library(caretEnsemble)\n",
    "library(gbm)\n",
    "library(ipred)\n",
    "library(FSelector)\n",
    "library(Matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprensión de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una primera instancia debemos cargar y explorar los datos para entender el contexto en donde nos encontramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>PassengerId</th><th scope=col>Survived</th><th scope=col>Pclass</th><th scope=col>Name</th><th scope=col>Sex</th><th scope=col>Age</th><th scope=col>SibSp</th><th scope=col>Parch</th><th scope=col>Ticket</th><th scope=col>Fare</th><th scope=col>Cabin</th><th scope=col>Embarked</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1                                                  </td><td>0                                                  </td><td>3                                                  </td><td>Braund, Mr. Owen Harris                            </td><td>male                                               </td><td>22                                                 </td><td>1                                                  </td><td>0                                                  </td><td>A/5 21171                                          </td><td> 7.2500                                            </td><td>                                                   </td><td>S                                                  </td></tr>\n",
       "\t<tr><td>2                                                  </td><td>1                                                  </td><td>1                                                  </td><td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td><td>female                                             </td><td>38                                                 </td><td>1                                                  </td><td>0                                                  </td><td>PC 17599                                           </td><td>71.2833                                            </td><td>C85                                                </td><td>C                                                  </td></tr>\n",
       "\t<tr><td>3                                                  </td><td>1                                                  </td><td>3                                                  </td><td>Heikkinen, Miss. Laina                             </td><td>female                                             </td><td>26                                                 </td><td>0                                                  </td><td>0                                                  </td><td>STON/O2. 3101282                                   </td><td> 7.9250                                            </td><td>                                                   </td><td>S                                                  </td></tr>\n",
       "\t<tr><td>4                                                  </td><td>1                                                  </td><td>1                                                  </td><td>Futrelle, Mrs. Jacques Heath (Lily May Peel)       </td><td>female                                             </td><td>35                                                 </td><td>1                                                  </td><td>0                                                  </td><td>113803                                             </td><td>53.1000                                            </td><td>C123                                               </td><td>S                                                  </td></tr>\n",
       "\t<tr><td>5                                                  </td><td>0                                                  </td><td>3                                                  </td><td>Allen, Mr. William Henry                           </td><td>male                                               </td><td>35                                                 </td><td>0                                                  </td><td>0                                                  </td><td>373450                                             </td><td> 8.0500                                            </td><td>                                                   </td><td>S                                                  </td></tr>\n",
       "\t<tr><td>6                                                  </td><td>0                                                  </td><td>3                                                  </td><td>Moran, Mr. James                                   </td><td>male                                               </td><td>NA                                                 </td><td>0                                                  </td><td>0                                                  </td><td>330877                                             </td><td> 8.4583                                            </td><td>                                                   </td><td>Q                                                  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       " PassengerId & Survived & Pclass & Name & Sex & Age & SibSp & Parch & Ticket & Fare & Cabin & Embarked\\\\\n",
       "\\hline\n",
       "\t 1                                                   & 0                                                   & 3                                                   & Braund, Mr. Owen Harris                             & male                                                & 22                                                  & 1                                                   & 0                                                   & A/5 21171                                           &  7.2500                                             &                                                     & S                                                  \\\\\n",
       "\t 2                                                   & 1                                                   & 1                                                   & Cumings, Mrs. John Bradley (Florence Briggs Thayer) & female                                              & 38                                                  & 1                                                   & 0                                                   & PC 17599                                            & 71.2833                                             & C85                                                 & C                                                  \\\\\n",
       "\t 3                                                   & 1                                                   & 3                                                   & Heikkinen, Miss. Laina                              & female                                              & 26                                                  & 0                                                   & 0                                                   & STON/O2. 3101282                                    &  7.9250                                             &                                                     & S                                                  \\\\\n",
       "\t 4                                                   & 1                                                   & 1                                                   & Futrelle, Mrs. Jacques Heath (Lily May Peel)        & female                                              & 35                                                  & 1                                                   & 0                                                   & 113803                                              & 53.1000                                             & C123                                                & S                                                  \\\\\n",
       "\t 5                                                   & 0                                                   & 3                                                   & Allen, Mr. William Henry                            & male                                                & 35                                                  & 0                                                   & 0                                                   & 373450                                              &  8.0500                                             &                                                     & S                                                  \\\\\n",
       "\t 6                                                   & 0                                                   & 3                                                   & Moran, Mr. James                                    & male                                                & NA                                                  & 0                                                   & 0                                                   & 330877                                              &  8.4583                                             &                                                     & Q                                                  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked | \n",
       "|---|---|---|---|---|---|\n",
       "| 1                                                   | 0                                                   | 3                                                   | Braund, Mr. Owen Harris                             | male                                                | 22                                                  | 1                                                   | 0                                                   | A/5 21171                                           |  7.2500                                             |                                                     | S                                                   | \n",
       "| 2                                                   | 1                                                   | 1                                                   | Cumings, Mrs. John Bradley (Florence Briggs Thayer) | female                                              | 38                                                  | 1                                                   | 0                                                   | PC 17599                                            | 71.2833                                             | C85                                                 | C                                                   | \n",
       "| 3                                                   | 1                                                   | 3                                                   | Heikkinen, Miss. Laina                              | female                                              | 26                                                  | 0                                                   | 0                                                   | STON/O2. 3101282                                    |  7.9250                                             |                                                     | S                                                   | \n",
       "| 4                                                   | 1                                                   | 1                                                   | Futrelle, Mrs. Jacques Heath (Lily May Peel)        | female                                              | 35                                                  | 1                                                   | 0                                                   | 113803                                              | 53.1000                                             | C123                                                | S                                                   | \n",
       "| 5                                                   | 0                                                   | 3                                                   | Allen, Mr. William Henry                            | male                                                | 35                                                  | 0                                                   | 0                                                   | 373450                                              |  8.0500                                             |                                                     | S                                                   | \n",
       "| 6                                                   | 0                                                   | 3                                                   | Moran, Mr. James                                    | male                                                | NA                                                  | 0                                                   | 0                                                   | 330877                                              |  8.4583                                             |                                                     | Q                                                   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  PassengerId Survived Pclass\n",
       "1 1           0        3     \n",
       "2 2           1        1     \n",
       "3 3           1        3     \n",
       "4 4           1        1     \n",
       "5 5           0        3     \n",
       "6 6           0        3     \n",
       "  Name                                                Sex    Age SibSp Parch\n",
       "1 Braund, Mr. Owen Harris                             male   22  1     0    \n",
       "2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38  1     0    \n",
       "3 Heikkinen, Miss. Laina                              female 26  0     0    \n",
       "4 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female 35  1     0    \n",
       "5 Allen, Mr. William Henry                            male   35  0     0    \n",
       "6 Moran, Mr. James                                    male   NA  0     0    \n",
       "  Ticket           Fare    Cabin Embarked\n",
       "1 A/5 21171         7.2500       S       \n",
       "2 PC 17599         71.2833 C85   C       \n",
       "3 STON/O2. 3101282  7.9250       S       \n",
       "4 113803           53.1000 C123  S       \n",
       "5 373450            8.0500       S       \n",
       "6 330877            8.4583       Q       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train <- read.csv(\"train.csv\")\n",
    "df_test <- read.csv(\"test.csv\")\n",
    "\n",
    "df_test$Survived <- NA\n",
    "df_train <- rbind(df_train, df_test)\n",
    "\n",
    "head(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1309 obs. of  12 variables:\n",
      " $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...\n",
      " $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...\n",
      " $ Name       : Factor w/ 1307 levels \"Abbing, Mr. Anthony\",..: 109 191 358 277 16 559 520 629 417 581 ...\n",
      " $ Sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 2 1 1 ...\n",
      " $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...\n",
      " $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...\n",
      " $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...\n",
      " $ Ticket     : Factor w/ 929 levels \"110152\",\"110413\",..: 524 597 670 50 473 276 86 396 345 133 ...\n",
      " $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...\n",
      " $ Cabin      : Factor w/ 187 levels \"\",\"A10\",\"A14\",..: 1 83 1 57 1 1 131 1 1 1 ...\n",
      " $ Embarked   : Factor w/ 4 levels \"\",\"C\",\"Q\",\"S\": 4 2 4 4 4 3 4 4 4 2 ...\n"
     ]
    }
   ],
   "source": [
    "str(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset de entrenamiento contiene 891 pasajeros con 12 variables cada una.\n",
    "\n",
    "### Verificación de datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAANlBMVEUAAAAAcrJNTU1oaGh8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\nSUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aggr(df_train, digits = 3, numbers = TRUE, labels = names(df_train), cex.axis = .5, cex.numbers = .6,\n",
    "       gap = 2, ylabs = c(\"Histograma de datos faltantes\", \"Patron de datos faltantes\"), col = c('#0072B2', '#D55E00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAACkVBMVEUAAAAFBQUICAgQEBAS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\nSUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrixplot(df_train, interactive = F, sortby = \"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo Age (Edad) falta en el 20% de los datos. Los demás se ven completos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Survived\n",
    "Indica si el pasajero sobrevivió o no (Sí = 1; No = 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1 \n",
       "549 342 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1 \n",
       "0.62 0.38 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(df_train$Survived)\n",
    "round(prop.table(table(df_train$Survived) * 100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nWDwIFs//Afd2bj26Y18tAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = as.factor(Survived))) + geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Survived') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 62% de los pasajeros sobrevivieron mientras que el 38% no pudieron sobrevivir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Pclass\n",
    "Indica la clase social del pasajero: Primera, segunda o tercera clase. (1 = 1st; 2 = 2nd; 3 = 3rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  1   2   3 \n",
       "323 277 709 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   1    2    3 \n",
       "0.25 0.21 0.54 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(df_train$Pclass)\n",
    "round(prop.table(table(df_train$Pclass) * 100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = as.factor(Pclass))) + \n",
    "    geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Pclass') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 55% de los pasajeros correspondían a la tercera clase. Esto es el doble de las primera y segunda clase juntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Name\n",
    "Nombre del pasajero.\n",
    "Los nombres están compuestos de la siguiente forma: Apellido, **Title.** Nombre\n",
    "Lo que haremos es extraer el Título como una columna aparte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>Braund, Mr. Owen Harris</li>\n",
       "\t<li>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</li>\n",
       "\t<li>Heikkinen, Miss. Laina</li>\n",
       "\t<li>Futrelle, Mrs. Jacques Heath (Lily May Peel)</li>\n",
       "\t<li>Allen, Mr. William Henry</li>\n",
       "\t<li>Moran, Mr. James</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item Braund, Mr. Owen Harris\n",
       "\\item Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
       "\\item Heikkinen, Miss. Laina\n",
       "\\item Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
       "\\item Allen, Mr. William Henry\n",
       "\\item Moran, Mr. James\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. Braund, Mr. Owen Harris\n",
       "2. Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
       "3. Heikkinen, Miss. Laina\n",
       "4. Futrelle, Mrs. Jacques Heath (Lily May Peel)\n",
       "5. Allen, Mr. William Henry\n",
       "6. Moran, Mr. James\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] Braund, Mr. Owen Harris                            \n",
       "[2] Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
       "[3] Heikkinen, Miss. Laina                             \n",
       "[4] Futrelle, Mrs. Jacques Heath (Lily May Peel)       \n",
       "[5] Allen, Mr. William Henry                           \n",
       "[6] Moran, Mr. James                                   \n",
       "1307 Levels: Abbing, Mr. Anthony ... Zakarian, Mr. Ortin"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Mr'</li>\n",
       "\t<li>'Mrs'</li>\n",
       "\t<li>'Miss'</li>\n",
       "\t<li>'Master'</li>\n",
       "\t<li>'Don'</li>\n",
       "\t<li>'Rev'</li>\n",
       "\t<li>'Dr'</li>\n",
       "\t<li>'Mme'</li>\n",
       "\t<li>'Ms'</li>\n",
       "\t<li>'Major'</li>\n",
       "\t<li>'Lady'</li>\n",
       "\t<li>'Sir'</li>\n",
       "\t<li>'Mlle'</li>\n",
       "\t<li>'Col'</li>\n",
       "\t<li>'Capt'</li>\n",
       "\t<li>'the'</li>\n",
       "\t<li>'Jonkheer'</li>\n",
       "\t<li>'Dona'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Mr'\n",
       "\\item 'Mrs'\n",
       "\\item 'Miss'\n",
       "\\item 'Master'\n",
       "\\item 'Don'\n",
       "\\item 'Rev'\n",
       "\\item 'Dr'\n",
       "\\item 'Mme'\n",
       "\\item 'Ms'\n",
       "\\item 'Major'\n",
       "\\item 'Lady'\n",
       "\\item 'Sir'\n",
       "\\item 'Mlle'\n",
       "\\item 'Col'\n",
       "\\item 'Capt'\n",
       "\\item 'the'\n",
       "\\item 'Jonkheer'\n",
       "\\item 'Dona'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Mr'\n",
       "2. 'Mrs'\n",
       "3. 'Miss'\n",
       "4. 'Master'\n",
       "5. 'Don'\n",
       "6. 'Rev'\n",
       "7. 'Dr'\n",
       "8. 'Mme'\n",
       "9. 'Ms'\n",
       "10. 'Major'\n",
       "11. 'Lady'\n",
       "12. 'Sir'\n",
       "13. 'Mlle'\n",
       "14. 'Col'\n",
       "15. 'Capt'\n",
       "16. 'the'\n",
       "17. 'Jonkheer'\n",
       "18. 'Dona'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"Mr\"       \"Mrs\"      \"Miss\"     \"Master\"   \"Don\"      \"Rev\"     \n",
       " [7] \"Dr\"       \"Mme\"      \"Ms\"       \"Major\"    \"Lady\"     \"Sir\"     \n",
       "[13] \"Mlle\"     \"Col\"      \"Capt\"     \"the\"      \"Jonkheer\" \"Dona\"    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "18"
      ],
      "text/latex": [
       "18"
      ],
      "text/markdown": [
       "18"
      ],
      "text/plain": [
       "[1] 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df_train$Name)\n",
    "\n",
    "df_train$Title <- gsub(\".*,\\\\s([a-zA-Z]+)..*\", \"\\\\1\", df_train$Name)\n",
    "df_train$Name <- gsub(\"(.*),\\\\s[a-zA-Z]+.\\\\s(.*)\", \"\\\\2 \\\\1\", df_train$Name)\n",
    "\n",
    "unique(df_train$Title)\n",
    "length(unique(df_train$Title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver hay 17 títulos diferentes sin contar el título \"the\" que parece un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    Capt      Col      Don     Dona       Dr Jonkheer     Lady    Major \n",
       "       1        4        1        1        8        1        1        2 \n",
       "  Master     Miss     Mlle      Mme       Mr      Mrs       Ms      Rev \n",
       "      61      260        2        1      757      197        2        8 \n",
       "     Sir      the \n",
       "       1        1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(df_train$Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Countess. of (Lucy Noel Martha Dyer-Edwards) Rothes'"
      ],
      "text/latex": [
       "'Countess. of (Lucy Noel Martha Dyer-Edwards) Rothes'"
      ],
      "text/markdown": [
       "'Countess. of (Lucy Noel Martha Dyer-Edwards) Rothes'"
      ],
      "text/plain": [
       "[1] \"Countess. of (Lucy Noel Martha Dyer-Edwards) Rothes\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx <- which(df_train$Title == \"the\")\n",
    "df_train$Name[idx]\n",
    "\n",
    "df_train$Title[idx] <- 'Countess'\n",
    "df_train$Title <- as.factor(df_train$Title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazamos el erróneo \"the\" con el valor correcto que es Countess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nyoPgyvP/AQFrm7PgPv8AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = as.factor(Title))) + \n",
    "    geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Title') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros') + \n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los títulos más utilizados son Mr., Miss, Mrs. Probablemente por la abundancia de pasajeros en tercera clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Sex\n",
    "Género del pasajero: Male (hombre) o Female (mujer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "female   male \n",
       "   466    843 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "female   male \n",
       "  35.6   64.4 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "FALSE \n",
       " 1309 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(df_train$Sex)\n",
    "round(prop.table(table(df_train$Sex))*100,2)\n",
    "\n",
    "table(is.na(df_train$Sex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nYgAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = as.factor(Sex))) + \n",
    "    geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Sex') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 65% de los pasajeros corresponde a hombres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Age\n",
    "Edad del pasajero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n",
       "   0.17   21.00   28.00   29.88   39.00   80.00     263 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(df_train$Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La edad promedio de los pasajeros es de 30 años mientras que la mediana es de 28 años. La edad máxima es de 80 años.\n",
    "No se tiene la edad de 177 pasajeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\n/A8hZkLWziGQVwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = Age)) + geom_histogram(binwidth = 2, col=\"black\", fill=\"blue\", alpha = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La mayor parte de los pasajeros tienen entre 20 y 40 años. Como vimos la mediana es de 28 años.\n",
    "\n",
    "Para aquellos que no tienen las edades cargadas lo reemplazaremos con valores entre el primer y tercer cuartil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>26.18</li>\n",
       "\t<li>35.19</li>\n",
       "\t<li>28.36</li>\n",
       "\t<li>36.89</li>\n",
       "\t<li>37.93</li>\n",
       "\t<li>21.82</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 26.18\n",
       "\\item 35.19\n",
       "\\item 28.36\n",
       "\\item 36.89\n",
       "\\item 37.93\n",
       "\\item 21.82\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 26.18\n",
       "2. 35.19\n",
       "3. 28.36\n",
       "4. 36.89\n",
       "5. 37.93\n",
       "6. 21.82\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 26.18 35.19 28.36 36.89 37.93 21.82"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "na_count <- sum(is.na(df_train$Age))\n",
    "set.seed(123)\n",
    "\n",
    "ages <- round(runif(na_count, summary(df_train$Age)[2], summary(df_train$Age)[5]), 2)\n",
    "head(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train$Age[which(is.na(df_train$Age))] <- ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que imputamos los datos volvemos a graficar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = Age)) + geom_histogram(binwidth = 2, col=\"black\", fill=\"blue\", alpha = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora discreticemos el atributo Age de la siguiente forma:\n",
    "1. Bebé: entre 0 y 3 años\n",
    "2. Niño: entre 3 y 18 años\n",
    "3. Adulto: entre 18 y 50 años\n",
    "4. Anciano: mayor a 50 años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   Bebé    Niño  Adulto Anciano \n",
       "     34     120    1045     110 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   Bebé    Niño  Adulto Anciano \n",
       "   2.60    9.17   79.83    8.40 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train$AgeD <- \"Bebé\"\n",
    "df_train$AgeD[df_train$Age >= 3] <- \"Niño\"\n",
    "df_train$AgeD[df_train$Age >= 18] <- \"Adulto\"\n",
    "df_train$AgeD[df_train$Age >= 50] <- \"Anciano\"\n",
    "\n",
    "ages <- c(\"Bebé\", \"Niño\", \"Adulto\", \"Anciano\")\n",
    "\n",
    "df_train$AgeD <- factor(df_train$AgeD, labels = ages, levels = ages)\n",
    "\n",
    "table(df_train$AgeD)\n",
    "round(prop.table(table(df_train$AgeD)) * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nxQOweAAWD8DiAVg8AIsHYPH8H5CNxymkVKEXAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = as.factor(AgeD))) + \n",
    "    geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Edad') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros') + \n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos en el gráfico la mayoría de los tripulantes eran adultos, y casi el 23% eran bebés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: SibSp\n",
    "Número de hermanos/esposas a bordo por pasajero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nweJBsHgQLB4EiwfB4vk//h3zwVyv7fsAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train$SibSp <- factor(df_train$SibSp, levels = sort(unique(df_train$SibSp)), labels = sort(unique(df_train$SibSp)))\n",
    "\n",
    "ggplot(data = df_train, aes(x = as.factor(SibSp))) + \n",
    "    geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Hermanos/Esposas') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros') + \n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  0   1   2   3   4   5   8 \n",
       "891 319  42  20  22   6   9 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     3     4     5     8 \n",
       "68.07 24.37  3.21  1.53  1.68  0.46  0.69 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(df_train$SibSp)\n",
    "round(prop.table(table(df_train$SibSp)) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 90% de los pasajeros no tenía un hermano/esposa o tenía al menos 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: parch\n",
    "Número de padres/hijos a bordo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train$Parch<- factor(df_train$Parch, levels = sort(unique(df_train$Parch)), labels = sort(unique(df_train$Parch)))\n",
    "\n",
    "ggplot(data = df_train, aes(x = as.factor(Parch))) + \n",
    "    geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Padres/Hijos') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros') + \n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "   0    1    2    3    4    5    6    9 \n",
       "1002  170  113    8    6    6    2    2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    0     1     2     3     4     5     6     9 \n",
       "76.55 12.99  8.63  0.61  0.46  0.46  0.15  0.15 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(df_train$Parch)\n",
    "round(prop.table(table(df_train$Parch)) * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 75% de los pasajeros no tenían padres o hijos a bordo.\n",
    "\n",
    "### Atributo: Family Size = SibSp + Parch \n",
    "Podemos construir un nuevo atributo a partir de los otros dos. Esto contendrá el tamaño de la familia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "  3   4   5   6   7   8   9  10  11 \n",
       "790 235 159  43  22  25  16   8  11 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    3     4     5     6     7     8     9    10    11 \n",
       "60.35 17.95 12.15  3.28  1.68  1.91  1.22  0.61  0.84 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train$FamilySize <- as.integer(df_train$SibSp) + as.integer(df_train$Parch) + 1\n",
    "\n",
    "table(df_train$FamilySize)\n",
    "round(prop.table(table(df_train$FamilySize)) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = as.factor(FamilySize))) + \n",
    "    geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Family Size') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros') + \n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Ticket\n",
    "Número del ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train$Ticket <- as.integer(df_train$Ticket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Fare\n",
    "Es la tarifa que pagó el pasajero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n",
       "  0.000   7.896  14.450  33.300  31.280 512.300       1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(df_train$Fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8\nfHyMjIyampqnp6eysrK8vO+9vb3Hx8fMzP/Q0NDZ2dnh4eHp6enr6+vw8PD///+MWiR5AAAA\nCXBIWXMAABJ0AAASdAHeZh94AAAM6ElEQVR4nO2di1abWhgGEa2pradeeP93PeZqEoMCfrAn\n2/nXOlp1wp5kBAm1OU3nVD1NaQFn3jFw5WPgysfAlY+BKx8DVz4GrnwMXPl8O/DLpbn82bEI\njYHpfMYYeAoD0zFwmoHpGDjNwHQMnGZgOgZOMzAdA6cZmI6B0wxMx8BpBqZj4DQD0zFwmoHp\nGDjNwHQMnGZgOgZOMzCdhQI77HEPHs7AdDxEpxmYjoHTDEzHwGkGplM2cLOeGe9BCQamUzjw\nw8ODgYsxBp7CwHQMnGZgOgZOMzAdA6cZmI6B0wxMx8BpBqZj4DQD0zFwmoHpGDjNwHQMnGZg\nOgZOMzAdA6cZmI6B0wxMx8BpBqZj4DQD0zFwmoHpGDjNwHQMnGZgOgZOMzAdA6cZmI6B0wxM\nx8BpBqZj4DQD0zFwmoHpGDjNwHQMnGZgOgZOMzAdA6cZmI6B0wxMx8BpBqZj4DQD00kGbjdv\n3ub4vYG5zMjAm6DtrvT+vYHBzLjAbWfghZdaNPAuqoFhOvMHvllPz42ax8dHX0UPMF9HaDv3\n4MWXWnAPPvQ0MEwnFXg7BsbppJ8HGximY+A0A9PxSlaagel4LTrNwHQMnGZgOgZOMzAdA6cZ\nmI6B0wxMx8BpBqZj4DQD0zFwmoHpGDjNwHQMnGZgOgZOMzAdA6cZmI6B0wxMx8BpBqZj4DQD\n0zFwmoHpGDjNwHQMnGZgOgZOMzAdA6cZmI6B0wxMx8BpBqZj4DQD0zFwmoHpGDjNwHQMnGZg\nOgZOMzAdA6cZmI6B0wxMx8BpBqZj4DQD0zFwmoHpGDjNwHQMnGZgOgZOMzAdA6cZmM5CgXvG\nlzKEjHvwcAam4yE6zcB0DJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0\nDJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiO\ngdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9Mx\ncJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMMTCcWuH2bS+8NzGXGBG53b87fGxjMGHgKA9OJ\n/gw28LJLMQLfrKfnBr6UIWSGRNieVLkHw3Q8RKcZmI6B0wxMx7PoNAPTMXCagel4JSvNwHS8\nFp1mYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiO\ngdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9Mx\ncJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoG\nTjMwHQOnGZiOgdMMTGehwD3jSxlCxj14OAPT8RCdZmA6kwI3u4+PXwnLwMsvNU/gtjkaA5dc\nap7Af476/jFwyaVmP0QPn56lDVyU6Q08fnqWNnBRpj/wqvVnMGCp2QKvPMlCLDVb4Hb42ZWB\nwUxvYE+yGEvNFvhX82pgwFKzBX5u754NXH6pGQ/RnmQRljJwCQam44WONAPTMXCagel4iE4z\nMB0DpxmYzjcO0c93v4f2NTCS+SJw99oMLtyztIGLMl8FHnHJsmdpAxdlvgr8t/F3soouNf9J\n1srAJZeaO3A7uK+BkUxv4PHTs7SBizIGnsLAdKYFfl3dNs3tavjfCvcsbeCiTG/g593v3LWD\n/1a4Z2kDF2V6A98367/wf75r7g1ccqkZz6JP3xu4zFJXEng9M92DEgxMB3CI/mwvhjwSYxiY\nDuAky8ClmN7A2adJBi7F9AcePT1LG7goY+ApDExnWuBfm080t/4MLrrUbIFX2+dHzfFZdNtu\nX7Hj/L2BuUxv4Lb5t373dPQ8uN29OX9vYDDTG/jChQ4DF1hqtsC/mvvX9XOl5u5szzYwTud7\nFzqeBgS+WU93eTYvZejLGZafngsdZyfRbecejNNJPg828MJLLRy4PX5j4CtgxgVuTyob+AqY\nUYHb093YwFfAjAnctrtLV17JWm6ppU+yPpmepQ1clDHwFAamY+A0A9MxcJqB6Rg4zcB0DJxm\nYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMM\nTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB\n6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB6SwUuGd8KUPIuAcPZ2A6\nHqLTDEzHwGkGpmPgNAPTMXCagekYOM3AdAycZmA6Bk4zMB0DpxmYDijwpf+RMOSRGMPAdEiB\nL+zKkEdiDAPTMXCagekYOM3AdAycZmA6Bk4zMB0DpxmYjoHTDEzHwGkGpmPgNAPTMXCagekY\nOM3AdAycZmA6Bk4zMB0DpxmYjoHTDEzHwGkGpmPgNAPTMXCagekYOM3AdAycZmA6Bk4zMB0D\npxmYjoHTDEzHwGkGpmPgNAPTMXCagelAAm/GwAszIwO327dvc/x+WOCHnn+FBnkkxjAwnVzg\nXdfdm/cPDIxlRgVuOwMvvVSJQ7SBYTrzB75ZT89NDq909+hL3hUd9+DhDEzHQ3SagekYOM3A\ndAycZmA6Bk4zMB2vZKUZmA7kWrSBSzAGnsLAdAycZmA6Bk4zMB1a4LOXM4Q8EmMYmA4t8Nle\nDHkkxjAwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMM\nTMfAaQamY+A0A9MxcJqB6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB\n6Rg4zcB0DJxmYDoGTjMwHQOnGZiOgdMMTMfAaQamY+A0A9MxcJqB6Rg4zcB0FgrcMx9fytCX\nMywy7sHDGZiOh+g0A9MxcJqB6Rg4zcB06IHPX5Ulfy/TDEwHH/jsE/l7mWZgOgZOMzAdA6cZ\nmI6B0wxMx8BpBqZj4DQD0zFwmoHpGDjNwHQMnGZgOgZOMzAdA6cZmM7VBW4+XJ2GPFoFlqoz\n8MP5ZyCPVoGlrjXw0T5q4DmZUoGPEhp4TsbAUxiYzlUF3hy7DRxjeIHPvhq5l2kGpmPgNAPT\nMXCagelgA2+fKhl4TqZo4G1GA8/JzBq42Z8SfxJ4Txxuc7Z/L/ZIjGFgOuUCPzw8Xmh69sHj\nyaWt8/17sUdiDAPTuYrA+6OygbOMgacwMB0DT2E+/p3lbEvNyRi4j/l4Kj/bUnMyVxT4q3+j\nZuCLX0IFPnpW9f4kan8Pmv4HfNwj8cV3ioHnC3wR3d+DXODPN2RgSuCzPdHAF790zYH3B/HN\nz+6v/xX5i4FHTvs2pQO/n5w9fvW7ty+XAn/8xjDwoe/hzayB13MIfJiX48Cbk7PH06/2PxL7\nwO+Xyg/C+7VerjDw5Tt+BYHX/x0Cn+60J+jj6Vc/eSSObn/6bOyw1ss1Br7oa2ADDwh8s56P\nQOMsPZ/kmmEPHvb9h9wdMEuhT7KG6UEeiTEMTMfAaQamY+A0A9MxcJqB6RS7kjVMD/JIjGFg\nOsWuRQ/TgzwSYxiYjoHTDEzHwGkGpmPgNAPTMXCagekYOM3AdAycZmA6Bk4zMB0DpxmYjoHT\nDEzHwGkGpmPgNAPTWSjwxbnwizwFN1OpzrDtGHjxzRg4vZlKdQyc3g5Mx8Dp7cB0SgZ2MGPg\nysfAlY+BKx8DVz5zBD79vdopGzjZzNTNnd9+4nZCm9ncNLGddnfDgduZIfDZb8ZP2MD7Ftrp\nmzu//cTthDazuVV7YXvThIZvBxi47eoMvL1fBj7Zwvd2mdSuF9nM7raR79sR2zHwUptJBd7/\nCB64nboDZ46JkZ+dbRcKfHZ7AzP24MPNlj4wVR04+Y3y3cDt7thq4C4Wpj3Z2Dd3PcoBxUP0\n6VaqDDxmO/VeyWpHXvL5bDsBnc1NE9sZ6eO16MrHwJWPgSsfA1c+Bq58DFz5GLjyMXDlY+DK\nx8CVz88NPOTl0iuYyu/eJ2Pgyqf2srv5Gffy0hwH/veradrV5pNP7V3Xvd43zf1rMbXkGPht\n/tseq1frT941913Xrj+8LSiXm58c+PAj+Lb523VP6z9uKne/129XzZ/Siokx8OaD5/9+320D\nP3fr4BvgV0m91PzkwO9/vtu33n6ypvPrKu7EpDnqd9/c/vnv2cB1zVG/zR9f3wPfVvSoVHRX\nRs5J4H/d69174NX6JOtvc1fMLTgG7tZBT38Gv26eJjVPxdyCY+D13L89//33Hrh73nyikFh2\nfm7gHzIGrnwMXPkYuPIxcOVj4MrHwJWPgSsfA1c+/wMZ7puCDS66/wAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = Fare)) + geom_histogram(binwidth = 6, col=\"black\", fill=\"blue\", alpha = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El promedio del precio de un ticket es de \\$33, mientras que lo máximo que se pagó por uno fue más de \\$500. Podemos ver que hay tickets con valor \\$0. Veamos estas observaciones si hay algún error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>PassengerId</th><th scope=col>Survived</th><th scope=col>Pclass</th><th scope=col>Name</th><th scope=col>Sex</th><th scope=col>Age</th><th scope=col>SibSp</th><th scope=col>Parch</th><th scope=col>Ticket</th><th scope=col>Fare</th><th scope=col>Cabin</th><th scope=col>Embarked</th><th scope=col>Title</th><th scope=col>AgeD</th><th scope=col>FamilySize</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>180</th><td> 180                            </td><td> 0                              </td><td> 3                              </td><td>Lionel Leonard                  </td><td>male                            </td><td>36.00                           </td><td>0                               </td><td>0                               </td><td>575                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>264</th><td> 264                            </td><td> 0                              </td><td> 1                              </td><td>William Harrison                </td><td>male                            </td><td>40.00                           </td><td>0                               </td><td>0                               </td><td> 17                             </td><td> 0                              </td><td>B94                             </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>272</th><td> 272                            </td><td> 1                              </td><td> 3                              </td><td>William Henry Tornquist         </td><td>male                            </td><td>25.00                           </td><td>0                               </td><td>0                               </td><td>575                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>278</th><td> 278                            </td><td> 0                              </td><td> 2                              </td><td>Francis \"Frank\" Parkes          </td><td>male                            </td><td>31.10                           </td><td>0                               </td><td>0                               </td><td>136                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>303</th><td> 303                            </td><td> 0                              </td><td> 3                              </td><td>William Cahoone Jr Johnson      </td><td>male                            </td><td>19.00                           </td><td>0                               </td><td>0                               </td><td>575                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>414</th><td> 414                            </td><td> 0                              </td><td> 2                              </td><td>Alfred Fleming Cunningham       </td><td>male                            </td><td>33.03                           </td><td>0                               </td><td>0                               </td><td>136                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>467</th><td> 467                            </td><td> 0                              </td><td> 2                              </td><td>William Campbell                </td><td>male                            </td><td>32.82                           </td><td>0                               </td><td>0                               </td><td>136                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>482</th><td> 482                            </td><td> 0                              </td><td> 2                              </td><td>Anthony Wood \"Archie\" Frost     </td><td>male                            </td><td>22.68                           </td><td>0                               </td><td>0                               </td><td>137                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>598</th><td> 598                            </td><td> 0                              </td><td> 3                              </td><td>Alfred Johnson                  </td><td>male                            </td><td>49.00                           </td><td>0                               </td><td>0                               </td><td>575                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>634</th><td> 634                            </td><td> 0                              </td><td> 1                              </td><td>William Henry Marsh Parr        </td><td>male                            </td><td>33.11                           </td><td>0                               </td><td>0                               </td><td> 14                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>675</th><td> 675                            </td><td> 0                              </td><td> 2                              </td><td>Ennis Hastings Watson           </td><td>male                            </td><td>28.37                           </td><td>0                               </td><td>0                               </td><td>139                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>733</th><td> 733                            </td><td> 0                              </td><td> 2                              </td><td>Robert J Knight                 </td><td>male                            </td><td>34.18                           </td><td>0                               </td><td>0                               </td><td>138                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>807</th><td> 807                            </td><td> 0                              </td><td> 1                              </td><td>Thomas Jr Andrews               </td><td>male                            </td><td>39.00                           </td><td>0                               </td><td>0                               </td><td> 13                             </td><td> 0                              </td><td>A36                             </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>816</th><td> 816                            </td><td> 0                              </td><td> 1                              </td><td>Richard Fry                     </td><td>male                            </td><td>27.74                           </td><td>0                               </td><td>0                               </td><td> 16                             </td><td> 0                              </td><td>B102                            </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>823</th><td> 823                            </td><td> 0                              </td><td> 1                              </td><td>John George Reuchlin            </td><td>male                            </td><td>38.00                           </td><td>0                               </td><td>0                               </td><td> 98                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Jonkheer                        </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>NA</th><td>  NA                            </td><td>NA                              </td><td>NA                              </td><td>NA                              </td><td>NA                              </td><td>   NA                           </td><td>NA                              </td><td>NA                              </td><td> NA                             </td><td>NA                              </td><td>NA                              </td><td>NA                              </td><td>NA                              </td><td>NA                              </td><td>NA                              </td></tr>\n",
       "\t<tr><th scope=row>1158</th><td>1158                            </td><td>NA                              </td><td> 1                              </td><td>Roderick Robert Crispin Chisholm</td><td>male                            </td><td>28.71                           </td><td>0                               </td><td>0                               </td><td>685                             </td><td> 0                              </td><td>                                </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "\t<tr><th scope=row>1264</th><td>1264                            </td><td>NA                              </td><td> 1                              </td><td>Joseph Bruce Ismay              </td><td>male                            </td><td>49.00                           </td><td>0                               </td><td>0                               </td><td> 16                             </td><td> 0                              </td><td>B52 B54 B56                     </td><td>S                               </td><td>Mr                              </td><td>Adulto                          </td><td> 3                              </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       "  & PassengerId & Survived & Pclass & Name & Sex & Age & SibSp & Parch & Ticket & Fare & Cabin & Embarked & Title & AgeD & FamilySize\\\\\n",
       "\\hline\n",
       "\t180 &  180                             &  0                               &  3                               & Lionel Leonard                   & male                             & 36.00                            & 0                                & 0                                & 575                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t264 &  264                             &  0                               &  1                               & William Harrison                 & male                             & 40.00                            & 0                                & 0                                &  17                              &  0                               & B94                              & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t272 &  272                             &  1                               &  3                               & William Henry Tornquist          & male                             & 25.00                            & 0                                & 0                                & 575                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t278 &  278                             &  0                               &  2                               & Francis \"Frank\" Parkes           & male                             & 31.10                            & 0                                & 0                                & 136                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t303 &  303                             &  0                               &  3                               & William Cahoone Jr Johnson       & male                             & 19.00                            & 0                                & 0                                & 575                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t414 &  414                             &  0                               &  2                               & Alfred Fleming Cunningham        & male                             & 33.03                            & 0                                & 0                                & 136                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t467 &  467                             &  0                               &  2                               & William Campbell                 & male                             & 32.82                            & 0                                & 0                                & 136                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t482 &  482                             &  0                               &  2                               & Anthony Wood \"Archie\" Frost      & male                             & 22.68                            & 0                                & 0                                & 137                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t598 &  598                             &  0                               &  3                               & Alfred Johnson                   & male                             & 49.00                            & 0                                & 0                                & 575                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t634 &  634                             &  0                               &  1                               & William Henry Marsh Parr         & male                             & 33.11                            & 0                                & 0                                &  14                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t675 &  675                             &  0                               &  2                               & Ennis Hastings Watson            & male                             & 28.37                            & 0                                & 0                                & 139                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t733 &  733                             &  0                               &  2                               & Robert J Knight                  & male                             & 34.18                            & 0                                & 0                                & 138                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t807 &  807                             &  0                               &  1                               & Thomas Jr Andrews                & male                             & 39.00                            & 0                                & 0                                &  13                              &  0                               & A36                              & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t816 &  816                             &  0                               &  1                               & Richard Fry                      & male                             & 27.74                            & 0                                & 0                                &  16                              &  0                               & B102                             & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t823 &  823                             &  0                               &  1                               & John George Reuchlin             & male                             & 38.00                            & 0                                & 0                                &  98                              &  0                               &                                  & S                                & Jonkheer                         & Adulto                           &  3                              \\\\\n",
       "\tNA &   NA                             & NA                               & NA                               & NA                               & NA                               &    NA                            & NA                               & NA                               &  NA                              & NA                               & NA                               & NA                               & NA                               & NA                               & NA                              \\\\\n",
       "\t1158 & 1158                             & NA                               &  1                               & Roderick Robert Crispin Chisholm & male                             & 28.71                            & 0                                & 0                                & 685                              &  0                               &                                  & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\t1264 & 1264                             & NA                               &  1                               & Joseph Bruce Ismay               & male                             & 49.00                            & 0                                & 0                                &  16                              &  0                               & B52 B54 B56                      & S                                & Mr                               & Adulto                           &  3                              \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | PassengerId | Survived | Pclass | Name | Sex | Age | SibSp | Parch | Ticket | Fare | Cabin | Embarked | Title | AgeD | FamilySize | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 180 |  180                             |  0                               |  3                               | Lionel Leonard                   | male                             | 36.00                            | 0                                | 0                                | 575                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 264 |  264                             |  0                               |  1                               | William Harrison                 | male                             | 40.00                            | 0                                | 0                                |  17                              |  0                               | B94                              | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 272 |  272                             |  1                               |  3                               | William Henry Tornquist          | male                             | 25.00                            | 0                                | 0                                | 575                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 278 |  278                             |  0                               |  2                               | Francis \"Frank\" Parkes           | male                             | 31.10                            | 0                                | 0                                | 136                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 303 |  303                             |  0                               |  3                               | William Cahoone Jr Johnson       | male                             | 19.00                            | 0                                | 0                                | 575                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 414 |  414                             |  0                               |  2                               | Alfred Fleming Cunningham        | male                             | 33.03                            | 0                                | 0                                | 136                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 467 |  467                             |  0                               |  2                               | William Campbell                 | male                             | 32.82                            | 0                                | 0                                | 136                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 482 |  482                             |  0                               |  2                               | Anthony Wood \"Archie\" Frost      | male                             | 22.68                            | 0                                | 0                                | 137                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 598 |  598                             |  0                               |  3                               | Alfred Johnson                   | male                             | 49.00                            | 0                                | 0                                | 575                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 634 |  634                             |  0                               |  1                               | William Henry Marsh Parr         | male                             | 33.11                            | 0                                | 0                                |  14                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 675 |  675                             |  0                               |  2                               | Ennis Hastings Watson            | male                             | 28.37                            | 0                                | 0                                | 139                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 733 |  733                             |  0                               |  2                               | Robert J Knight                  | male                             | 34.18                            | 0                                | 0                                | 138                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 807 |  807                             |  0                               |  1                               | Thomas Jr Andrews                | male                             | 39.00                            | 0                                | 0                                |  13                              |  0                               | A36                              | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 816 |  816                             |  0                               |  1                               | Richard Fry                      | male                             | 27.74                            | 0                                | 0                                |  16                              |  0                               | B102                             | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 823 |  823                             |  0                               |  1                               | John George Reuchlin             | male                             | 38.00                            | 0                                | 0                                |  98                              |  0                               |                                  | S                                | Jonkheer                         | Adulto                           |  3                               | \n",
       "| NA |   NA                             | NA                               | NA                               | NA                               | NA                               |    NA                            | NA                               | NA                               |  NA                              | NA                               | NA                               | NA                               | NA                               | NA                               | NA                               | \n",
       "| 1158 | 1158                             | NA                               |  1                               | Roderick Robert Crispin Chisholm | male                             | 28.71                            | 0                                | 0                                | 685                              |  0                               |                                  | S                                | Mr                               | Adulto                           |  3                               | \n",
       "| 1264 | 1264                             | NA                               |  1                               | Joseph Bruce Ismay               | male                             | 49.00                            | 0                                | 0                                |  16                              |  0                               | B52 B54 B56                      | S                                | Mr                               | Adulto                           |  3                               | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     PassengerId Survived Pclass Name                             Sex  Age  \n",
       "180   180         0        3     Lionel Leonard                   male 36.00\n",
       "264   264         0        1     William Harrison                 male 40.00\n",
       "272   272         1        3     William Henry Tornquist          male 25.00\n",
       "278   278         0        2     Francis \"Frank\" Parkes           male 31.10\n",
       "303   303         0        3     William Cahoone Jr Johnson       male 19.00\n",
       "414   414         0        2     Alfred Fleming Cunningham        male 33.03\n",
       "467   467         0        2     William Campbell                 male 32.82\n",
       "482   482         0        2     Anthony Wood \"Archie\" Frost      male 22.68\n",
       "598   598         0        3     Alfred Johnson                   male 49.00\n",
       "634   634         0        1     William Henry Marsh Parr         male 33.11\n",
       "675   675         0        2     Ennis Hastings Watson            male 28.37\n",
       "733   733         0        2     Robert J Knight                  male 34.18\n",
       "807   807         0        1     Thomas Jr Andrews                male 39.00\n",
       "816   816         0        1     Richard Fry                      male 27.74\n",
       "823   823         0        1     John George Reuchlin             male 38.00\n",
       "NA     NA        NA       NA     NA                               NA      NA\n",
       "1158 1158        NA        1     Roderick Robert Crispin Chisholm male 28.71\n",
       "1264 1264        NA        1     Joseph Bruce Ismay               male 49.00\n",
       "     SibSp Parch Ticket Fare Cabin       Embarked Title    AgeD   FamilySize\n",
       "180  0     0     575     0               S        Mr       Adulto  3        \n",
       "264  0     0      17     0   B94         S        Mr       Adulto  3        \n",
       "272  0     0     575     0               S        Mr       Adulto  3        \n",
       "278  0     0     136     0               S        Mr       Adulto  3        \n",
       "303  0     0     575     0               S        Mr       Adulto  3        \n",
       "414  0     0     136     0               S        Mr       Adulto  3        \n",
       "467  0     0     136     0               S        Mr       Adulto  3        \n",
       "482  0     0     137     0               S        Mr       Adulto  3        \n",
       "598  0     0     575     0               S        Mr       Adulto  3        \n",
       "634  0     0      14     0               S        Mr       Adulto  3        \n",
       "675  0     0     139     0               S        Mr       Adulto  3        \n",
       "733  0     0     138     0               S        Mr       Adulto  3        \n",
       "807  0     0      13     0   A36         S        Mr       Adulto  3        \n",
       "816  0     0      16     0   B102        S        Mr       Adulto  3        \n",
       "823  0     0      98     0               S        Jonkheer Adulto  3        \n",
       "NA   NA    NA     NA    NA   NA          NA       NA       NA     NA        \n",
       "1158 0     0     685     0               S        Mr       Adulto  3        \n",
       "1264 0     0      16     0   B52 B54 B56 S        Mr       Adulto  3        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train[df_train$Fare == 0,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazemos estos valores con la mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train$Fare[which(df_train$Fare == 0)] <- median(df_train$Fare, na.rm = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vemos que el mínimo es \\$4 y volvemos a graficar el histograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n",
       "  3.171   7.925  14.450  33.480  31.280 512.300       1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nAo0AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(df_train$Fare)\n",
    "ggplot(data = df_train, aes(x = Fare)) + geom_histogram(binwidth = 6, col=\"black\", fill=\"blue\", alpha = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Cabin\n",
    "Cabina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Factor w/ 187 levels \"\",\"A10\",\"A14\",..: 1 83 1 57 1 1 131 1 1 1 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li></li>\n",
       "\t<li>C85</li>\n",
       "\t<li></li>\n",
       "\t<li>C123</li>\n",
       "\t<li></li>\n",
       "\t<li></li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item \n",
       "\\item C85\n",
       "\\item \n",
       "\\item C123\n",
       "\\item \n",
       "\\item \n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. \n",
       "2. C85\n",
       "3. \n",
       "4. C123\n",
       "5. \n",
       "6. \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]      C85       C123          \n",
       "187 Levels:  A10 A14 A16 A19 A20 A23 A24 A26 A31 A32 A34 A36 A5 A6 A7 ... F E57"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "FALSE  TRUE \n",
       "  295  1014 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "FALSE  TRUE \n",
       "22.54 77.46 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str(df_train$Cabin)\n",
    "head(df_train$Cabin)\n",
    "\n",
    "df_train$Cabin[df_train$Cabin == \"\"] <- NA\n",
    "\n",
    "table(is.na(df_train$Cabin))\n",
    "round(prop.table(table(is.na(df_train$Cabin)))*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos ver que hay valores faltantes en el atributo Cabina, pero estaba codificados como caracteres en blanco. Falta el 23% de los datos en este atributo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAANlBMVEUAAAAAcrJNTU1oaGh8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\n",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aggr(df_train, digits = 3, numbers = TRUE, labels = names(df_train), cex.axis = .5, cex.numbers = .6,\n",
    "       gap = 2, ylabs = c(\"Histograma de datos faltantes\", \"Patron de datos faltantes\"), col = c('#0072B2', '#D55E00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributo: Embarked\n",
    "Embarque. (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Factor w/ 4 levels \"\",\"C\",\"Q\",\"S\": 4 2 4 4 4 3 4 4 4 2 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "      C   Q   S \n",
       "  0 168  77 644 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "          C     Q     S \n",
       " 0.00 18.90  8.66 72.44 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "FALSE  TRUE \n",
       "  889     2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str(df_train$Embarked)\n",
    "\n",
    "df_train$Embarked[df_train$Embarked == \"\"] <- NA\n",
    "\n",
    "table(df_train$Embarked)\n",
    "round(prop.table(table(df_train$Embarked)) *100, 2)\n",
    "\n",
    "table(is.na(df_train$Embarked))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay dos pasajeros que no tienen una Embarque asignado. Así que les asignaremos el valor más común que es S."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx <- which(is.na(df_train$Embarked))\n",
    "df_train$Embarked[idx] <- \"S\"\n",
    "df_train$Embarked <- factor(df_train$Embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAPFBMVEUAAAAzMzNNTU1oaGh8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\nIX60SSGmdAAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(data = df_train, aes(x = Embarked)) + \n",
    "    geom_bar(col=\"black\", fill=\"blue\", alpha = .2) + \n",
    "    ggtitle('Atributo: Embarked') + \n",
    "    xlab('') + \n",
    "    ylab('No. de pasajeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 73% de los pasajeros partieron del mismo puerto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "\n",
    "### Análisis multivariado\n",
    "\n",
    "Ahora veremos como se relacionan las variables entre sí para encontrar correlaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t891 obs. of  15 variables:\n",
      " $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...\n",
      " $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...\n",
      " $ Name       : chr  \"Owen Harris Braund\" \"John Bradley (Florence Briggs Thayer) Cumings\" \"Laina Heikkinen\" \"Jacques Heath (Lily May Peel) Futrelle\" ...\n",
      " $ Sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 2 1 1 ...\n",
      " $ Age        : num  22 38 26 35 35 ...\n",
      " $ SibSp      : Factor w/ 7 levels \"0\",\"1\",\"2\",\"3\",..: 2 2 1 2 1 1 1 4 1 2 ...\n",
      " $ Parch      : Factor w/ 7 levels \"0\",\"1\",\"2\",\"3\",..: 1 1 1 1 1 1 1 2 3 1 ...\n",
      " $ Ticket     : int  524 597 670 50 473 276 86 396 345 133 ...\n",
      " $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...\n",
      " $ Cabin      : Factor w/ 148 levels \"\",\"A10\",\"A14\",..: NA 83 NA 57 NA NA 131 NA NA NA ...\n",
      " $ Embarked   : Factor w/ 3 levels \"C\",\"Q\",\"S\": 3 1 3 3 3 2 3 3 3 1 ...\n",
      " $ Title      : Factor w/ 17 levels \"Capt\",\"Col\",\"Countess\",..: 13 14 10 14 13 13 13 9 14 14 ...\n",
      " $ AgeD       : Factor w/ 4 levels \"Bebé\",\"Niño\",..: 3 3 3 3 3 3 4 1 3 2 ...\n",
      " $ FamilySize : num  4 4 3 4 3 3 3 7 5 4 ...\n"
     ]
    }
   ],
   "source": [
    "str(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train$PassengerId <- NULL\n",
    "df_train$Survived <- as.factor(df_train$Survived)\n",
    "df_train$Pclass <- as.factor(df_train$Pclass)\n",
    "df_train$Age <- NULL\n",
    "df_train$Ticket <- NULL\n",
    "df_train$Cabin <- NULL\n",
    "df_train$FamilySize <- as.factor(df_train$FamilySize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos: Survived vs. Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAQlBMVEUAAAAAujgzMzNNTU1h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\nTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df_train, aes(Survived, ..count..)) + geom_bar(aes(fill = Pclass), position = \"dodge\") +\n",
    "    ggtitle(\"Sobrevivientes según clase social\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cantidad de pasajeros que sobrevivieron y que no en la primera clase es casi la misma, igualmente para la segunda clase. No así para la tercera clase donde no sobrevivieron casi 400 personas.\n",
    "\n",
    "### Atributos: Survived vs. Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAP1BMVEUAAAAAv8QzMzNNTU1o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\n0U0AAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df_train, aes(Survived, ..count..)) + geom_bar(aes(fill = Sex), position = \"dodge\") +\n",
    "    ggtitle(\"Sobrevivientes según sexo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La proporción de hombres que no sobrevivieron es mucho mayor que las mujeres que no sobrevivieron, esto es debido a la prioridad que tenían las mujeres para subirse a los botes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos: Survived vs. Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAARVBMVEUAAAAAv8QzMzNNTU1o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\nwYlDwYlDwYnzf/3b4eScOoB+AAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df_train, aes(Survived, ..count..)) + geom_bar(aes(fill = AgeD), position = \"dodge\") +\n",
    "    ggtitle(\"Sobrevivientes según edad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobrevivieron más niños que ancianos o bebés.\n",
    "Los adultos tenían mucha probabilidad de no sobrevivir dado a que las prioridades eran los niños."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos: Survived vs FamilySize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAVFBMVEUAAAAAueMAujgAwZ8z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\nrkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df_train, aes(Survived, ..count..)) + geom_bar(aes(fill = FamilySize), position = \"dodge\") +\n",
    "    ggtitle(\"Sobrevivientes según tamaño de familia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las familias más chicas a bordo tenían menos chances de sobrevivir. Las familias a bordo que eran más grandes tenían más chances de supervivencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atributos: Survived vs. Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAANlBMVEUAAAAzMzNNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df_train, aes(Survived, Fare)) + geom_boxplot() +\n",
    "    ggtitle(\"Sobrevivientes según la tarifa del ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los que poseían tarifas de mayor valor tenían más chances de sobrevivir, quizás porque pertenecían a clase más alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAQlBMVEUAAAAAujgzMzNNTU1h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\nmLdadp9iJwAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df_train, aes(Survived, Fare, fill = Pclass)) + geom_bar(stat='identity') +\n",
    "    ggtitle(\"Sobrevivientes según tarifa del ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos corroborar con el gráfico anterior que los de primera clase tenían tarifas más caras. \n",
    "Recordemos que la tercera clase representa el 50% de los pasajeros e incluso así son minoría en el gráfico. (El tamaño de cada bloque está dado por la suma de todos los tickets para esa clase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAQlBMVEUAAAAAujgzMzNNTU1h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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df_train, aes(Survived, ..count..)) + geom_bar(aes(fill = Embarked), position = \"dodge\") +\n",
    "    ggtitle(\"Sobrevivientes según puerto de embarque\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los que embarcaron en Southampton tenían menos chances de sobrevivir. Veamos si tiene que ver la clase social."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1309 obs. of  12 variables:\n",
      " $ PassengerId: int  1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Survived   : int  0 1 1 1 0 0 0 0 1 1 ...\n",
      " $ Pclass     : int  3 1 3 1 3 3 1 3 3 2 ...\n",
      " $ Name       : Factor w/ 1307 levels \"Abbing, Mr. Anthony\",..: 109 191 358 277 16 559 520 629 417 581 ...\n",
      " $ Sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 2 1 1 ...\n",
      " $ Age        : num  22 38 26 35 35 NA 54 2 27 14 ...\n",
      " $ SibSp      : int  1 1 0 1 0 0 0 3 0 1 ...\n",
      " $ Parch      : int  0 0 0 0 0 0 0 1 2 0 ...\n",
      " $ Ticket     : Factor w/ 929 levels \"110152\",\"110413\",..: 524 597 670 50 473 276 86 396 345 133 ...\n",
      " $ Fare       : num  7.25 71.28 7.92 53.1 8.05 ...\n",
      " $ Cabin      : Factor w/ 186 levels \"A10\",\"A14\",\"A16\",..: NA 82 NA 56 NA NA 130 NA NA NA ...\n",
      " $ Embarked   : Factor w/ 3 levels \"C\",\"Q\",\"S\": 3 1 3 3 3 2 3 3 3 1 ...\n"
     ]
    }
   ],
   "source": [
    "df_train <- read.csv(\"train.csv\", na.strings = c(\"\", \"NA\"))\n",
    "df_test <- read.csv(\"test.csv\", na.strings = c(\"\", \"NA\"))\n",
    "\n",
    "df_test$Survived <- NA\n",
    "df_train <- rbind(df_train, df_test)\n",
    "\n",
    "str(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1309 obs. of  11 variables:\n",
      " $ Survived: Factor w/ 2 levels \"X0\",\"X1\": 1 2 2 2 1 1 1 1 2 2 ...\n",
      " $ Pclass  : Factor w/ 3 levels \"X1\",\"X2\",\"X3\": 3 1 3 1 3 3 1 3 3 2 ...\n",
      " $ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 1 1 1 2 2 2 2 1 1 ...\n",
      " $ SibSp   : Factor w/ 7 levels \"X0\",\"X1\",\"X2\",..: 2 2 1 2 1 1 1 4 1 2 ...\n",
      " $ Parch   : Factor w/ 8 levels \"X0\",\"X1\",\"X2\",..: 1 1 1 1 1 1 1 2 3 1 ...\n",
      " $ Fare    : num  7.25 71.28 7.92 53.1 8.05 ...\n",
      " $ Embarked: Factor w/ 3 levels \"C\",\"Q\",\"S\": 3 1 3 3 3 2 3 3 3 1 ...\n",
      " $ Title   : Factor w/ 18 levels \"Capt\",\"Col\",\"Countess\",..: 14 15 11 15 14 14 14 10 15 15 ...\n",
      " $ AgeD    : Factor w/ 4 levels \"Bebé\",\"Niño\",..: 3 3 3 3 3 1 4 1 3 2 ...\n",
      " $ FamSize : Factor w/ 9 levels \"X1\",\"X11\",\"X2\",..: 3 3 1 3 1 1 1 6 4 3 ...\n",
      " $ Deck    : Factor w/ 8 levels \"A\",\"B\",\"C\",\"D\",..: NA 3 NA 3 NA NA 5 NA NA NA ...\n"
     ]
    }
   ],
   "source": [
    "df_train$Survived <- make.names(df_train$Survived)\n",
    "df_train$Survived[df_train$Survived == \"NA.\"] <- NA\n",
    "df_train$Survived <- as.factor(df_train$Survived)\n",
    "\n",
    "df_train$Pclass <- make.names(df_train$Pclass)\n",
    "df_train$Pclass[df_train$Pclass == \"NA.\"] <- NA\n",
    "df_train$Pclass <- as.factor(df_train$Pclass)\n",
    "\n",
    "df_train$Title <- gsub(\".*,\\\\s([a-zA-Z]+)..*\", \"\\\\1\", df_train$Name)\n",
    "idx <- which(df_train$Title == \"the\")\n",
    "df_train$Title[idx] <- 'Countess'\n",
    "df_train$Title <- make.names(df_train$Title)\n",
    "df_train$Title[df_train$Title == \"NA.\"] <- NA\n",
    "df_train$Title <- as.factor(df_train$Title)\n",
    "\n",
    "df_train$Sex <- make.names(df_train$Sex)\n",
    "df_train$Sex[df_train$Sex == \"NA.\"] <- NA\n",
    "df_train$Sex <- as.factor(df_train$Sex)\n",
    "\n",
    "df_train$AgeD <- \"Bebé\"\n",
    "df_train$AgeD[df_train$Age >= 3] <- \"Niño\"\n",
    "df_train$AgeD[df_train$Age >= 18] <- \"Adulto\"\n",
    "df_train$AgeD[df_train$Age >= 50] <- \"Anciano\"\n",
    "ages <- c(\"Bebé\", \"Niño\", \"Adulto\", \"Anciano\")\n",
    "df_train$AgeD <- make.names(df_train$AgeD)\n",
    "df_train$AgeD[df_train$AgeD == \"NA.\"] <- NA\n",
    "df_train$AgeD <- factor(df_train$AgeD, labels = ages, levels = ages)\n",
    "\n",
    "df_train$FamSize <- df_train$SibSp + df_train$Parch + 1\n",
    "df_train$FamSize <- make.names(df_train$FamSize)\n",
    "df_train$FamSize[df_train$FamSize == \"NA.\"] <- NA\n",
    "df_train$FamSize <- as.factor(df_train$FamSize)\n",
    "\n",
    "df_train$SibSp <- make.names(df_train$SibSp)\n",
    "df_train$SibSp[df_train$SibSp == \"NA.\"] <- NA\n",
    "df_train$SibSp <- as.factor(df_train$SibSp)\n",
    "\n",
    "df_train$Parch <- make.names(df_train$Parch)\n",
    "df_train$Parch[df_train$Parch == \"NA.\"] <- NA\n",
    "df_train$Parch <- as.factor(df_train$Parch)\n",
    "\n",
    "df_train$Fare[which(df_train$Fare == 0)] <- NA\n",
    "\n",
    "df_train$Deck <- substring(df_train$Cabin, 1, 1)\n",
    "df_train$Deck <- make.names(df_train$Deck)\n",
    "df_train$Deck[df_train$Deck == \"NA.\"] <- NA\n",
    "df_train$Deck <- as.factor(df_train$Deck)\n",
    "\n",
    "df_train$Embarked <- as.character(df_train$Embarked)\n",
    "df_train$Embarked <- make.names(df_train$Embarked)\n",
    "df_train$Embarked[df_train$Embarked == \"NA.\"] <- NA\n",
    "df_train$Embarked <- as.factor(df_train$Embarked)\n",
    "\n",
    "\n",
    "df_train[, c('PassengerId', 'Ticket', 'Name', 'Age', 'Cabin')] <- NULL\n",
    "\n",
    "\n",
    "str(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Pclass</th><th scope=col>Sex</th><th scope=col>SibSp</th><th scope=col>Parch</th><th scope=col>Title</th><th scope=col>AgeD</th><th scope=col>FamSize</th><th scope=col>Embarked</th><th scope=col>Fare</th><th scope=col>Survived</th><th scope=col>Deck</th><th scope=col></th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>199</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td> 1  </td><td>  1 </td><td>   1</td><td>   0</td></tr>\n",
       "\t<tr><th scope=row> 90</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td> 1  </td><td>  0 </td><td>   1</td><td>   1</td></tr>\n",
       "\t<tr><th scope=row>  3</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td> 0  </td><td>  1 </td><td>   1</td><td>   1</td></tr>\n",
       "\t<tr><th scope=row>  2</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>0   </td><td> 1  </td><td>  1 </td><td>   1</td><td>   1</td></tr>\n",
       "\t<tr><th scope=row>675</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td> 1  </td><td>  1 </td><td>   0</td><td>   1</td></tr>\n",
       "\t<tr><th scope=row>  1</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td> 0  </td><td>  0 </td><td>   1</td><td>   2</td></tr>\n",
       "\t<tr><th scope=row>325</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td> 1  </td><td>  0 </td><td>   0</td><td>   2</td></tr>\n",
       "\t<tr><th scope=row> 12</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td> 0  </td><td>  1 </td><td>   0</td><td>   2</td></tr>\n",
       "\t<tr><th scope=row>  2</th><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td>1   </td><td> 0  </td><td>  0 </td><td>   0</td><td>   3</td></tr>\n",
       "\t<tr><th scope=row></th><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>0   </td><td>2   </td><td>18  </td><td>418 </td><td>1014</td><td>1452</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       "  & Pclass & Sex & SibSp & Parch & Title & AgeD & FamSize & Embarked & Fare & Survived & Deck & \\\\\n",
       "\\hline\n",
       "\t199 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 1    &  1   &   1  &    1 &    0\\\\\n",
       "\t 90 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 1    &  1   &   0  &    1 &    1\\\\\n",
       "\t  3 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 1    &  0   &   1  &    1 &    1\\\\\n",
       "\t  2 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 0    &  1   &   1  &    1 &    1\\\\\n",
       "\t675 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 1    &  1   &   1  &    0 &    1\\\\\n",
       "\t  1 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 1    &  0   &   0  &    1 &    2\\\\\n",
       "\t325 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 1    &  1   &   0  &    0 &    2\\\\\n",
       "\t 12 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 1    &  0   &   1  &    0 &    2\\\\\n",
       "\t  2 & 1    & 1    & 1    & 1    & 1    & 1    & 1    & 1    &  0   &   0  &    0 &    3\\\\\n",
       "\t & 0    & 0    & 0    & 0    & 0    & 0    & 0    & 2    & 18   & 418  & 1014 & 1452\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Pclass | Sex | SibSp | Parch | Title | AgeD | FamSize | Embarked | Fare | Survived | Deck |  | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 199 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |  1   |   1  |    1 |    0 | \n",
       "|  90 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |  1   |   0  |    1 |    1 | \n",
       "|   3 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |  0   |   1  |    1 |    1 | \n",
       "|   2 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 0    |  1   |   1  |    1 |    1 | \n",
       "| 675 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |  1   |   1  |    0 |    1 | \n",
       "|   1 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |  0   |   0  |    1 |    2 | \n",
       "| 325 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |  1   |   0  |    0 |    2 | \n",
       "|  12 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |  0   |   1  |    0 |    2 | \n",
       "|   2 | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |  0   |   0  |    0 |    3 | \n",
       "|  | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 2    | 18   | 418  | 1014 | 1452 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    Pclass Sex SibSp Parch Title AgeD FamSize Embarked Fare Survived Deck     \n",
       "199 1      1   1     1     1     1    1       1         1     1         1    0\n",
       " 90 1      1   1     1     1     1    1       1         1     0         1    1\n",
       "  3 1      1   1     1     1     1    1       1         0     1         1    1\n",
       "  2 1      1   1     1     1     1    1       0         1     1         1    1\n",
       "675 1      1   1     1     1     1    1       1         1     1         0    1\n",
       "  1 1      1   1     1     1     1    1       1         0     0         1    2\n",
       "325 1      1   1     1     1     1    1       1         1     0         0    2\n",
       " 12 1      1   1     1     1     1    1       1         0     1         0    2\n",
       "  2 1      1   1     1     1     1    1       1         0     0         0    3\n",
       "    0      0   0     0     0     0    0       2        18   418      1014 1452"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAANlBMVEUAAAAAcrJNTU1oaGh8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\nXAoYXP8HWLtX7Y/GY1oAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "md.pattern(df_train)\n",
    "aggr(df_train, digits = 3, numbers = TRUE, labels = names(df_train), cex.axis = .5, cex.numbers = .6,\n",
    "       gap = 2, ylabs = c(\"Histograma de datos faltantes\", \"Patron de datos faltantes\"), col = c('#0072B2', '#D55E00'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " iter imp variable\n",
      "  1   1  Survived  Fare  Embarked  Deck\n",
      "  2   1  Survived  Fare  Embarked  Deck\n",
      "  3   1  Survived  Fare  Embarked  Deck\n",
      "  4   1  Survived  Fare  Embarked  Deck\n",
      "  5   1  Survived  Fare  Embarked  Deck\n",
      "  6   1  Survived  Fare  Embarked  Deck\n",
      "  7   1  Survived  Fare  Embarked  Deck\n",
      "  8   1  Survived  Fare  Embarked  Deck\n",
      "  9   1  Survived  Fare  Embarked  Deck\n",
      "  10   1  Survived  Fare  Embarked  Deck\n",
      "  11   1  Survived  Fare  Embarked  Deck\n",
      "  12   1  Survived  Fare  Embarked  Deck\n",
      "  13   1  Survived  Fare  Embarked  Deck\n",
      "  14   1  Survived  Fare  Embarked  Deck\n",
      "  15   1  Survived  Fare  Embarked  Deck\n",
      "  16   1  Survived  Fare  Embarked  Deck\n",
      "  17   1  Survived  Fare  Embarked  Deck\n",
      "  18   1  Survived  Fare  Embarked  Deck\n",
      "  19   1  Survived  Fare  Embarked  Deck\n",
      "  20   1  Survived  Fare  Embarked  Deck\n",
      "  21   1  Survived  Fare  Embarked  Deck\n",
      "  22   1  Survived  Fare  Embarked  Deck\n",
      "  23   1  Survived  Fare  Embarked  Deck\n",
      "  24   1  Survived  Fare  Embarked  Deck\n",
      "  25   1  Survived  Fare  Embarked  Deck\n",
      "  26   1  Survived  Fare  Embarked  Deck\n",
      "  27   1  Survived  Fare  Embarked  Deck\n",
      "  28   1  Survived  Fare  Embarked  Deck\n",
      "  29   1  Survived  Fare  Embarked  Deck\n",
      "  30   1  Survived  Fare  Embarked  Deck\n",
      "  31   1  Survived  Fare  Embarked  Deck\n",
      "  32   1  Survived  Fare  Embarked  Deck\n",
      "  33   1  Survived  Fare  Embarked  Deck\n",
      "  34   1  Survived  Fare  Embarked  Deck\n",
      "  35   1  Survived  Fare  Embarked  Deck\n",
      "  36   1  Survived  Fare  Embarked  Deck\n",
      "  37   1  Survived  Fare  Embarked  Deck\n",
      "  38   1  Survived  Fare  Embarked  Deck\n",
      "  39   1  Survived  Fare  Embarked  Deck\n",
      "  40   1  Survived  Fare  Embarked  Deck\n",
      "  41   1  Survived  Fare  Embarked  Deck\n",
      "  42   1  Survived  Fare  Embarked  Deck\n",
      "  43   1  Survived  Fare  Embarked  Deck\n",
      "  44   1  Survived  Fare  Embarked  Deck\n",
      "  45   1  Survived  Fare  Embarked  Deck\n",
      "  46   1  Survived  Fare  Embarked  Deck\n",
      "  47   1  Survived  Fare  Embarked  Deck\n",
      "  48   1  Survived  Fare  Embarked  Deck\n",
      "  49   1  Survived  Fare  Embarked  Deck\n",
      "  50   1  Survived  Fare  Embarked  Deck\n"
     ]
    }
   ],
   "source": [
    "tempData <- mice(df_train, m=1, maxit=50, meth='pmm', seed=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAM1BMVEUAAAAAcrJNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completedData <- complete(tempData,1)\n",
    "aggr(completedData, digits = 3, numbers = TRUE, labels = names(df_train), cex.axis = .5, cex.numbers = .6,\n",
    "       gap = 2, ylabs = c(\"Histograma de datos faltantes\", \"Patron de datos faltantes\"), col = c('#0072B2', '#D55E00'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset <- completedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "summary.resamples(object = boosting_results)\n",
       "\n",
       "Models: c5.0, gbm \n",
       "Number of resamples: 30 \n",
       "\n",
       "Accuracy \n",
       "       Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's\n",
       "c5.0 0.7923  0.8321 0.8506 0.8479  0.8623 0.9242    0\n",
       "gbm  0.7939  0.8171 0.8321 0.8418  0.8626 0.9008    0\n",
       "\n",
       "Kappa \n",
       "       Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's\n",
       "c5.0 0.5583  0.6395 0.6826 0.6794   0.708 0.8415    0\n",
       "gbm  0.5663  0.6218 0.6505 0.6681   0.708 0.7969    0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAY1BMVEUAAAAAgP9NRT5NTU1o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\nByjkBXWAQl5QByjkBXWAQl7+DwBlbYbs2HFiAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of Boosting Algorithms\n",
    "control <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n",
    "seed <- 7\n",
    "metric <- \"Accuracy\"\n",
    "# C5.0\n",
    "set.seed(seed)\n",
    "fit.c50 <- train(Survived~., data=dataset, method=\"C5.0\", metric=metric, trControl=control)\n",
    "# Stochastic Gradient Boosting\n",
    "set.seed(seed)\n",
    "fit.gbm <- train(Survived~., data=dataset, method=\"gbm\", metric=metric, trControl=control, verbose=FALSE)\n",
    "# summarize results\n",
    "boosting_results <- resamples(list(c5.0=fit.c50, gbm=fit.gbm))\n",
    "summary(boosting_results)\n",
    "dotplot(boosting_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultados algoritmos con boosting:\n",
    "c5.0: 84,79% <br>\n",
    "gbm: 84,18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "summary.resamples(object = bagging_results)\n",
       "\n",
       "Models: treebag, rf \n",
       "Number of resamples: 30 \n",
       "\n",
       "Accuracy \n",
       "          Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's\n",
       "treebag 0.7405  0.8015 0.8314 0.8246  0.8473 0.8779    0\n",
       "rf      0.7634  0.8234 0.8397 0.8352  0.8531 0.8855    0\n",
       "\n",
       "Kappa \n",
       "          Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's\n",
       "treebag 0.4580  0.5831 0.6505 0.6352  0.6789 0.7493    0\n",
       "rf      0.5103  0.6289 0.6625 0.6558  0.6901 0.7631    0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAY1BMVEUAAAAAgP9NRT5NTU1o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\nsGuGAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of Bagging algorithms\n",
    "control <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n",
    "seed <- 7\n",
    "metric <- \"Accuracy\"\n",
    "# Bagged CART\n",
    "set.seed(seed)\n",
    "fit.treebag <- train(Survived~., data=dataset, method=\"treebag\", metric=metric, trControl=control)\n",
    "# Random Forest\n",
    "set.seed(seed)\n",
    "fit.rf <- train(Survived~., data=dataset, method=\"rf\", metric=metric, trControl=control)\n",
    "# summarize results\n",
    "bagging_results <- resamples(list(treebag=fit.treebag, rf=fit.rf))\n",
    "summary(bagging_results)\n",
    "dotplot(bagging_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resultados algoritmos con bagging\n",
    "Treebag: 82,46%<br>\n",
    "Random Forest: 83,52% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking algorithms\n",
    "\n",
    "Creamos 5 submodelos:\n",
    "1. Linear Discriminate Analysis (LDA)\n",
    "2. Classification and Regression Trees (CART)\n",
    "3. Logistic Regression (via Generalized Linear Model or GLM)\n",
    "4. k-Nearest Neighbors (kNN)\n",
    "5. Support Vector Machine with a Radial Basis Kernel Function (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3029             nan     0.1000    0.0260\n",
      "     2        1.2584             nan     0.1000    0.0217\n",
      "     3        1.2239             nan     0.1000    0.0176\n",
      "     4        1.1949             nan     0.1000    0.0143\n",
      "     5        1.1704             nan     0.1000    0.0116\n",
      "     6        1.1520             nan     0.1000    0.0100\n",
      "     7        1.1336             nan     0.1000    0.0082\n",
      "     8        1.1211             nan     0.1000    0.0069\n",
      "     9        1.1090             nan     0.1000    0.0055\n",
      "    10        1.0997             nan     0.1000    0.0044\n",
      "    20        1.0362             nan     0.1000    0.0016\n",
      "    40        0.9816             nan     0.1000   -0.0000\n",
      "    60        0.9506             nan     0.1000   -0.0003\n",
      "    80        0.9317             nan     0.1000   -0.0001\n",
      "   100        0.9150             nan     0.1000   -0.0003\n",
      "   120        0.9028             nan     0.1000   -0.0013\n",
      "   140        0.8914             nan     0.1000   -0.0001\n",
      "   150        0.8867             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2934             nan     0.1000    0.0307\n",
      "     2        1.2414             nan     0.1000    0.0248\n",
      "     3        1.2011             nan     0.1000    0.0202\n",
      "     4        1.1674             nan     0.1000    0.0170\n",
      "     5        1.1369             nan     0.1000    0.0151\n",
      "     6        1.1087             nan     0.1000    0.0139\n",
      "     7        1.0864             nan     0.1000    0.0105\n",
      "     8        1.0656             nan     0.1000    0.0093\n",
      "     9        1.0486             nan     0.1000    0.0080\n",
      "    10        1.0327             nan     0.1000    0.0067\n",
      "    20        0.9500             nan     0.1000    0.0011\n",
      "    40        0.8813             nan     0.1000    0.0000\n",
      "    60        0.8389             nan     0.1000    0.0000\n",
      "    80        0.8120             nan     0.1000    0.0005\n",
      "   100        0.7941             nan     0.1000    0.0001\n",
      "   120        0.7795             nan     0.1000    0.0001\n",
      "   140        0.7669             nan     0.1000   -0.0008\n",
      "   150        0.7586             nan     0.1000   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2812             nan     0.1000    0.0351\n",
      "     2        1.2214             nan     0.1000    0.0254\n",
      "     3        1.1783             nan     0.1000    0.0203\n",
      "     4        1.1366             nan     0.1000    0.0186\n",
      "     5        1.1006             nan     0.1000    0.0141\n",
      "     6        1.0718             nan     0.1000    0.0130\n",
      "     7        1.0474             nan     0.1000    0.0101\n",
      "     8        1.0240             nan     0.1000    0.0108\n",
      "     9        1.0074             nan     0.1000    0.0062\n",
      "    10        0.9910             nan     0.1000    0.0086\n",
      "    20        0.9007             nan     0.1000    0.0011\n",
      "    40        0.8185             nan     0.1000   -0.0001\n",
      "    60        0.7701             nan     0.1000   -0.0000\n",
      "    80        0.7443             nan     0.1000   -0.0009\n",
      "   100        0.7215             nan     0.1000   -0.0006\n",
      "   120        0.7040             nan     0.1000   -0.0005\n",
      "   140        0.6883             nan     0.1000   -0.0003\n",
      "   150        0.6822             nan     0.1000   -0.0016\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2933             nan     0.1000    0.0278\n",
      "     2        1.2457             nan     0.1000    0.0222\n",
      "     3        1.2129             nan     0.1000    0.0173\n",
      "     4        1.1807             nan     0.1000    0.0137\n",
      "     5        1.1575             nan     0.1000    0.0115\n",
      "     6        1.1342             nan     0.1000    0.0107\n",
      "     7        1.1160             nan     0.1000    0.0089\n",
      "     8        1.1016             nan     0.1000    0.0062\n",
      "     9        1.0912             nan     0.1000    0.0061\n",
      "    10        1.0801             nan     0.1000    0.0050\n",
      "    20        1.0202             nan     0.1000    0.0009\n",
      "    40        0.9681             nan     0.1000    0.0003\n",
      "    60        0.9383             nan     0.1000    0.0001\n",
      "    80        0.9156             nan     0.1000    0.0003\n",
      "   100        0.8969             nan     0.1000   -0.0002\n",
      "   120        0.8828             nan     0.1000   -0.0003\n",
      "   140        0.8717             nan     0.1000   -0.0005\n",
      "   150        0.8668             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2894             nan     0.1000    0.0334\n",
      "     2        1.2346             nan     0.1000    0.0268\n",
      "     3        1.1923             nan     0.1000    0.0224\n",
      "     4        1.1544             nan     0.1000    0.0180\n",
      "     5        1.1216             nan     0.1000    0.0149\n",
      "     6        1.0943             nan     0.1000    0.0141\n",
      "     7        1.0721             nan     0.1000    0.0112\n",
      "     8        1.0553             nan     0.1000    0.0064\n",
      "     9        1.0356             nan     0.1000    0.0084\n",
      "    10        1.0199             nan     0.1000    0.0068\n",
      "    20        0.9476             nan     0.1000    0.0007\n",
      "    40        0.8700             nan     0.1000    0.0005\n",
      "    60        0.8290             nan     0.1000   -0.0001\n",
      "    80        0.7973             nan     0.1000   -0.0011\n",
      "   100        0.7711             nan     0.1000    0.0008\n",
      "   120        0.7518             nan     0.1000   -0.0004\n",
      "   140        0.7355             nan     0.1000   -0.0002\n",
      "   150        0.7299             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2782             nan     0.1000    0.0345\n",
      "     2        1.2204             nan     0.1000    0.0284\n",
      "     3        1.1728             nan     0.1000    0.0206\n",
      "     4        1.1332             nan     0.1000    0.0196\n",
      "     5        1.0943             nan     0.1000    0.0185\n",
      "     6        1.0675             nan     0.1000    0.0143\n",
      "     7        1.0437             nan     0.1000    0.0114\n",
      "     8        1.0204             nan     0.1000    0.0105\n",
      "     9        0.9992             nan     0.1000    0.0107\n",
      "    10        0.9814             nan     0.1000    0.0084\n",
      "    20        0.8789             nan     0.1000    0.0023\n",
      "    40        0.8048             nan     0.1000   -0.0008\n",
      "    60        0.7589             nan     0.1000    0.0001\n",
      "    80        0.7265             nan     0.1000   -0.0004\n",
      "   100        0.7044             nan     0.1000   -0.0000\n",
      "   120        0.6838             nan     0.1000   -0.0002\n",
      "   140        0.6650             nan     0.1000   -0.0016\n",
      "   150        0.6584             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2980             nan     0.1000    0.0285\n",
      "     2        1.2534             nan     0.1000    0.0223\n",
      "     3        1.2165             nan     0.1000    0.0192\n",
      "     4        1.1817             nan     0.1000    0.0157\n",
      "     5        1.1584             nan     0.1000    0.0129\n",
      "     6        1.1376             nan     0.1000    0.0106\n",
      "     7        1.1201             nan     0.1000    0.0093\n",
      "     8        1.1041             nan     0.1000    0.0074\n",
      "     9        1.0931             nan     0.1000    0.0061\n",
      "    10        1.0825             nan     0.1000    0.0054\n",
      "    20        1.0227             nan     0.1000    0.0001\n",
      "    40        0.9705             nan     0.1000    0.0006\n",
      "    60        0.9388             nan     0.1000   -0.0001\n",
      "    80        0.9152             nan     0.1000    0.0001\n",
      "   100        0.8973             nan     0.1000    0.0001\n",
      "   120        0.8819             nan     0.1000   -0.0012\n",
      "   140        0.8713             nan     0.1000   -0.0000\n",
      "   150        0.8653             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2863             nan     0.1000    0.0331\n",
      "     2        1.2377             nan     0.1000    0.0253\n",
      "     3        1.1914             nan     0.1000    0.0224\n",
      "     4        1.1534             nan     0.1000    0.0181\n",
      "     5        1.1226             nan     0.1000    0.0159\n",
      "     6        1.0976             nan     0.1000    0.0125\n",
      "     7        1.0745             nan     0.1000    0.0112\n",
      "     8        1.0549             nan     0.1000    0.0097\n",
      "     9        1.0373             nan     0.1000    0.0070\n",
      "    10        1.0217             nan     0.1000    0.0073\n",
      "    20        0.9357             nan     0.1000    0.0027\n",
      "    40        0.8616             nan     0.1000    0.0009\n",
      "    60        0.8224             nan     0.1000   -0.0010\n",
      "    80        0.7917             nan     0.1000    0.0004\n",
      "   100        0.7700             nan     0.1000   -0.0006\n",
      "   120        0.7536             nan     0.1000    0.0002\n",
      "   140        0.7380             nan     0.1000   -0.0006\n",
      "   150        0.7317             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2811             nan     0.1000    0.0339\n",
      "     2        1.2251             nan     0.1000    0.0287\n",
      "     3        1.1752             nan     0.1000    0.0229\n",
      "     4        1.1326             nan     0.1000    0.0205\n",
      "     5        1.0947             nan     0.1000    0.0174\n",
      "     6        1.0638             nan     0.1000    0.0152\n",
      "     7        1.0383             nan     0.1000    0.0118\n",
      "     8        1.0174             nan     0.1000    0.0104\n",
      "     9        0.9957             nan     0.1000    0.0098\n",
      "    10        0.9779             nan     0.1000    0.0083\n",
      "    20        0.8823             nan     0.1000    0.0015\n",
      "    40        0.7998             nan     0.1000    0.0012\n",
      "    60        0.7566             nan     0.1000   -0.0013\n",
      "    80        0.7257             nan     0.1000   -0.0002\n",
      "   100        0.7004             nan     0.1000   -0.0001\n",
      "   120        0.6816             nan     0.1000   -0.0013\n",
      "   140        0.6663             nan     0.1000   -0.0004\n",
      "   150        0.6566             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3025             nan     0.1000    0.0258\n",
      "     2        1.2635             nan     0.1000    0.0208\n",
      "     3        1.2258             nan     0.1000    0.0168\n",
      "     4        1.1946             nan     0.1000    0.0131\n",
      "     5        1.1724             nan     0.1000    0.0109\n",
      "     6        1.1536             nan     0.1000    0.0102\n",
      "     7        1.1345             nan     0.1000    0.0081\n",
      "     8        1.1189             nan     0.1000    0.0062\n",
      "     9        1.1086             nan     0.1000    0.0051\n",
      "    10        1.0997             nan     0.1000    0.0036\n",
      "    20        1.0390             nan     0.1000    0.0015\n",
      "    40        0.9914             nan     0.1000    0.0005\n",
      "    60        0.9609             nan     0.1000   -0.0001\n",
      "    80        0.9398             nan     0.1000   -0.0002\n",
      "   100        0.9208             nan     0.1000   -0.0007\n",
      "   120        0.9074             nan     0.1000   -0.0003\n",
      "   140        0.8968             nan     0.1000   -0.0003\n",
      "   150        0.8902             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2921             nan     0.1000    0.0310\n",
      "     2        1.2447             nan     0.1000    0.0245\n",
      "     3        1.2050             nan     0.1000    0.0212\n",
      "     4        1.1706             nan     0.1000    0.0164\n",
      "     5        1.1382             nan     0.1000    0.0148\n",
      "     6        1.1107             nan     0.1000    0.0119\n",
      "     7        1.0865             nan     0.1000    0.0092\n",
      "     8        1.0700             nan     0.1000    0.0078\n",
      "     9        1.0536             nan     0.1000    0.0078\n",
      "    10        1.0390             nan     0.1000    0.0069\n",
      "    20        0.9627             nan     0.1000    0.0021\n",
      "    40        0.8878             nan     0.1000    0.0008\n",
      "    60        0.8436             nan     0.1000    0.0004\n",
      "    80        0.8106             nan     0.1000    0.0004\n",
      "   100        0.7901             nan     0.1000   -0.0010\n",
      "   120        0.7692             nan     0.1000   -0.0013\n",
      "   140        0.7487             nan     0.1000   -0.0005\n",
      "   150        0.7407             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2821             nan     0.1000    0.0347\n",
      "     2        1.2271             nan     0.1000    0.0276\n",
      "     3        1.1783             nan     0.1000    0.0221\n",
      "     4        1.1414             nan     0.1000    0.0186\n",
      "     5        1.1087             nan     0.1000    0.0167\n",
      "     6        1.0825             nan     0.1000    0.0137\n",
      "     7        1.0571             nan     0.1000    0.0128\n",
      "     8        1.0341             nan     0.1000    0.0105\n",
      "     9        1.0154             nan     0.1000    0.0085\n",
      "    10        0.9977             nan     0.1000    0.0085\n",
      "    20        0.9004             nan     0.1000    0.0023\n",
      "    40        0.8208             nan     0.1000    0.0007\n",
      "    60        0.7808             nan     0.1000    0.0004\n",
      "    80        0.7505             nan     0.1000    0.0000\n",
      "   100        0.7245             nan     0.1000   -0.0009\n",
      "   120        0.6993             nan     0.1000   -0.0007\n",
      "   140        0.6776             nan     0.1000   -0.0021\n",
      "   150        0.6664             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2936             nan     0.1000    0.0289\n",
      "     2        1.2493             nan     0.1000    0.0228\n",
      "     3        1.2116             nan     0.1000    0.0187\n",
      "     4        1.1800             nan     0.1000    0.0157\n",
      "     5        1.1541             nan     0.1000    0.0129\n",
      "     6        1.1305             nan     0.1000    0.0111\n",
      "     7        1.1125             nan     0.1000    0.0089\n",
      "     8        1.0989             nan     0.1000    0.0075\n",
      "     9        1.0875             nan     0.1000    0.0064\n",
      "    10        1.0781             nan     0.1000    0.0052\n",
      "    20        1.0121             nan     0.1000    0.0019\n",
      "    40        0.9657             nan     0.1000    0.0002\n",
      "    60        0.9332             nan     0.1000    0.0002\n",
      "    80        0.9106             nan     0.1000    0.0003\n",
      "   100        0.8943             nan     0.1000   -0.0002\n",
      "   120        0.8791             nan     0.1000    0.0000\n",
      "   140        0.8677             nan     0.1000   -0.0001\n",
      "   150        0.8620             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2877             nan     0.1000    0.0329\n",
      "     2        1.2325             nan     0.1000    0.0254\n",
      "     3        1.1883             nan     0.1000    0.0204\n",
      "     4        1.1518             nan     0.1000    0.0196\n",
      "     5        1.1232             nan     0.1000    0.0159\n",
      "     6        1.0980             nan     0.1000    0.0126\n",
      "     7        1.0757             nan     0.1000    0.0108\n",
      "     8        1.0543             nan     0.1000    0.0100\n",
      "     9        1.0393             nan     0.1000    0.0080\n",
      "    10        1.0232             nan     0.1000    0.0074\n",
      "    20        0.9443             nan     0.1000    0.0019\n",
      "    40        0.8720             nan     0.1000    0.0004\n",
      "    60        0.8304             nan     0.1000   -0.0010\n",
      "    80        0.8065             nan     0.1000   -0.0013\n",
      "   100        0.7826             nan     0.1000    0.0008\n",
      "   120        0.7617             nan     0.1000   -0.0008\n",
      "   140        0.7467             nan     0.1000   -0.0004\n",
      "   150        0.7371             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2805             nan     0.1000    0.0368\n",
      "     2        1.2165             nan     0.1000    0.0294\n",
      "     3        1.1677             nan     0.1000    0.0244\n",
      "     4        1.1231             nan     0.1000    0.0186\n",
      "     5        1.0885             nan     0.1000    0.0165\n",
      "     6        1.0600             nan     0.1000    0.0140\n",
      "     7        1.0339             nan     0.1000    0.0120\n",
      "     8        1.0111             nan     0.1000    0.0095\n",
      "     9        0.9931             nan     0.1000    0.0086\n",
      "    10        0.9766             nan     0.1000    0.0076\n",
      "    20        0.8831             nan     0.1000    0.0028\n",
      "    40        0.8030             nan     0.1000    0.0001\n",
      "    60        0.7610             nan     0.1000    0.0002\n",
      "    80        0.7338             nan     0.1000   -0.0007\n",
      "   100        0.7084             nan     0.1000   -0.0000\n",
      "   120        0.6864             nan     0.1000   -0.0003\n",
      "   140        0.6730             nan     0.1000   -0.0009\n",
      "   150        0.6633             nan     0.1000   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.1000    0.0278\n",
      "     2        1.2585             nan     0.1000    0.0235\n",
      "     3        1.2196             nan     0.1000    0.0191\n",
      "     4        1.1860             nan     0.1000    0.0153\n",
      "     5        1.1581             nan     0.1000    0.0127\n",
      "     6        1.1379             nan     0.1000    0.0106\n",
      "     7        1.1214             nan     0.1000    0.0088\n",
      "     8        1.1081             nan     0.1000    0.0074\n",
      "     9        1.0934             nan     0.1000    0.0061\n",
      "    10        1.0834             nan     0.1000    0.0050\n",
      "    20        1.0236             nan     0.1000    0.0002\n",
      "    40        0.9736             nan     0.1000   -0.0000\n",
      "    60        0.9429             nan     0.1000   -0.0005\n",
      "    80        0.9229             nan     0.1000   -0.0001\n",
      "   100        0.9034             nan     0.1000   -0.0002\n",
      "   120        0.8885             nan     0.1000   -0.0001\n",
      "   140        0.8767             nan     0.1000   -0.0002\n",
      "   150        0.8711             nan     0.1000    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2879             nan     0.1000    0.0333\n",
      "     2        1.2383             nan     0.1000    0.0245\n",
      "     3        1.1944             nan     0.1000    0.0217\n",
      "     4        1.1577             nan     0.1000    0.0176\n",
      "     5        1.1256             nan     0.1000    0.0153\n",
      "     6        1.0975             nan     0.1000    0.0114\n",
      "     7        1.0746             nan     0.1000    0.0106\n",
      "     8        1.0549             nan     0.1000    0.0088\n",
      "     9        1.0394             nan     0.1000    0.0069\n",
      "    10        1.0250             nan     0.1000    0.0069\n",
      "    20        0.9522             nan     0.1000    0.0027\n",
      "    40        0.8875             nan     0.1000    0.0001\n",
      "    60        0.8481             nan     0.1000   -0.0005\n",
      "    80        0.8180             nan     0.1000   -0.0004\n",
      "   100        0.7930             nan     0.1000    0.0003\n",
      "   120        0.7726             nan     0.1000    0.0002\n",
      "   140        0.7556             nan     0.1000   -0.0008\n",
      "   150        0.7446             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2778             nan     0.1000    0.0350\n",
      "     2        1.2232             nan     0.1000    0.0281\n",
      "     3        1.1795             nan     0.1000    0.0230\n",
      "     4        1.1365             nan     0.1000    0.0200\n",
      "     5        1.1007             nan     0.1000    0.0170\n",
      "     6        1.0733             nan     0.1000    0.0144\n",
      "     7        1.0472             nan     0.1000    0.0114\n",
      "     8        1.0261             nan     0.1000    0.0101\n",
      "     9        1.0063             nan     0.1000    0.0094\n",
      "    10        0.9896             nan     0.1000    0.0075\n",
      "    20        0.8941             nan     0.1000    0.0007\n",
      "    40        0.8165             nan     0.1000   -0.0002\n",
      "    60        0.7758             nan     0.1000   -0.0007\n",
      "    80        0.7389             nan     0.1000   -0.0005\n",
      "   100        0.7170             nan     0.1000   -0.0003\n",
      "   120        0.6941             nan     0.1000   -0.0015\n",
      "   140        0.6778             nan     0.1000   -0.0001\n",
      "   150        0.6710             nan     0.1000    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2966             nan     0.1000    0.0281\n",
      "     2        1.2516             nan     0.1000    0.0230\n",
      "     3        1.2124             nan     0.1000    0.0186\n",
      "     4        1.1801             nan     0.1000    0.0154\n",
      "     5        1.1524             nan     0.1000    0.0125\n",
      "     6        1.1318             nan     0.1000    0.0104\n",
      "     7        1.1138             nan     0.1000    0.0089\n",
      "     8        1.0992             nan     0.1000    0.0071\n",
      "     9        1.0875             nan     0.1000    0.0057\n",
      "    10        1.0761             nan     0.1000    0.0051\n",
      "    20        1.0142             nan     0.1000    0.0017\n",
      "    40        0.9613             nan     0.1000    0.0007\n",
      "    60        0.9324             nan     0.1000   -0.0005\n",
      "    80        0.9116             nan     0.1000   -0.0001\n",
      "   100        0.8937             nan     0.1000   -0.0005\n",
      "   120        0.8779             nan     0.1000   -0.0003\n",
      "   140        0.8664             nan     0.1000   -0.0007\n",
      "   150        0.8626             nan     0.1000   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2899             nan     0.1000    0.0315\n",
      "     2        1.2351             nan     0.1000    0.0256\n",
      "     3        1.1925             nan     0.1000    0.0201\n",
      "     4        1.1529             nan     0.1000    0.0180\n",
      "     5        1.1194             nan     0.1000    0.0162\n",
      "     6        1.0940             nan     0.1000    0.0117\n",
      "     7        1.0702             nan     0.1000    0.0117\n",
      "     8        1.0512             nan     0.1000    0.0091\n",
      "     9        1.0327             nan     0.1000    0.0072\n",
      "    10        1.0186             nan     0.1000    0.0080\n",
      "    20        0.9407             nan     0.1000    0.0021\n",
      "    40        0.8670             nan     0.1000   -0.0000\n",
      "    60        0.8278             nan     0.1000   -0.0000\n",
      "    80        0.7961             nan     0.1000   -0.0000\n",
      "   100        0.7696             nan     0.1000   -0.0005\n",
      "   120        0.7487             nan     0.1000    0.0002\n",
      "   140        0.7322             nan     0.1000   -0.0006\n",
      "   150        0.7241             nan     0.1000   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2762             nan     0.1000    0.0341\n",
      "     2        1.2154             nan     0.1000    0.0285\n",
      "     3        1.1663             nan     0.1000    0.0230\n",
      "     4        1.1257             nan     0.1000    0.0188\n",
      "     5        1.0919             nan     0.1000    0.0167\n",
      "     6        1.0636             nan     0.1000    0.0149\n",
      "     7        1.0373             nan     0.1000    0.0119\n",
      "     8        1.0143             nan     0.1000    0.0107\n",
      "     9        0.9936             nan     0.1000    0.0086\n",
      "    10        0.9758             nan     0.1000    0.0077\n",
      "    20        0.8820             nan     0.1000    0.0031\n",
      "    40        0.8099             nan     0.1000    0.0021\n",
      "    60        0.7627             nan     0.1000   -0.0000\n",
      "    80        0.7254             nan     0.1000   -0.0007\n",
      "   100        0.6986             nan     0.1000    0.0000\n",
      "   120        0.6786             nan     0.1000   -0.0012\n",
      "   140        0.6601             nan     0.1000   -0.0004\n",
      "   150        0.6524             nan     0.1000   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2968             nan     0.1000    0.0275\n",
      "     2        1.2556             nan     0.1000    0.0217\n",
      "     3        1.2186             nan     0.1000    0.0187\n",
      "     4        1.1890             nan     0.1000    0.0149\n",
      "     5        1.1615             nan     0.1000    0.0129\n",
      "     6        1.1397             nan     0.1000    0.0105\n",
      "     7        1.1217             nan     0.1000    0.0085\n",
      "     8        1.1077             nan     0.1000    0.0069\n",
      "     9        1.0956             nan     0.1000    0.0056\n",
      "    10        1.0829             nan     0.1000    0.0052\n",
      "    20        1.0150             nan     0.1000    0.0011\n",
      "    40        0.9601             nan     0.1000    0.0004\n",
      "    60        0.9290             nan     0.1000    0.0001\n",
      "    80        0.9074             nan     0.1000   -0.0000\n",
      "   100        0.8910             nan     0.1000   -0.0007\n",
      "   120        0.8759             nan     0.1000   -0.0005\n",
      "   140        0.8625             nan     0.1000   -0.0012\n",
      "   150        0.8573             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2874             nan     0.1000    0.0329\n",
      "     2        1.2336             nan     0.1000    0.0262\n",
      "     3        1.1894             nan     0.1000    0.0227\n",
      "     4        1.1525             nan     0.1000    0.0185\n",
      "     5        1.1218             nan     0.1000    0.0150\n",
      "     6        1.0958             nan     0.1000    0.0138\n",
      "     7        1.0718             nan     0.1000    0.0099\n",
      "     8        1.0539             nan     0.1000    0.0081\n",
      "     9        1.0357             nan     0.1000    0.0066\n",
      "    10        1.0217             nan     0.1000    0.0071\n",
      "    20        0.9381             nan     0.1000    0.0015\n",
      "    40        0.8610             nan     0.1000    0.0008\n",
      "    60        0.8224             nan     0.1000    0.0005\n",
      "    80        0.7885             nan     0.1000   -0.0019\n",
      "   100        0.7649             nan     0.1000   -0.0004\n",
      "   120        0.7490             nan     0.1000   -0.0009\n",
      "   140        0.7326             nan     0.1000   -0.0006\n",
      "   150        0.7265             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2772             nan     0.1000    0.0379\n",
      "     2        1.2137             nan     0.1000    0.0296\n",
      "     3        1.1669             nan     0.1000    0.0231\n",
      "     4        1.1262             nan     0.1000    0.0195\n",
      "     5        1.0931             nan     0.1000    0.0166\n",
      "     6        1.0608             nan     0.1000    0.0149\n",
      "     7        1.0360             nan     0.1000    0.0121\n",
      "     8        1.0130             nan     0.1000    0.0109\n",
      "     9        0.9945             nan     0.1000    0.0095\n",
      "    10        0.9758             nan     0.1000    0.0076\n",
      "    20        0.8741             nan     0.1000    0.0041\n",
      "    40        0.7969             nan     0.1000   -0.0004\n",
      "    60        0.7586             nan     0.1000   -0.0005\n",
      "    80        0.7234             nan     0.1000    0.0004\n",
      "   100        0.6978             nan     0.1000   -0.0003\n",
      "   120        0.6784             nan     0.1000   -0.0005\n",
      "   140        0.6619             nan     0.1000   -0.0007\n",
      "   150        0.6544             nan     0.1000   -0.0015\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2998             nan     0.1000    0.0267\n",
      "     2        1.2581             nan     0.1000    0.0214\n",
      "     3        1.2212             nan     0.1000    0.0170\n",
      "     4        1.1912             nan     0.1000    0.0141\n",
      "     5        1.1680             nan     0.1000    0.0120\n",
      "     6        1.1484             nan     0.1000    0.0097\n",
      "     7        1.1325             nan     0.1000    0.0082\n",
      "     8        1.1222             nan     0.1000    0.0043\n",
      "     9        1.1066             nan     0.1000    0.0064\n",
      "    10        1.0939             nan     0.1000    0.0050\n",
      "    20        1.0352             nan     0.1000    0.0003\n",
      "    40        0.9822             nan     0.1000    0.0003\n",
      "    60        0.9504             nan     0.1000    0.0002\n",
      "    80        0.9291             nan     0.1000    0.0002\n",
      "   100        0.9108             nan     0.1000    0.0001\n",
      "   120        0.8958             nan     0.1000   -0.0015\n",
      "   140        0.8843             nan     0.1000   -0.0005\n",
      "   150        0.8787             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2918             nan     0.1000    0.0309\n",
      "     2        1.2416             nan     0.1000    0.0234\n",
      "     3        1.2031             nan     0.1000    0.0174\n",
      "     4        1.1648             nan     0.1000    0.0194\n",
      "     5        1.1349             nan     0.1000    0.0154\n",
      "     6        1.1113             nan     0.1000    0.0112\n",
      "     7        1.0881             nan     0.1000    0.0100\n",
      "     8        1.0691             nan     0.1000    0.0078\n",
      "     9        1.0511             nan     0.1000    0.0080\n",
      "    10        1.0394             nan     0.1000    0.0058\n",
      "    20        0.9624             nan     0.1000    0.0013\n",
      "    40        0.8904             nan     0.1000    0.0001\n",
      "    60        0.8427             nan     0.1000   -0.0007\n",
      "    80        0.8139             nan     0.1000   -0.0000\n",
      "   100        0.7865             nan     0.1000   -0.0005\n",
      "   120        0.7638             nan     0.1000   -0.0002\n",
      "   140        0.7470             nan     0.1000   -0.0004\n",
      "   150        0.7427             nan     0.1000   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2849             nan     0.1000    0.0368\n",
      "     2        1.2295             nan     0.1000    0.0272\n",
      "     3        1.1854             nan     0.1000    0.0217\n",
      "     4        1.1412             nan     0.1000    0.0206\n",
      "     5        1.1056             nan     0.1000    0.0159\n",
      "     6        1.0765             nan     0.1000    0.0142\n",
      "     7        1.0533             nan     0.1000    0.0113\n",
      "     8        1.0310             nan     0.1000    0.0104\n",
      "     9        1.0095             nan     0.1000    0.0091\n",
      "    10        0.9945             nan     0.1000    0.0068\n",
      "    20        0.8969             nan     0.1000    0.0032\n",
      "    40        0.8174             nan     0.1000    0.0001\n",
      "    60        0.7720             nan     0.1000   -0.0003\n",
      "    80        0.7364             nan     0.1000   -0.0002\n",
      "   100        0.7103             nan     0.1000   -0.0009\n",
      "   120        0.6878             nan     0.1000   -0.0007\n",
      "   140        0.6698             nan     0.1000   -0.0010\n",
      "   150        0.6625             nan     0.1000   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3018             nan     0.1000    0.0269\n",
      "     2        1.2550             nan     0.1000    0.0212\n",
      "     3        1.2159             nan     0.1000    0.0201\n",
      "     4        1.1850             nan     0.1000    0.0163\n",
      "     5        1.1561             nan     0.1000    0.0134\n",
      "     6        1.1332             nan     0.1000    0.0110\n",
      "     7        1.1146             nan     0.1000    0.0090\n",
      "     8        1.0991             nan     0.1000    0.0070\n",
      "     9        1.0869             nan     0.1000    0.0061\n",
      "    10        1.0781             nan     0.1000    0.0037\n",
      "    20        1.0185             nan     0.1000    0.0022\n",
      "    40        0.9668             nan     0.1000    0.0006\n",
      "    60        0.9334             nan     0.1000    0.0002\n",
      "    80        0.9138             nan     0.1000    0.0002\n",
      "   100        0.8931             nan     0.1000   -0.0009\n",
      "   120        0.8794             nan     0.1000    0.0000\n",
      "   140        0.8672             nan     0.1000   -0.0001\n",
      "   150        0.8616             nan     0.1000   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2904             nan     0.1000    0.0326\n",
      "     2        1.2386             nan     0.1000    0.0259\n",
      "     3        1.1960             nan     0.1000    0.0217\n",
      "     4        1.1576             nan     0.1000    0.0181\n",
      "     5        1.1268             nan     0.1000    0.0162\n",
      "     6        1.1014             nan     0.1000    0.0129\n",
      "     7        1.0772             nan     0.1000    0.0120\n",
      "     8        1.0572             nan     0.1000    0.0093\n",
      "     9        1.0406             nan     0.1000    0.0080\n",
      "    10        1.0228             nan     0.1000    0.0081\n",
      "    20        0.9446             nan     0.1000    0.0016\n",
      "    40        0.8722             nan     0.1000   -0.0007\n",
      "    60        0.8192             nan     0.1000    0.0005\n",
      "    80        0.7933             nan     0.1000    0.0003\n",
      "   100        0.7670             nan     0.1000   -0.0002\n",
      "   120        0.7473             nan     0.1000   -0.0001\n",
      "   140        0.7273             nan     0.1000   -0.0010\n",
      "   150        0.7204             nan     0.1000   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2850             nan     0.1000    0.0347\n",
      "     2        1.2261             nan     0.1000    0.0280\n",
      "     3        1.1809             nan     0.1000    0.0241\n",
      "     4        1.1429             nan     0.1000    0.0199\n",
      "     5        1.1098             nan     0.1000    0.0165\n",
      "     6        1.0730             nan     0.1000    0.0160\n",
      "     7        1.0471             nan     0.1000    0.0118\n",
      "     8        1.0208             nan     0.1000    0.0117\n",
      "     9        0.9989             nan     0.1000    0.0099\n",
      "    10        0.9798             nan     0.1000    0.0085\n",
      "    20        0.8905             nan     0.1000    0.0021\n",
      "    40        0.8102             nan     0.1000   -0.0002\n",
      "    60        0.7634             nan     0.1000   -0.0003\n",
      "    80        0.7276             nan     0.1000   -0.0009\n",
      "   100        0.7016             nan     0.1000   -0.0002\n",
      "   120        0.6812             nan     0.1000   -0.0008\n",
      "   140        0.6609             nan     0.1000   -0.0017\n",
      "   150        0.6540             nan     0.1000   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2954             nan     0.1000    0.0277\n",
      "     2        1.2458             nan     0.1000    0.0210\n",
      "     3        1.2099             nan     0.1000    0.0175\n",
      "     4        1.1779             nan     0.1000    0.0143\n",
      "     5        1.1557             nan     0.1000    0.0117\n",
      "     6        1.1340             nan     0.1000    0.0092\n",
      "     7        1.1184             nan     0.1000    0.0081\n",
      "     8        1.1055             nan     0.1000    0.0065\n",
      "     9        1.0939             nan     0.1000    0.0054\n",
      "    10        1.0842             nan     0.1000    0.0046\n",
      "    20        1.0259             nan     0.1000    0.0011\n",
      "    40        0.9811             nan     0.1000    0.0000\n",
      "    60        0.9550             nan     0.1000   -0.0003\n",
      "    80        0.9320             nan     0.1000    0.0004\n",
      "   100        0.9152             nan     0.1000   -0.0004\n",
      "   120        0.9013             nan     0.1000   -0.0002\n",
      "   140        0.8900             nan     0.1000   -0.0005\n",
      "   150        0.8839             nan     0.1000    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2883             nan     0.1000    0.0303\n",
      "     2        1.2331             nan     0.1000    0.0252\n",
      "     3        1.1897             nan     0.1000    0.0195\n",
      "     4        1.1531             nan     0.1000    0.0165\n",
      "     5        1.1255             nan     0.1000    0.0154\n",
      "     6        1.0993             nan     0.1000    0.0127\n",
      "     7        1.0794             nan     0.1000    0.0103\n",
      "     8        1.0603             nan     0.1000    0.0082\n",
      "     9        1.0455             nan     0.1000    0.0084\n",
      "    10        1.0310             nan     0.1000    0.0069\n",
      "    20        0.9521             nan     0.1000    0.0016\n",
      "    40        0.8781             nan     0.1000    0.0007\n",
      "    60        0.8419             nan     0.1000   -0.0002\n",
      "    80        0.8131             nan     0.1000   -0.0009\n",
      "   100        0.7903             nan     0.1000   -0.0000\n",
      "   120        0.7728             nan     0.1000   -0.0007\n",
      "   140        0.7563             nan     0.1000   -0.0003\n",
      "   150        0.7486             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2827             nan     0.1000    0.0359\n",
      "     2        1.2266             nan     0.1000    0.0279\n",
      "     3        1.1798             nan     0.1000    0.0245\n",
      "     4        1.1398             nan     0.1000    0.0199\n",
      "     5        1.1014             nan     0.1000    0.0181\n",
      "     6        1.0730             nan     0.1000    0.0133\n",
      "     7        1.0463             nan     0.1000    0.0122\n",
      "     8        1.0220             nan     0.1000    0.0116\n",
      "     9        1.0028             nan     0.1000    0.0090\n",
      "    10        0.9838             nan     0.1000    0.0082\n",
      "    20        0.8929             nan     0.1000    0.0024\n",
      "    40        0.8131             nan     0.1000    0.0003\n",
      "    60        0.7705             nan     0.1000   -0.0007\n",
      "    80        0.7426             nan     0.1000   -0.0007\n",
      "   100        0.7167             nan     0.1000   -0.0015\n",
      "   120        0.6925             nan     0.1000   -0.0001\n",
      "   140        0.6749             nan     0.1000   -0.0009\n",
      "   150        0.6684             nan     0.1000   -0.0015\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2907             nan     0.1000    0.0282\n",
      "     2        1.2435             nan     0.1000    0.0223\n",
      "     3        1.2048             nan     0.1000    0.0189\n",
      "     4        1.1711             nan     0.1000    0.0143\n",
      "     5        1.1455             nan     0.1000    0.0126\n",
      "     6        1.1263             nan     0.1000    0.0103\n",
      "     7        1.1088             nan     0.1000    0.0085\n",
      "     8        1.0983             nan     0.1000    0.0042\n",
      "     9        1.0850             nan     0.1000    0.0070\n",
      "    10        1.0738             nan     0.1000    0.0058\n",
      "    20        1.0044             nan     0.1000    0.0017\n",
      "    40        0.9520             nan     0.1000    0.0004\n",
      "    60        0.9219             nan     0.1000    0.0000\n",
      "    80        0.8999             nan     0.1000   -0.0000\n",
      "   100        0.8832             nan     0.1000   -0.0001\n",
      "   120        0.8706             nan     0.1000   -0.0004\n",
      "   140        0.8594             nan     0.1000   -0.0005\n",
      "   150        0.8541             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2890             nan     0.1000    0.0303\n",
      "     2        1.2303             nan     0.1000    0.0277\n",
      "     3        1.1884             nan     0.1000    0.0216\n",
      "     4        1.1525             nan     0.1000    0.0173\n",
      "     5        1.1189             nan     0.1000    0.0167\n",
      "     6        1.0908             nan     0.1000    0.0125\n",
      "     7        1.0689             nan     0.1000    0.0114\n",
      "     8        1.0521             nan     0.1000    0.0077\n",
      "     9        1.0346             nan     0.1000    0.0089\n",
      "    10        1.0195             nan     0.1000    0.0063\n",
      "    20        0.9327             nan     0.1000    0.0020\n",
      "    40        0.8586             nan     0.1000    0.0011\n",
      "    60        0.8181             nan     0.1000    0.0001\n",
      "    80        0.7900             nan     0.1000    0.0000\n",
      "   100        0.7703             nan     0.1000   -0.0006\n",
      "   120        0.7523             nan     0.1000   -0.0001\n",
      "   140        0.7336             nan     0.1000   -0.0004\n",
      "   150        0.7241             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2790             nan     0.1000    0.0363\n",
      "     2        1.2244             nan     0.1000    0.0291\n",
      "     3        1.1720             nan     0.1000    0.0256\n",
      "     4        1.1332             nan     0.1000    0.0193\n",
      "     5        1.0977             nan     0.1000    0.0167\n",
      "     6        1.0644             nan     0.1000    0.0148\n",
      "     7        1.0356             nan     0.1000    0.0133\n",
      "     8        1.0121             nan     0.1000    0.0104\n",
      "     9        0.9924             nan     0.1000    0.0086\n",
      "    10        0.9751             nan     0.1000    0.0068\n",
      "    20        0.8724             nan     0.1000    0.0013\n",
      "    40        0.7916             nan     0.1000    0.0001\n",
      "    60        0.7476             nan     0.1000   -0.0004\n",
      "    80        0.7166             nan     0.1000   -0.0001\n",
      "   100        0.6945             nan     0.1000   -0.0008\n",
      "   120        0.6724             nan     0.1000   -0.0008\n",
      "   140        0.6517             nan     0.1000   -0.0002\n",
      "   150        0.6448             nan     0.1000   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2973             nan     0.1000    0.0278\n",
      "     2        1.2536             nan     0.1000    0.0225\n",
      "     3        1.2187             nan     0.1000    0.0188\n",
      "     4        1.1857             nan     0.1000    0.0161\n",
      "     5        1.1600             nan     0.1000    0.0128\n",
      "     6        1.1391             nan     0.1000    0.0106\n",
      "     7        1.1219             nan     0.1000    0.0092\n",
      "     8        1.1078             nan     0.1000    0.0077\n",
      "     9        1.0932             nan     0.1000    0.0063\n",
      "    10        1.0809             nan     0.1000    0.0049\n",
      "    20        1.0218             nan     0.1000    0.0004\n",
      "    40        0.9740             nan     0.1000    0.0001\n",
      "    60        0.9401             nan     0.1000    0.0002\n",
      "    80        0.9159             nan     0.1000   -0.0001\n",
      "   100        0.8968             nan     0.1000   -0.0000\n",
      "   120        0.8837             nan     0.1000   -0.0001\n",
      "   140        0.8722             nan     0.1000   -0.0001\n",
      "   150        0.8657             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2868             nan     0.1000    0.0341\n",
      "     2        1.2341             nan     0.1000    0.0247\n",
      "     3        1.1885             nan     0.1000    0.0204\n",
      "     4        1.1513             nan     0.1000    0.0177\n",
      "     5        1.1212             nan     0.1000    0.0144\n",
      "     6        1.0958             nan     0.1000    0.0127\n",
      "     7        1.0733             nan     0.1000    0.0105\n",
      "     8        1.0537             nan     0.1000    0.0083\n",
      "     9        1.0403             nan     0.1000    0.0072\n",
      "    10        1.0245             nan     0.1000    0.0072\n",
      "    20        0.9431             nan     0.1000    0.0029\n",
      "    40        0.8697             nan     0.1000    0.0015\n",
      "    60        0.8186             nan     0.1000    0.0002\n",
      "    80        0.7893             nan     0.1000   -0.0001\n",
      "   100        0.7679             nan     0.1000   -0.0004\n",
      "   120        0.7466             nan     0.1000   -0.0010\n",
      "   140        0.7318             nan     0.1000    0.0002\n",
      "   150        0.7242             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2841             nan     0.1000    0.0357\n",
      "     2        1.2216             nan     0.1000    0.0306\n",
      "     3        1.1764             nan     0.1000    0.0215\n",
      "     4        1.1340             nan     0.1000    0.0205\n",
      "     5        1.0979             nan     0.1000    0.0168\n",
      "     6        1.0684             nan     0.1000    0.0149\n",
      "     7        1.0435             nan     0.1000    0.0116\n",
      "     8        1.0231             nan     0.1000    0.0113\n",
      "     9        1.0050             nan     0.1000    0.0089\n",
      "    10        0.9873             nan     0.1000    0.0080\n",
      "    20        0.8881             nan     0.1000    0.0021\n",
      "    40        0.8037             nan     0.1000    0.0012\n",
      "    60        0.7555             nan     0.1000    0.0007\n",
      "    80        0.7214             nan     0.1000    0.0005\n",
      "   100        0.6952             nan     0.1000   -0.0007\n",
      "   120        0.6770             nan     0.1000   -0.0007\n",
      "   140        0.6614             nan     0.1000   -0.0012\n",
      "   150        0.6538             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3017             nan     0.1000    0.0254\n",
      "     2        1.2559             nan     0.1000    0.0215\n",
      "     3        1.2211             nan     0.1000    0.0166\n",
      "     4        1.1895             nan     0.1000    0.0143\n",
      "     5        1.1673             nan     0.1000    0.0106\n",
      "     6        1.1514             nan     0.1000    0.0097\n",
      "     7        1.1350             nan     0.1000    0.0085\n",
      "     8        1.1211             nan     0.1000    0.0071\n",
      "     9        1.1106             nan     0.1000    0.0058\n",
      "    10        1.1003             nan     0.1000    0.0047\n",
      "    20        1.0376             nan     0.1000    0.0012\n",
      "    40        0.9859             nan     0.1000    0.0005\n",
      "    60        0.9553             nan     0.1000    0.0001\n",
      "    80        0.9320             nan     0.1000    0.0001\n",
      "   100        0.9153             nan     0.1000    0.0000\n",
      "   120        0.9002             nan     0.1000    0.0001\n",
      "   140        0.8890             nan     0.1000   -0.0001\n",
      "   150        0.8838             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2915             nan     0.1000    0.0305\n",
      "     2        1.2426             nan     0.1000    0.0244\n",
      "     3        1.2006             nan     0.1000    0.0213\n",
      "     4        1.1663             nan     0.1000    0.0177\n",
      "     5        1.1372             nan     0.1000    0.0146\n",
      "     6        1.1121             nan     0.1000    0.0130\n",
      "     7        1.0869             nan     0.1000    0.0108\n",
      "     8        1.0689             nan     0.1000    0.0088\n",
      "     9        1.0526             nan     0.1000    0.0070\n",
      "    10        1.0386             nan     0.1000    0.0058\n",
      "    20        0.9620             nan     0.1000    0.0022\n",
      "    40        0.8918             nan     0.1000    0.0000\n",
      "    60        0.8475             nan     0.1000    0.0001\n",
      "    80        0.8207             nan     0.1000   -0.0004\n",
      "   100        0.7948             nan     0.1000    0.0004\n",
      "   120        0.7758             nan     0.1000   -0.0003\n",
      "   140        0.7566             nan     0.1000   -0.0003\n",
      "   150        0.7475             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2857             nan     0.1000    0.0345\n",
      "     2        1.2305             nan     0.1000    0.0248\n",
      "     3        1.1839             nan     0.1000    0.0209\n",
      "     4        1.1437             nan     0.1000    0.0198\n",
      "     5        1.1085             nan     0.1000    0.0155\n",
      "     6        1.0802             nan     0.1000    0.0137\n",
      "     7        1.0539             nan     0.1000    0.0122\n",
      "     8        1.0360             nan     0.1000    0.0071\n",
      "     9        1.0197             nan     0.1000    0.0078\n",
      "    10        1.0003             nan     0.1000    0.0081\n",
      "    20        0.9053             nan     0.1000    0.0024\n",
      "    40        0.8244             nan     0.1000    0.0009\n",
      "    60        0.7803             nan     0.1000   -0.0002\n",
      "    80        0.7510             nan     0.1000   -0.0007\n",
      "   100        0.7261             nan     0.1000   -0.0004\n",
      "   120        0.7052             nan     0.1000   -0.0007\n",
      "   140        0.6854             nan     0.1000   -0.0008\n",
      "   150        0.6764             nan     0.1000   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2984             nan     0.1000    0.0281\n",
      "     2        1.2509             nan     0.1000    0.0211\n",
      "     3        1.2125             nan     0.1000    0.0187\n",
      "     4        1.1786             nan     0.1000    0.0149\n",
      "     5        1.1548             nan     0.1000    0.0122\n",
      "     6        1.1343             nan     0.1000    0.0095\n",
      "     7        1.1151             nan     0.1000    0.0084\n",
      "     8        1.0997             nan     0.1000    0.0067\n",
      "     9        1.0894             nan     0.1000    0.0047\n",
      "    10        1.0772             nan     0.1000    0.0054\n",
      "    20        1.0139             nan     0.1000    0.0010\n",
      "    40        0.9631             nan     0.1000    0.0005\n",
      "    60        0.9309             nan     0.1000    0.0004\n",
      "    80        0.9072             nan     0.1000    0.0001\n",
      "   100        0.8921             nan     0.1000   -0.0005\n",
      "   120        0.8780             nan     0.1000   -0.0007\n",
      "   140        0.8669             nan     0.1000   -0.0002\n",
      "   150        0.8619             nan     0.1000    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2868             nan     0.1000    0.0321\n",
      "     2        1.2290             nan     0.1000    0.0270\n",
      "     3        1.1862             nan     0.1000    0.0201\n",
      "     4        1.1494             nan     0.1000    0.0194\n",
      "     5        1.1178             nan     0.1000    0.0149\n",
      "     6        1.0925             nan     0.1000    0.0121\n",
      "     7        1.0701             nan     0.1000    0.0115\n",
      "     8        1.0534             nan     0.1000    0.0068\n",
      "     9        1.0349             nan     0.1000    0.0077\n",
      "    10        1.0224             nan     0.1000    0.0065\n",
      "    20        0.9381             nan     0.1000    0.0033\n",
      "    40        0.8690             nan     0.1000   -0.0005\n",
      "    60        0.8224             nan     0.1000   -0.0001\n",
      "    80        0.7938             nan     0.1000   -0.0004\n",
      "   100        0.7687             nan     0.1000    0.0009\n",
      "   120        0.7464             nan     0.1000    0.0001\n",
      "   140        0.7263             nan     0.1000   -0.0007\n",
      "   150        0.7182             nan     0.1000   -0.0014\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2790             nan     0.1000    0.0376\n",
      "     2        1.2212             nan     0.1000    0.0282\n",
      "     3        1.1689             nan     0.1000    0.0248\n",
      "     4        1.1295             nan     0.1000    0.0216\n",
      "     5        1.0939             nan     0.1000    0.0174\n",
      "     6        1.0644             nan     0.1000    0.0152\n",
      "     7        1.0409             nan     0.1000    0.0116\n",
      "     8        1.0166             nan     0.1000    0.0109\n",
      "     9        0.9986             nan     0.1000    0.0094\n",
      "    10        0.9821             nan     0.1000    0.0085\n",
      "    20        0.8795             nan     0.1000    0.0026\n",
      "    40        0.7989             nan     0.1000    0.0005\n",
      "    60        0.7489             nan     0.1000    0.0016\n",
      "    80        0.7103             nan     0.1000   -0.0006\n",
      "   100        0.6818             nan     0.1000   -0.0008\n",
      "   120        0.6659             nan     0.1000   -0.0008\n",
      "   140        0.6471             nan     0.1000   -0.0004\n",
      "   150        0.6399             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3010             nan     0.1000    0.0277\n",
      "     2        1.2571             nan     0.1000    0.0229\n",
      "     3        1.2207             nan     0.1000    0.0184\n",
      "     4        1.1892             nan     0.1000    0.0153\n",
      "     5        1.1633             nan     0.1000    0.0125\n",
      "     6        1.1431             nan     0.1000    0.0100\n",
      "     7        1.1271             nan     0.1000    0.0080\n",
      "     8        1.1126             nan     0.1000    0.0080\n",
      "     9        1.1004             nan     0.1000    0.0066\n",
      "    10        1.0887             nan     0.1000    0.0055\n",
      "    20        1.0254             nan     0.1000    0.0002\n",
      "    40        0.9716             nan     0.1000    0.0006\n",
      "    60        0.9379             nan     0.1000    0.0001\n",
      "    80        0.9144             nan     0.1000    0.0001\n",
      "   100        0.8969             nan     0.1000   -0.0001\n",
      "   120        0.8821             nan     0.1000   -0.0001\n",
      "   140        0.8703             nan     0.1000   -0.0006\n",
      "   150        0.8647             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2903             nan     0.1000    0.0312\n",
      "     2        1.2391             nan     0.1000    0.0262\n",
      "     3        1.1929             nan     0.1000    0.0221\n",
      "     4        1.1584             nan     0.1000    0.0170\n",
      "     5        1.1260             nan     0.1000    0.0154\n",
      "     6        1.0981             nan     0.1000    0.0129\n",
      "     7        1.0742             nan     0.1000    0.0109\n",
      "     8        1.0555             nan     0.1000    0.0095\n",
      "     9        1.0354             nan     0.1000    0.0081\n",
      "    10        1.0218             nan     0.1000    0.0068\n",
      "    20        0.9397             nan     0.1000    0.0023\n",
      "    40        0.8652             nan     0.1000    0.0001\n",
      "    60        0.8257             nan     0.1000    0.0007\n",
      "    80        0.7923             nan     0.1000   -0.0002\n",
      "   100        0.7718             nan     0.1000   -0.0005\n",
      "   120        0.7535             nan     0.1000   -0.0001\n",
      "   140        0.7366             nan     0.1000   -0.0001\n",
      "   150        0.7305             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2823             nan     0.1000    0.0360\n",
      "     2        1.2218             nan     0.1000    0.0295\n",
      "     3        1.1737             nan     0.1000    0.0232\n",
      "     4        1.1326             nan     0.1000    0.0194\n",
      "     5        1.0958             nan     0.1000    0.0173\n",
      "     6        1.0679             nan     0.1000    0.0115\n",
      "     7        1.0424             nan     0.1000    0.0124\n",
      "     8        1.0204             nan     0.1000    0.0103\n",
      "     9        0.9994             nan     0.1000    0.0108\n",
      "    10        0.9804             nan     0.1000    0.0086\n",
      "    20        0.8826             nan     0.1000    0.0026\n",
      "    40        0.8018             nan     0.1000    0.0003\n",
      "    60        0.7613             nan     0.1000    0.0004\n",
      "    80        0.7306             nan     0.1000   -0.0001\n",
      "   100        0.7073             nan     0.1000   -0.0006\n",
      "   120        0.6872             nan     0.1000   -0.0003\n",
      "   140        0.6663             nan     0.1000   -0.0004\n",
      "   150        0.6576             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2960             nan     0.1000    0.0283\n",
      "     2        1.2492             nan     0.1000    0.0226\n",
      "     3        1.2129             nan     0.1000    0.0184\n",
      "     4        1.1811             nan     0.1000    0.0154\n",
      "     5        1.1568             nan     0.1000    0.0124\n",
      "     6        1.1364             nan     0.1000    0.0103\n",
      "     7        1.1183             nan     0.1000    0.0090\n",
      "     8        1.1046             nan     0.1000    0.0068\n",
      "     9        1.0939             nan     0.1000    0.0043\n",
      "    10        1.0791             nan     0.1000    0.0058\n",
      "    20        1.0181             nan     0.1000    0.0022\n",
      "    40        0.9642             nan     0.1000    0.0002\n",
      "    60        0.9306             nan     0.1000   -0.0005\n",
      "    80        0.9089             nan     0.1000   -0.0004\n",
      "   100        0.8905             nan     0.1000   -0.0002\n",
      "   120        0.8765             nan     0.1000   -0.0000\n",
      "   140        0.8634             nan     0.1000   -0.0005\n",
      "   150        0.8579             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2889             nan     0.1000    0.0310\n",
      "     2        1.2327             nan     0.1000    0.0261\n",
      "     3        1.1876             nan     0.1000    0.0211\n",
      "     4        1.1521             nan     0.1000    0.0176\n",
      "     5        1.1216             nan     0.1000    0.0145\n",
      "     6        1.0952             nan     0.1000    0.0126\n",
      "     7        1.0724             nan     0.1000    0.0095\n",
      "     8        1.0541             nan     0.1000    0.0079\n",
      "     9        1.0363             nan     0.1000    0.0090\n",
      "    10        1.0220             nan     0.1000    0.0080\n",
      "    20        0.9384             nan     0.1000    0.0022\n",
      "    40        0.8695             nan     0.1000   -0.0001\n",
      "    60        0.8233             nan     0.1000   -0.0009\n",
      "    80        0.7955             nan     0.1000    0.0005\n",
      "   100        0.7725             nan     0.1000    0.0011\n",
      "   120        0.7559             nan     0.1000   -0.0004\n",
      "   140        0.7398             nan     0.1000    0.0001\n",
      "   150        0.7336             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2789             nan     0.1000    0.0358\n",
      "     2        1.2215             nan     0.1000    0.0276\n",
      "     3        1.1726             nan     0.1000    0.0225\n",
      "     4        1.1281             nan     0.1000    0.0197\n",
      "     5        1.0900             nan     0.1000    0.0169\n",
      "     6        1.0610             nan     0.1000    0.0142\n",
      "     7        1.0364             nan     0.1000    0.0109\n",
      "     8        1.0151             nan     0.1000    0.0101\n",
      "     9        0.9960             nan     0.1000    0.0087\n",
      "    10        0.9800             nan     0.1000    0.0068\n",
      "    20        0.8825             nan     0.1000    0.0026\n",
      "    40        0.8071             nan     0.1000   -0.0003\n",
      "    60        0.7627             nan     0.1000   -0.0001\n",
      "    80        0.7308             nan     0.1000   -0.0010\n",
      "   100        0.7037             nan     0.1000   -0.0011\n",
      "   120        0.6841             nan     0.1000   -0.0003\n",
      "   140        0.6639             nan     0.1000   -0.0007\n",
      "   150        0.6556             nan     0.1000   -0.0012\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2986             nan     0.1000    0.0287\n",
      "     2        1.2494             nan     0.1000    0.0229\n",
      "     3        1.2111             nan     0.1000    0.0191\n",
      "     4        1.1803             nan     0.1000    0.0156\n",
      "     5        1.1527             nan     0.1000    0.0127\n",
      "     6        1.1304             nan     0.1000    0.0105\n",
      "     7        1.1123             nan     0.1000    0.0088\n",
      "     8        1.0978             nan     0.1000    0.0073\n",
      "     9        1.0848             nan     0.1000    0.0061\n",
      "    10        1.0728             nan     0.1000    0.0046\n",
      "    20        1.0109             nan     0.1000    0.0014\n",
      "    40        0.9631             nan     0.1000    0.0004\n",
      "    60        0.9318             nan     0.1000    0.0000\n",
      "    80        0.9107             nan     0.1000    0.0001\n",
      "   100        0.8941             nan     0.1000    0.0003\n",
      "   120        0.8788             nan     0.1000    0.0002\n",
      "   140        0.8668             nan     0.1000   -0.0000\n",
      "   150        0.8616             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2898             nan     0.1000    0.0299\n",
      "     2        1.2358             nan     0.1000    0.0271\n",
      "     3        1.1889             nan     0.1000    0.0217\n",
      "     4        1.1526             nan     0.1000    0.0184\n",
      "     5        1.1194             nan     0.1000    0.0155\n",
      "     6        1.0940             nan     0.1000    0.0123\n",
      "     7        1.0701             nan     0.1000    0.0103\n",
      "     8        1.0506             nan     0.1000    0.0087\n",
      "     9        1.0318             nan     0.1000    0.0086\n",
      "    10        1.0167             nan     0.1000    0.0072\n",
      "    20        0.9397             nan     0.1000    0.0011\n",
      "    40        0.8654             nan     0.1000    0.0021\n",
      "    60        0.8275             nan     0.1000   -0.0002\n",
      "    80        0.7895             nan     0.1000    0.0004\n",
      "   100        0.7700             nan     0.1000   -0.0002\n",
      "   120        0.7494             nan     0.1000   -0.0002\n",
      "   140        0.7366             nan     0.1000   -0.0005\n",
      "   150        0.7275             nan     0.1000   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2833             nan     0.1000    0.0353\n",
      "     2        1.2281             nan     0.1000    0.0290\n",
      "     3        1.1786             nan     0.1000    0.0241\n",
      "     4        1.1395             nan     0.1000    0.0192\n",
      "     5        1.1025             nan     0.1000    0.0178\n",
      "     6        1.0722             nan     0.1000    0.0157\n",
      "     7        1.0455             nan     0.1000    0.0129\n",
      "     8        1.0235             nan     0.1000    0.0110\n",
      "     9        1.0028             nan     0.1000    0.0092\n",
      "    10        0.9816             nan     0.1000    0.0095\n",
      "    20        0.8828             nan     0.1000    0.0022\n",
      "    40        0.8054             nan     0.1000    0.0003\n",
      "    60        0.7584             nan     0.1000   -0.0001\n",
      "    80        0.7323             nan     0.1000   -0.0011\n",
      "   100        0.7036             nan     0.1000   -0.0006\n",
      "   120        0.6822             nan     0.1000   -0.0008\n",
      "   140        0.6625             nan     0.1000   -0.0004\n",
      "   150        0.6555             nan     0.1000   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3012             nan     0.1000    0.0277\n",
      "     2        1.2536             nan     0.1000    0.0217\n",
      "     3        1.2177             nan     0.1000    0.0178\n",
      "     4        1.1883             nan     0.1000    0.0149\n",
      "     5        1.1606             nan     0.1000    0.0115\n",
      "     6        1.1385             nan     0.1000    0.0091\n",
      "     7        1.1204             nan     0.1000    0.0076\n",
      "     8        1.1058             nan     0.1000    0.0066\n",
      "     9        1.0951             nan     0.1000    0.0053\n",
      "    10        1.0865             nan     0.1000    0.0036\n",
      "    20        1.0297             nan     0.1000    0.0014\n",
      "    40        0.9809             nan     0.1000    0.0001\n",
      "    60        0.9499             nan     0.1000    0.0003\n",
      "    80        0.9264             nan     0.1000    0.0001\n",
      "   100        0.9112             nan     0.1000   -0.0001\n",
      "   120        0.8954             nan     0.1000   -0.0002\n",
      "   140        0.8840             nan     0.1000   -0.0005\n",
      "   150        0.8777             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2902             nan     0.1000    0.0320\n",
      "     2        1.2405             nan     0.1000    0.0260\n",
      "     3        1.1983             nan     0.1000    0.0212\n",
      "     4        1.1604             nan     0.1000    0.0180\n",
      "     5        1.1283             nan     0.1000    0.0147\n",
      "     6        1.0983             nan     0.1000    0.0116\n",
      "     7        1.0769             nan     0.1000    0.0107\n",
      "     8        1.0566             nan     0.1000    0.0087\n",
      "     9        1.0387             nan     0.1000    0.0070\n",
      "    10        1.0254             nan     0.1000    0.0064\n",
      "    20        0.9483             nan     0.1000    0.0018\n",
      "    40        0.8792             nan     0.1000    0.0004\n",
      "    60        0.8404             nan     0.1000   -0.0002\n",
      "    80        0.8027             nan     0.1000    0.0012\n",
      "   100        0.7789             nan     0.1000   -0.0003\n",
      "   120        0.7590             nan     0.1000    0.0004\n",
      "   140        0.7433             nan     0.1000   -0.0001\n",
      "   150        0.7362             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2847             nan     0.1000    0.0341\n",
      "     2        1.2253             nan     0.1000    0.0285\n",
      "     3        1.1769             nan     0.1000    0.0234\n",
      "     4        1.1373             nan     0.1000    0.0194\n",
      "     5        1.0967             nan     0.1000    0.0176\n",
      "     6        1.0675             nan     0.1000    0.0146\n",
      "     7        1.0438             nan     0.1000    0.0120\n",
      "     8        1.0188             nan     0.1000    0.0111\n",
      "     9        0.9986             nan     0.1000    0.0089\n",
      "    10        0.9817             nan     0.1000    0.0073\n",
      "    20        0.8924             nan     0.1000    0.0020\n",
      "    40        0.8131             nan     0.1000   -0.0010\n",
      "    60        0.7710             nan     0.1000   -0.0003\n",
      "    80        0.7373             nan     0.1000   -0.0001\n",
      "   100        0.7127             nan     0.1000   -0.0004\n",
      "   120        0.6928             nan     0.1000   -0.0002\n",
      "   140        0.6763             nan     0.1000   -0.0008\n",
      "   150        0.6678             nan     0.1000   -0.0013\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3060             nan     0.1000    0.0266\n",
      "     2        1.2639             nan     0.1000    0.0216\n",
      "     3        1.2278             nan     0.1000    0.0179\n",
      "     4        1.1976             nan     0.1000    0.0144\n",
      "     5        1.1722             nan     0.1000    0.0121\n",
      "     6        1.1534             nan     0.1000    0.0098\n",
      "     7        1.1363             nan     0.1000    0.0083\n",
      "     8        1.1250             nan     0.1000    0.0067\n",
      "     9        1.1131             nan     0.1000    0.0061\n",
      "    10        1.1037             nan     0.1000    0.0050\n",
      "    20        1.0408             nan     0.1000    0.0010\n",
      "    40        0.9912             nan     0.1000    0.0004\n",
      "    60        0.9611             nan     0.1000    0.0003\n",
      "    80        0.9390             nan     0.1000    0.0001\n",
      "   100        0.9200             nan     0.1000    0.0003\n",
      "   120        0.9053             nan     0.1000   -0.0001\n",
      "   140        0.8949             nan     0.1000    0.0000\n",
      "   150        0.8889             nan     0.1000   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2885             nan     0.1000    0.0311\n",
      "     2        1.2370             nan     0.1000    0.0241\n",
      "     3        1.1950             nan     0.1000    0.0178\n",
      "     4        1.1613             nan     0.1000    0.0170\n",
      "     5        1.1303             nan     0.1000    0.0138\n",
      "     6        1.1053             nan     0.1000    0.0113\n",
      "     7        1.0844             nan     0.1000    0.0105\n",
      "     8        1.0663             nan     0.1000    0.0073\n",
      "     9        1.0483             nan     0.1000    0.0077\n",
      "    10        1.0351             nan     0.1000    0.0068\n",
      "    20        0.9582             nan     0.1000    0.0025\n",
      "    40        0.8931             nan     0.1000   -0.0001\n",
      "    60        0.8520             nan     0.1000   -0.0001\n",
      "    80        0.8199             nan     0.1000   -0.0003\n",
      "   100        0.7967             nan     0.1000   -0.0004\n",
      "   120        0.7759             nan     0.1000   -0.0001\n",
      "   140        0.7612             nan     0.1000   -0.0008\n",
      "   150        0.7535             nan     0.1000   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2866             nan     0.1000    0.0335\n",
      "     2        1.2293             nan     0.1000    0.0290\n",
      "     3        1.1791             nan     0.1000    0.0225\n",
      "     4        1.1399             nan     0.1000    0.0168\n",
      "     5        1.1072             nan     0.1000    0.0160\n",
      "     6        1.0788             nan     0.1000    0.0125\n",
      "     7        1.0575             nan     0.1000    0.0112\n",
      "     8        1.0343             nan     0.1000    0.0103\n",
      "     9        1.0153             nan     0.1000    0.0087\n",
      "    10        1.0000             nan     0.1000    0.0077\n",
      "    20        0.9097             nan     0.1000    0.0024\n",
      "    40        0.8282             nan     0.1000    0.0007\n",
      "    60        0.7811             nan     0.1000   -0.0001\n",
      "    80        0.7511             nan     0.1000   -0.0005\n",
      "   100        0.7253             nan     0.1000   -0.0007\n",
      "   120        0.7066             nan     0.1000   -0.0010\n",
      "   140        0.6913             nan     0.1000   -0.0010\n",
      "   150        0.6824             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2979             nan     0.1000    0.0267\n",
      "     2        1.2535             nan     0.1000    0.0226\n",
      "     3        1.2140             nan     0.1000    0.0183\n",
      "     4        1.1869             nan     0.1000    0.0149\n",
      "     5        1.1614             nan     0.1000    0.0124\n",
      "     6        1.1422             nan     0.1000    0.0102\n",
      "     7        1.1233             nan     0.1000    0.0084\n",
      "     8        1.1074             nan     0.1000    0.0071\n",
      "     9        1.0949             nan     0.1000    0.0058\n",
      "    10        1.0867             nan     0.1000    0.0038\n",
      "    20        1.0256             nan     0.1000    0.0013\n",
      "    40        0.9771             nan     0.1000    0.0002\n",
      "    60        0.9446             nan     0.1000    0.0000\n",
      "    80        0.9229             nan     0.1000   -0.0002\n",
      "   100        0.9043             nan     0.1000    0.0000\n",
      "   120        0.8882             nan     0.1000    0.0001\n",
      "   140        0.8738             nan     0.1000   -0.0003\n",
      "   150        0.8675             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2879             nan     0.1000    0.0314\n",
      "     2        1.2359             nan     0.1000    0.0253\n",
      "     3        1.1963             nan     0.1000    0.0199\n",
      "     4        1.1581             nan     0.1000    0.0181\n",
      "     5        1.1273             nan     0.1000    0.0146\n",
      "     6        1.1017             nan     0.1000    0.0116\n",
      "     7        1.0818             nan     0.1000    0.0093\n",
      "     8        1.0621             nan     0.1000    0.0093\n",
      "     9        1.0432             nan     0.1000    0.0084\n",
      "    10        1.0284             nan     0.1000    0.0062\n",
      "    20        0.9537             nan     0.1000    0.0020\n",
      "    40        0.8794             nan     0.1000    0.0009\n",
      "    60        0.8323             nan     0.1000   -0.0003\n",
      "    80        0.8027             nan     0.1000    0.0008\n",
      "   100        0.7793             nan     0.1000   -0.0003\n",
      "   120        0.7563             nan     0.1000   -0.0007\n",
      "   140        0.7427             nan     0.1000   -0.0009\n",
      "   150        0.7337             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2811             nan     0.1000    0.0359\n",
      "     2        1.2234             nan     0.1000    0.0292\n",
      "     3        1.1731             nan     0.1000    0.0228\n",
      "     4        1.1293             nan     0.1000    0.0199\n",
      "     5        1.0962             nan     0.1000    0.0168\n",
      "     6        1.0673             nan     0.1000    0.0139\n",
      "     7        1.0414             nan     0.1000    0.0116\n",
      "     8        1.0205             nan     0.1000    0.0104\n",
      "     9        1.0041             nan     0.1000    0.0077\n",
      "    10        0.9863             nan     0.1000    0.0077\n",
      "    20        0.8888             nan     0.1000    0.0027\n",
      "    40        0.8084             nan     0.1000    0.0011\n",
      "    60        0.7673             nan     0.1000   -0.0002\n",
      "    80        0.7355             nan     0.1000    0.0002\n",
      "   100        0.7105             nan     0.1000   -0.0005\n",
      "   120        0.6869             nan     0.1000   -0.0002\n",
      "   140        0.6706             nan     0.1000   -0.0008\n",
      "   150        0.6626             nan     0.1000   -0.0009\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3025             nan     0.1000    0.0258\n",
      "     2        1.2580             nan     0.1000    0.0224\n",
      "     3        1.2165             nan     0.1000    0.0176\n",
      "     4        1.1879             nan     0.1000    0.0137\n",
      "     5        1.1630             nan     0.1000    0.0121\n",
      "     6        1.1449             nan     0.1000    0.0096\n",
      "     7        1.1279             nan     0.1000    0.0077\n",
      "     8        1.1117             nan     0.1000    0.0067\n",
      "     9        1.1008             nan     0.1000    0.0056\n",
      "    10        1.0901             nan     0.1000    0.0042\n",
      "    20        1.0290             nan     0.1000    0.0019\n",
      "    40        0.9827             nan     0.1000    0.0006\n",
      "    60        0.9495             nan     0.1000    0.0001\n",
      "    80        0.9251             nan     0.1000    0.0002\n",
      "   100        0.9078             nan     0.1000   -0.0004\n",
      "   120        0.8942             nan     0.1000   -0.0001\n",
      "   140        0.8823             nan     0.1000   -0.0001\n",
      "   150        0.8778             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2865             nan     0.1000    0.0310\n",
      "     2        1.2370             nan     0.1000    0.0253\n",
      "     3        1.1958             nan     0.1000    0.0207\n",
      "     4        1.1606             nan     0.1000    0.0181\n",
      "     5        1.1285             nan     0.1000    0.0150\n",
      "     6        1.1052             nan     0.1000    0.0120\n",
      "     7        1.0826             nan     0.1000    0.0109\n",
      "     8        1.0626             nan     0.1000    0.0094\n",
      "     9        1.0446             nan     0.1000    0.0084\n",
      "    10        1.0287             nan     0.1000    0.0062\n",
      "    20        0.9505             nan     0.1000    0.0028\n",
      "    40        0.8801             nan     0.1000    0.0015\n",
      "    60        0.8351             nan     0.1000   -0.0005\n",
      "    80        0.8029             nan     0.1000   -0.0002\n",
      "   100        0.7809             nan     0.1000   -0.0003\n",
      "   120        0.7659             nan     0.1000   -0.0009\n",
      "   140        0.7475             nan     0.1000    0.0004\n",
      "   150        0.7376             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2818             nan     0.1000    0.0341\n",
      "     2        1.2231             nan     0.1000    0.0264\n",
      "     3        1.1749             nan     0.1000    0.0230\n",
      "     4        1.1360             nan     0.1000    0.0194\n",
      "     5        1.1019             nan     0.1000    0.0176\n",
      "     6        1.0710             nan     0.1000    0.0146\n",
      "     7        1.0469             nan     0.1000    0.0117\n",
      "     8        1.0231             nan     0.1000    0.0106\n",
      "     9        1.0055             nan     0.1000    0.0091\n",
      "    10        0.9919             nan     0.1000    0.0061\n",
      "    20        0.8991             nan     0.1000    0.0024\n",
      "    40        0.8138             nan     0.1000    0.0004\n",
      "    60        0.7617             nan     0.1000    0.0005\n",
      "    80        0.7324             nan     0.1000   -0.0009\n",
      "   100        0.7080             nan     0.1000   -0.0004\n",
      "   120        0.6891             nan     0.1000   -0.0003\n",
      "   140        0.6736             nan     0.1000   -0.0004\n",
      "   150        0.6665             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2983             nan     0.1000    0.0266\n",
      "     2        1.2550             nan     0.1000    0.0208\n",
      "     3        1.2207             nan     0.1000    0.0174\n",
      "     4        1.1918             nan     0.1000    0.0148\n",
      "     5        1.1644             nan     0.1000    0.0122\n",
      "     6        1.1448             nan     0.1000    0.0100\n",
      "     7        1.1278             nan     0.1000    0.0085\n",
      "     8        1.1149             nan     0.1000    0.0070\n",
      "     9        1.1014             nan     0.1000    0.0062\n",
      "    10        1.0917             nan     0.1000    0.0046\n",
      "    20        1.0275             nan     0.1000    0.0019\n",
      "    40        0.9795             nan     0.1000    0.0003\n",
      "    60        0.9444             nan     0.1000    0.0005\n",
      "    80        0.9226             nan     0.1000    0.0002\n",
      "   100        0.9053             nan     0.1000   -0.0000\n",
      "   120        0.8902             nan     0.1000   -0.0000\n",
      "   140        0.8782             nan     0.1000   -0.0006\n",
      "   150        0.8732             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2925             nan     0.1000    0.0322\n",
      "     2        1.2430             nan     0.1000    0.0236\n",
      "     3        1.1952             nan     0.1000    0.0212\n",
      "     4        1.1595             nan     0.1000    0.0186\n",
      "     5        1.1284             nan     0.1000    0.0149\n",
      "     6        1.1038             nan     0.1000    0.0131\n",
      "     7        1.0800             nan     0.1000    0.0111\n",
      "     8        1.0607             nan     0.1000    0.0086\n",
      "     9        1.0456             nan     0.1000    0.0075\n",
      "    10        1.0308             nan     0.1000    0.0069\n",
      "    20        0.9491             nan     0.1000    0.0018\n",
      "    40        0.8715             nan     0.1000    0.0005\n",
      "    60        0.8325             nan     0.1000   -0.0001\n",
      "    80        0.7988             nan     0.1000   -0.0003\n",
      "   100        0.7766             nan     0.1000   -0.0002\n",
      "   120        0.7581             nan     0.1000   -0.0009\n",
      "   140        0.7419             nan     0.1000   -0.0004\n",
      "   150        0.7335             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2834             nan     0.1000    0.0359\n",
      "     2        1.2281             nan     0.1000    0.0279\n",
      "     3        1.1781             nan     0.1000    0.0233\n",
      "     4        1.1369             nan     0.1000    0.0186\n",
      "     5        1.1051             nan     0.1000    0.0162\n",
      "     6        1.0742             nan     0.1000    0.0136\n",
      "     7        1.0513             nan     0.1000    0.0120\n",
      "     8        1.0283             nan     0.1000    0.0104\n",
      "     9        1.0088             nan     0.1000    0.0075\n",
      "    10        0.9916             nan     0.1000    0.0076\n",
      "    20        0.8918             nan     0.1000    0.0025\n",
      "    40        0.8133             nan     0.1000    0.0002\n",
      "    60        0.7668             nan     0.1000    0.0010\n",
      "    80        0.7307             nan     0.1000   -0.0013\n",
      "   100        0.7070             nan     0.1000   -0.0001\n",
      "   120        0.6865             nan     0.1000   -0.0008\n",
      "   140        0.6687             nan     0.1000   -0.0006\n",
      "   150        0.6627             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2988             nan     0.1000    0.0271\n",
      "     2        1.2533             nan     0.1000    0.0213\n",
      "     3        1.2187             nan     0.1000    0.0181\n",
      "     4        1.1866             nan     0.1000    0.0143\n",
      "     5        1.1638             nan     0.1000    0.0121\n",
      "     6        1.1422             nan     0.1000    0.0097\n",
      "     7        1.1265             nan     0.1000    0.0084\n",
      "     8        1.1087             nan     0.1000    0.0063\n",
      "     9        1.0986             nan     0.1000    0.0055\n",
      "    10        1.0881             nan     0.1000    0.0034\n",
      "    20        1.0273             nan     0.1000    0.0012\n",
      "    40        0.9790             nan     0.1000   -0.0003\n",
      "    60        0.9497             nan     0.1000   -0.0004\n",
      "    80        0.9300             nan     0.1000   -0.0005\n",
      "   100        0.9113             nan     0.1000   -0.0003\n",
      "   120        0.8974             nan     0.1000   -0.0005\n",
      "   140        0.8859             nan     0.1000   -0.0006\n",
      "   150        0.8801             nan     0.1000   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2896             nan     0.1000    0.0309\n",
      "     2        1.2411             nan     0.1000    0.0229\n",
      "     3        1.1982             nan     0.1000    0.0221\n",
      "     4        1.1633             nan     0.1000    0.0178\n",
      "     5        1.1345             nan     0.1000    0.0146\n",
      "     6        1.1080             nan     0.1000    0.0126\n",
      "     7        1.0838             nan     0.1000    0.0105\n",
      "     8        1.0639             nan     0.1000    0.0092\n",
      "     9        1.0462             nan     0.1000    0.0068\n",
      "    10        1.0318             nan     0.1000    0.0062\n",
      "    20        0.9560             nan     0.1000    0.0025\n",
      "    40        0.8806             nan     0.1000    0.0003\n",
      "    60        0.8441             nan     0.1000   -0.0000\n",
      "    80        0.8173             nan     0.1000   -0.0005\n",
      "   100        0.7938             nan     0.1000   -0.0008\n",
      "   120        0.7740             nan     0.1000   -0.0005\n",
      "   140        0.7570             nan     0.1000   -0.0009\n",
      "   150        0.7496             nan     0.1000   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2839             nan     0.1000    0.0315\n",
      "     2        1.2246             nan     0.1000    0.0282\n",
      "     3        1.1771             nan     0.1000    0.0232\n",
      "     4        1.1371             nan     0.1000    0.0197\n",
      "     5        1.1046             nan     0.1000    0.0165\n",
      "     6        1.0747             nan     0.1000    0.0142\n",
      "     7        1.0518             nan     0.1000    0.0122\n",
      "     8        1.0299             nan     0.1000    0.0104\n",
      "     9        1.0098             nan     0.1000    0.0093\n",
      "    10        0.9920             nan     0.1000    0.0083\n",
      "    20        0.9001             nan     0.1000    0.0012\n",
      "    40        0.8187             nan     0.1000   -0.0002\n",
      "    60        0.7793             nan     0.1000   -0.0002\n",
      "    80        0.7437             nan     0.1000   -0.0001\n",
      "   100        0.7164             nan     0.1000   -0.0007\n",
      "   120        0.6961             nan     0.1000   -0.0013\n",
      "   140        0.6821             nan     0.1000   -0.0009\n",
      "   150        0.6742             nan     0.1000    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2927             nan     0.1000    0.0283\n",
      "     2        1.2469             nan     0.1000    0.0230\n",
      "     3        1.2121             nan     0.1000    0.0184\n",
      "     4        1.1777             nan     0.1000    0.0156\n",
      "     5        1.1553             nan     0.1000    0.0125\n",
      "     6        1.1333             nan     0.1000    0.0105\n",
      "     7        1.1149             nan     0.1000    0.0085\n",
      "     8        1.1004             nan     0.1000    0.0077\n",
      "     9        1.0879             nan     0.1000    0.0062\n",
      "    10        1.0771             nan     0.1000    0.0053\n",
      "    20        1.0145             nan     0.1000    0.0022\n",
      "    40        0.9594             nan     0.1000    0.0005\n",
      "    60        0.9280             nan     0.1000   -0.0003\n",
      "    80        0.9023             nan     0.1000   -0.0000\n",
      "   100        0.8832             nan     0.1000    0.0000\n",
      "   120        0.8698             nan     0.1000   -0.0004\n",
      "   140        0.8582             nan     0.1000   -0.0001\n",
      "   150        0.8530             nan     0.1000   -0.0007\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2892             nan     0.1000    0.0324\n",
      "     2        1.2344             nan     0.1000    0.0266\n",
      "     3        1.1878             nan     0.1000    0.0222\n",
      "     4        1.1531             nan     0.1000    0.0186\n",
      "     5        1.1207             nan     0.1000    0.0151\n",
      "     6        1.0899             nan     0.1000    0.0130\n",
      "     7        1.0673             nan     0.1000    0.0112\n",
      "     8        1.0478             nan     0.1000    0.0088\n",
      "     9        1.0307             nan     0.1000    0.0084\n",
      "    10        1.0150             nan     0.1000    0.0070\n",
      "    20        0.9353             nan     0.1000    0.0012\n",
      "    40        0.8543             nan     0.1000    0.0006\n",
      "    60        0.8158             nan     0.1000    0.0003\n",
      "    80        0.7869             nan     0.1000    0.0000\n",
      "   100        0.7590             nan     0.1000    0.0006\n",
      "   120        0.7401             nan     0.1000   -0.0001\n",
      "   140        0.7252             nan     0.1000   -0.0005\n",
      "   150        0.7177             nan     0.1000   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2783             nan     0.1000    0.0368\n",
      "     2        1.2205             nan     0.1000    0.0281\n",
      "     3        1.1708             nan     0.1000    0.0258\n",
      "     4        1.1276             nan     0.1000    0.0211\n",
      "     5        1.0891             nan     0.1000    0.0182\n",
      "     6        1.0589             nan     0.1000    0.0151\n",
      "     7        1.0315             nan     0.1000    0.0115\n",
      "     8        1.0087             nan     0.1000    0.0103\n",
      "     9        0.9893             nan     0.1000    0.0100\n",
      "    10        0.9714             nan     0.1000    0.0073\n",
      "    20        0.8805             nan     0.1000    0.0011\n",
      "    40        0.7897             nan     0.1000    0.0013\n",
      "    60        0.7524             nan     0.1000   -0.0002\n",
      "    80        0.7180             nan     0.1000   -0.0003\n",
      "   100        0.6951             nan     0.1000   -0.0001\n",
      "   120        0.6765             nan     0.1000   -0.0010\n",
      "   140        0.6591             nan     0.1000   -0.0015\n",
      "   150        0.6514             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2970             nan     0.1000    0.0270\n",
      "     2        1.2520             nan     0.1000    0.0219\n",
      "     3        1.2144             nan     0.1000    0.0177\n",
      "     4        1.1852             nan     0.1000    0.0151\n",
      "     5        1.1611             nan     0.1000    0.0126\n",
      "     6        1.1417             nan     0.1000    0.0105\n",
      "     7        1.1253             nan     0.1000    0.0091\n",
      "     8        1.1126             nan     0.1000    0.0049\n",
      "     9        1.0973             nan     0.1000    0.0074\n",
      "    10        1.0844             nan     0.1000    0.0060\n",
      "    20        1.0149             nan     0.1000    0.0009\n",
      "    40        0.9633             nan     0.1000   -0.0001\n",
      "    60        0.9316             nan     0.1000    0.0003\n",
      "    80        0.9092             nan     0.1000    0.0000\n",
      "   100        0.8943             nan     0.1000   -0.0003\n",
      "   120        0.8790             nan     0.1000   -0.0002\n",
      "   140        0.8666             nan     0.1000   -0.0002\n",
      "   150        0.8607             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2865             nan     0.1000    0.0331\n",
      "     2        1.2333             nan     0.1000    0.0252\n",
      "     3        1.1928             nan     0.1000    0.0205\n",
      "     4        1.1553             nan     0.1000    0.0184\n",
      "     5        1.1238             nan     0.1000    0.0164\n",
      "     6        1.0970             nan     0.1000    0.0137\n",
      "     7        1.0737             nan     0.1000    0.0117\n",
      "     8        1.0540             nan     0.1000    0.0096\n",
      "     9        1.0382             nan     0.1000    0.0077\n",
      "    10        1.0244             nan     0.1000    0.0069\n",
      "    20        0.9423             nan     0.1000    0.0026\n",
      "    40        0.8679             nan     0.1000    0.0014\n",
      "    60        0.8263             nan     0.1000   -0.0004\n",
      "    80        0.7969             nan     0.1000   -0.0006\n",
      "   100        0.7733             nan     0.1000   -0.0008\n",
      "   120        0.7530             nan     0.1000   -0.0003\n",
      "   140        0.7345             nan     0.1000   -0.0008\n",
      "   150        0.7258             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2756             nan     0.1000    0.0356\n",
      "     2        1.2215             nan     0.1000    0.0271\n",
      "     3        1.1760             nan     0.1000    0.0231\n",
      "     4        1.1361             nan     0.1000    0.0186\n",
      "     5        1.1031             nan     0.1000    0.0141\n",
      "     6        1.0745             nan     0.1000    0.0150\n",
      "     7        1.0456             nan     0.1000    0.0133\n",
      "     8        1.0230             nan     0.1000    0.0120\n",
      "     9        1.0044             nan     0.1000    0.0097\n",
      "    10        0.9875             nan     0.1000    0.0075\n",
      "    20        0.8891             nan     0.1000    0.0034\n",
      "    40        0.8081             nan     0.1000   -0.0001\n",
      "    60        0.7599             nan     0.1000   -0.0003\n",
      "    80        0.7280             nan     0.1000   -0.0002\n",
      "   100        0.7058             nan     0.1000   -0.0002\n",
      "   120        0.6836             nan     0.1000   -0.0003\n",
      "   140        0.6637             nan     0.1000   -0.0006\n",
      "   150        0.6560             nan     0.1000   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2998             nan     0.1000    0.0264\n",
      "     2        1.2570             nan     0.1000    0.0212\n",
      "     3        1.2229             nan     0.1000    0.0174\n",
      "     4        1.1951             nan     0.1000    0.0143\n",
      "     5        1.1685             nan     0.1000    0.0124\n",
      "     6        1.1478             nan     0.1000    0.0102\n",
      "     7        1.1330             nan     0.1000    0.0080\n",
      "     8        1.1178             nan     0.1000    0.0073\n",
      "     9        1.1063             nan     0.1000    0.0058\n",
      "    10        1.0961             nan     0.1000    0.0049\n",
      "    20        1.0328             nan     0.1000    0.0008\n",
      "    40        0.9803             nan     0.1000    0.0003\n",
      "    60        0.9505             nan     0.1000   -0.0003\n",
      "    80        0.9305             nan     0.1000    0.0003\n",
      "   100        0.9143             nan     0.1000    0.0002\n",
      "   120        0.9001             nan     0.1000    0.0004\n",
      "   140        0.8878             nan     0.1000   -0.0001\n",
      "   150        0.8810             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2921             nan     0.1000    0.0326\n",
      "     2        1.2393             nan     0.1000    0.0242\n",
      "     3        1.1968             nan     0.1000    0.0191\n",
      "     4        1.1601             nan     0.1000    0.0164\n",
      "     5        1.1289             nan     0.1000    0.0136\n",
      "     6        1.1045             nan     0.1000    0.0119\n",
      "     7        1.0846             nan     0.1000    0.0110\n",
      "     8        1.0664             nan     0.1000    0.0093\n",
      "     9        1.0520             nan     0.1000    0.0072\n",
      "    10        1.0368             nan     0.1000    0.0062\n",
      "    20        0.9616             nan     0.1000    0.0010\n",
      "    40        0.8867             nan     0.1000    0.0006\n",
      "    60        0.8448             nan     0.1000    0.0004\n",
      "    80        0.8137             nan     0.1000   -0.0001\n",
      "   100        0.7893             nan     0.1000   -0.0005\n",
      "   120        0.7691             nan     0.1000   -0.0007\n",
      "   140        0.7549             nan     0.1000    0.0005\n",
      "   150        0.7448             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2857             nan     0.1000    0.0342\n",
      "     2        1.2314             nan     0.1000    0.0251\n",
      "     3        1.1816             nan     0.1000    0.0232\n",
      "     4        1.1406             nan     0.1000    0.0205\n",
      "     5        1.1049             nan     0.1000    0.0171\n",
      "     6        1.0802             nan     0.1000    0.0096\n",
      "     7        1.0510             nan     0.1000    0.0126\n",
      "     8        1.0298             nan     0.1000    0.0106\n",
      "     9        1.0095             nan     0.1000    0.0092\n",
      "    10        0.9915             nan     0.1000    0.0081\n",
      "    20        0.8986             nan     0.1000    0.0025\n",
      "    40        0.8172             nan     0.1000    0.0003\n",
      "    60        0.7731             nan     0.1000    0.0002\n",
      "    80        0.7437             nan     0.1000   -0.0008\n",
      "   100        0.7199             nan     0.1000   -0.0006\n",
      "   120        0.7009             nan     0.1000   -0.0009\n",
      "   140        0.6792             nan     0.1000   -0.0006\n",
      "   150        0.6708             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2943             nan     0.1000    0.0278\n",
      "     2        1.2450             nan     0.1000    0.0229\n",
      "     3        1.2088             nan     0.1000    0.0190\n",
      "     4        1.1799             nan     0.1000    0.0154\n",
      "     5        1.1558             nan     0.1000    0.0129\n",
      "     6        1.1338             nan     0.1000    0.0110\n",
      "     7        1.1159             nan     0.1000    0.0085\n",
      "     8        1.1015             nan     0.1000    0.0076\n",
      "     9        1.0882             nan     0.1000    0.0063\n",
      "    10        1.0767             nan     0.1000    0.0052\n",
      "    20        1.0128             nan     0.1000    0.0019\n",
      "    40        0.9648             nan     0.1000   -0.0001\n",
      "    60        0.9355             nan     0.1000   -0.0002\n",
      "    80        0.9131             nan     0.1000    0.0005\n",
      "   100        0.8967             nan     0.1000   -0.0001\n",
      "   120        0.8805             nan     0.1000    0.0000\n",
      "   140        0.8687             nan     0.1000   -0.0003\n",
      "   150        0.8627             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2877             nan     0.1000    0.0322\n",
      "     2        1.2347             nan     0.1000    0.0257\n",
      "     3        1.1888             nan     0.1000    0.0205\n",
      "     4        1.1515             nan     0.1000    0.0184\n",
      "     5        1.1171             nan     0.1000    0.0149\n",
      "     6        1.0907             nan     0.1000    0.0132\n",
      "     7        1.0702             nan     0.1000    0.0103\n",
      "     8        1.0490             nan     0.1000    0.0078\n",
      "     9        1.0340             nan     0.1000    0.0075\n",
      "    10        1.0177             nan     0.1000    0.0074\n",
      "    20        0.9367             nan     0.1000    0.0024\n",
      "    40        0.8668             nan     0.1000    0.0002\n",
      "    60        0.8264             nan     0.1000   -0.0000\n",
      "    80        0.7993             nan     0.1000   -0.0007\n",
      "   100        0.7762             nan     0.1000   -0.0006\n",
      "   120        0.7563             nan     0.1000   -0.0007\n",
      "   140        0.7412             nan     0.1000    0.0004\n",
      "   150        0.7317             nan     0.1000   -0.0010\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2815             nan     0.1000    0.0369\n",
      "     2        1.2226             nan     0.1000    0.0269\n",
      "     3        1.1726             nan     0.1000    0.0230\n",
      "     4        1.1355             nan     0.1000    0.0168\n",
      "     5        1.1006             nan     0.1000    0.0160\n",
      "     6        1.0668             nan     0.1000    0.0161\n",
      "     7        1.0396             nan     0.1000    0.0123\n",
      "     8        1.0166             nan     0.1000    0.0106\n",
      "     9        0.9952             nan     0.1000    0.0103\n",
      "    10        0.9757             nan     0.1000    0.0086\n",
      "    20        0.8809             nan     0.1000    0.0017\n",
      "    40        0.7965             nan     0.1000   -0.0003\n",
      "    60        0.7546             nan     0.1000   -0.0006\n",
      "    80        0.7239             nan     0.1000   -0.0006\n",
      "   100        0.7034             nan     0.1000   -0.0002\n",
      "   120        0.6900             nan     0.1000   -0.0007\n",
      "   140        0.6687             nan     0.1000   -0.0012\n",
      "   150        0.6620             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3001             nan     0.1000    0.0264\n",
      "     2        1.2546             nan     0.1000    0.0236\n",
      "     3        1.2183             nan     0.1000    0.0170\n",
      "     4        1.1852             nan     0.1000    0.0162\n",
      "     5        1.1580             nan     0.1000    0.0131\n",
      "     6        1.1364             nan     0.1000    0.0107\n",
      "     7        1.1188             nan     0.1000    0.0088\n",
      "     8        1.1039             nan     0.1000    0.0073\n",
      "     9        1.0915             nan     0.1000    0.0056\n",
      "    10        1.0803             nan     0.1000    0.0047\n",
      "    20        1.0177             nan     0.1000    0.0018\n",
      "    40        0.9691             nan     0.1000    0.0005\n",
      "    60        0.9400             nan     0.1000    0.0001\n",
      "    80        0.9198             nan     0.1000   -0.0002\n",
      "   100        0.9048             nan     0.1000   -0.0002\n",
      "   120        0.8905             nan     0.1000   -0.0003\n",
      "   140        0.8796             nan     0.1000   -0.0002\n",
      "   150        0.8747             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2868             nan     0.1000    0.0329\n",
      "     2        1.2316             nan     0.1000    0.0250\n",
      "     3        1.1870             nan     0.1000    0.0208\n",
      "     4        1.1507             nan     0.1000    0.0174\n",
      "     5        1.1197             nan     0.1000    0.0153\n",
      "     6        1.0948             nan     0.1000    0.0127\n",
      "     7        1.0720             nan     0.1000    0.0102\n",
      "     8        1.0559             nan     0.1000    0.0081\n",
      "     9        1.0381             nan     0.1000    0.0076\n",
      "    10        1.0238             nan     0.1000    0.0071\n",
      "    20        0.9454             nan     0.1000    0.0023\n",
      "    40        0.8736             nan     0.1000    0.0005\n",
      "    60        0.8327             nan     0.1000   -0.0001\n",
      "    80        0.8057             nan     0.1000    0.0001\n",
      "   100        0.7828             nan     0.1000    0.0002\n",
      "   120        0.7655             nan     0.1000   -0.0005\n",
      "   140        0.7503             nan     0.1000   -0.0003\n",
      "   150        0.7418             nan     0.1000    0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2840             nan     0.1000    0.0368\n",
      "     2        1.2262             nan     0.1000    0.0270\n",
      "     3        1.1738             nan     0.1000    0.0249\n",
      "     4        1.1320             nan     0.1000    0.0210\n",
      "     5        1.0956             nan     0.1000    0.0164\n",
      "     6        1.0621             nan     0.1000    0.0148\n",
      "     7        1.0356             nan     0.1000    0.0123\n",
      "     8        1.0126             nan     0.1000    0.0104\n",
      "     9        0.9935             nan     0.1000    0.0088\n",
      "    10        0.9777             nan     0.1000    0.0072\n",
      "    20        0.8846             nan     0.1000    0.0017\n",
      "    40        0.8094             nan     0.1000    0.0010\n",
      "    60        0.7620             nan     0.1000   -0.0003\n",
      "    80        0.7298             nan     0.1000    0.0004\n",
      "   100        0.7065             nan     0.1000   -0.0001\n",
      "   120        0.6883             nan     0.1000   -0.0006\n",
      "   140        0.6736             nan     0.1000   -0.0007\n",
      "   150        0.6665             nan     0.1000   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3058             nan     0.1000    0.0270\n",
      "     2        1.2592             nan     0.1000    0.0242\n",
      "     3        1.2184             nan     0.1000    0.0199\n",
      "     4        1.1869             nan     0.1000    0.0151\n",
      "     5        1.1586             nan     0.1000    0.0119\n",
      "     6        1.1361             nan     0.1000    0.0112\n",
      "     7        1.1163             nan     0.1000    0.0092\n",
      "     8        1.1020             nan     0.1000    0.0076\n",
      "     9        1.0876             nan     0.1000    0.0062\n",
      "    10        1.0764             nan     0.1000    0.0046\n",
      "    20        1.0154             nan     0.1000    0.0019\n",
      "    40        0.9635             nan     0.1000    0.0008\n",
      "    60        0.9307             nan     0.1000    0.0003\n",
      "    80        0.9097             nan     0.1000   -0.0001\n",
      "   100        0.8932             nan     0.1000    0.0002\n",
      "   120        0.8803             nan     0.1000   -0.0006\n",
      "   140        0.8682             nan     0.1000   -0.0002\n",
      "   150        0.8625             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2877             nan     0.1000    0.0319\n",
      "     2        1.2326             nan     0.1000    0.0262\n",
      "     3        1.1907             nan     0.1000    0.0188\n",
      "     4        1.1552             nan     0.1000    0.0181\n",
      "     5        1.1235             nan     0.1000    0.0138\n",
      "     6        1.0962             nan     0.1000    0.0119\n",
      "     7        1.0743             nan     0.1000    0.0096\n",
      "     8        1.0532             nan     0.1000    0.0098\n",
      "     9        1.0371             nan     0.1000    0.0084\n",
      "    10        1.0237             nan     0.1000    0.0063\n",
      "    20        0.9505             nan     0.1000    0.0012\n",
      "    40        0.8787             nan     0.1000   -0.0004\n",
      "    60        0.8395             nan     0.1000   -0.0003\n",
      "    80        0.8031             nan     0.1000   -0.0004\n",
      "   100        0.7806             nan     0.1000   -0.0013\n",
      "   120        0.7592             nan     0.1000   -0.0005\n",
      "   140        0.7422             nan     0.1000   -0.0008\n",
      "   150        0.7361             nan     0.1000   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2821             nan     0.1000    0.0367\n",
      "     2        1.2253             nan     0.1000    0.0303\n",
      "     3        1.1739             nan     0.1000    0.0244\n",
      "     4        1.1342             nan     0.1000    0.0190\n",
      "     5        1.0976             nan     0.1000    0.0172\n",
      "     6        1.0689             nan     0.1000    0.0140\n",
      "     7        1.0425             nan     0.1000    0.0132\n",
      "     8        1.0177             nan     0.1000    0.0105\n",
      "     9        0.9988             nan     0.1000    0.0083\n",
      "    10        0.9825             nan     0.1000    0.0076\n",
      "    20        0.8815             nan     0.1000    0.0019\n",
      "    40        0.8028             nan     0.1000    0.0001\n",
      "    60        0.7634             nan     0.1000   -0.0010\n",
      "    80        0.7357             nan     0.1000   -0.0011\n",
      "   100        0.7126             nan     0.1000   -0.0019\n",
      "   120        0.6884             nan     0.1000   -0.0011\n",
      "   140        0.6684             nan     0.1000   -0.0017\n",
      "   150        0.6622             nan     0.1000   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2845             nan     0.1000    0.0366\n",
      "     2        1.2231             nan     0.1000    0.0291\n",
      "     3        1.1761             nan     0.1000    0.0236\n",
      "     4        1.1335             nan     0.1000    0.0197\n",
      "     5        1.0983             nan     0.1000    0.0158\n",
      "     6        1.0675             nan     0.1000    0.0143\n",
      "     7        1.0429             nan     0.1000    0.0109\n",
      "     8        1.0195             nan     0.1000    0.0111\n",
      "     9        1.0020             nan     0.1000    0.0075\n",
      "    10        0.9849             nan     0.1000    0.0082\n",
      "    20        0.8924             nan     0.1000    0.0011\n",
      "    40        0.8162             nan     0.1000    0.0012\n",
      "    60        0.7721             nan     0.1000   -0.0003\n",
      "    80        0.7426             nan     0.1000   -0.0009\n",
      "   100        0.7150             nan     0.1000   -0.0006\n",
      "   120        0.6936             nan     0.1000   -0.0004\n",
      "   140        0.6761             nan     0.1000   -0.0007\n",
      "   150        0.6682             nan     0.1000   -0.0008\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "summary.resamples(object = results)\n",
       "\n",
       "Models: gbm, rpart, glm, knn, svmRadial \n",
       "Number of resamples: 30 \n",
       "\n",
       "Accuracy \n",
       "            Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's\n",
       "gbm       0.7939  0.8171 0.8321 0.8418  0.8626 0.9008    0\n",
       "rpart     0.7538  0.7939 0.8168 0.8197  0.8454 0.9015    0\n",
       "glm       0.7405  0.7786 0.8077 0.8018  0.8219 0.8636    0\n",
       "knn       0.7000  0.7576 0.7863 0.7833  0.8092 0.8485    0\n",
       "svmRadial 0.7077  0.7793 0.8206 0.8064  0.8394 0.8788    0\n",
       "\n",
       "Kappa \n",
       "            Min. 1st Qu. Median   Mean 3rd Qu.   Max. NA's\n",
       "gbm       0.5663  0.6218 0.6505 0.6681  0.7080 0.7969    0\n",
       "rpart     0.4812  0.5675 0.6157 0.6256  0.6750 0.7922    0\n",
       "glm       0.4523  0.5396 0.5959 0.5840  0.6294 0.7114    0\n",
       "knn       0.3619  0.4960 0.5510 0.5480  0.6062 0.6884    0\n",
       "svmRadial 0.3839  0.5437 0.6272 0.5969  0.6616 0.7479    0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAAY1BMVEUAAAAAgP9NRT5NTU1o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\n2JsAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of Stacking algorithms\n",
    "# create submodels\n",
    "control <- trainControl(method=\"repeatedcv\", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)\n",
    "algorithmList <- c('gbm', 'rpart', 'glm', 'knn', 'svmRadial')\n",
    "set.seed(seed)\n",
    "models <- caretList(Survived~.-Survived, data=dataset, trControl=control, methodList=algorithmList)\n",
    "results <- resamples(models)\n",
    "summary(results)\n",
    "dotplot(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>gbm</th><th scope=col>rpart</th><th scope=col>glm</th><th scope=col>knn</th><th scope=col>svmRadial</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>gbm</th><td>1.0000000</td><td>0.7656270</td><td>0.6314683</td><td>0.5393940</td><td>0.6411182</td></tr>\n",
       "\t<tr><th scope=row>rpart</th><td>0.7656270</td><td>1.0000000</td><td>0.6701229</td><td>0.6821604</td><td>0.6914525</td></tr>\n",
       "\t<tr><th scope=row>glm</th><td>0.6314683</td><td>0.6701229</td><td>1.0000000</td><td>0.5539906</td><td>0.6744476</td></tr>\n",
       "\t<tr><th scope=row>knn</th><td>0.5393940</td><td>0.6821604</td><td>0.5539906</td><td>1.0000000</td><td>0.6727837</td></tr>\n",
       "\t<tr><th scope=row>svmRadial</th><td>0.6411182</td><td>0.6914525</td><td>0.6744476</td><td>0.6727837</td><td>1.0000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & gbm & rpart & glm & knn & svmRadial\\\\\n",
       "\\hline\n",
       "\tgbm & 1.0000000 & 0.7656270 & 0.6314683 & 0.5393940 & 0.6411182\\\\\n",
       "\trpart & 0.7656270 & 1.0000000 & 0.6701229 & 0.6821604 & 0.6914525\\\\\n",
       "\tglm & 0.6314683 & 0.6701229 & 1.0000000 & 0.5539906 & 0.6744476\\\\\n",
       "\tknn & 0.5393940 & 0.6821604 & 0.5539906 & 1.0000000 & 0.6727837\\\\\n",
       "\tsvmRadial & 0.6411182 & 0.6914525 & 0.6744476 & 0.6727837 & 1.0000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | gbm | rpart | glm | knn | svmRadial | \n",
       "|---|---|---|---|---|\n",
       "| gbm | 1.0000000 | 0.7656270 | 0.6314683 | 0.5393940 | 0.6411182 | \n",
       "| rpart | 0.7656270 | 1.0000000 | 0.6701229 | 0.6821604 | 0.6914525 | \n",
       "| glm | 0.6314683 | 0.6701229 | 1.0000000 | 0.5539906 | 0.6744476 | \n",
       "| knn | 0.5393940 | 0.6821604 | 0.5539906 | 1.0000000 | 0.6727837 | \n",
       "| svmRadial | 0.6411182 | 0.6914525 | 0.6744476 | 0.6727837 | 1.0000000 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "          gbm       rpart     glm       knn       svmRadial\n",
       "gbm       1.0000000 0.7656270 0.6314683 0.5393940 0.6411182\n",
       "rpart     0.7656270 1.0000000 0.6701229 0.6821604 0.6914525\n",
       "glm       0.6314683 0.6701229 1.0000000 0.5539906 0.6744476\n",
       "knn       0.5393940 0.6821604 0.5539906 1.0000000 0.6727837\n",
       "svmRadial 0.6411182 0.6914525 0.6744476 0.6727837 1.0000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHgCAMAAABKCk6nAAAANlBMVEUAAAAAgP9NTU1oaGh8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\nIvjkchF8crkIPrlcBJ9cLoJPLv8BcJ+U3cleTzMAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation between results\n",
    "modelCor(results)\n",
    "splom(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A glm ensemble of 2 base models: gbm, rpart, glm, knn, svmRadial\n",
      "\n",
      "Ensemble results:\n",
      "Generalized Linear Model \n",
      "\n",
      "3927 samples\n",
      "   5 predictor\n",
      "   2 classes: 'X0', 'X1' \n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 3 times) \n",
      "Summary of sample sizes: 3534, 3534, 3535, 3534, 3535, 3535, ... \n",
      "Resampling results:\n",
      "\n",
      "  Accuracy   Kappa    \n",
      "  0.8448291  0.6753849\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# stack using glm\n",
    "stackControl <- trainControl(method=\"repeatedcv\", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)\n",
    "set.seed(seed)\n",
    "stack.glm <- caretStack(models, method=\"glm\", metric=\"Accuracy\", trControl=stackControl)\n",
    "print(stack.glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2666             nan     0.1000    0.0420\n",
      "     2        1.2002             nan     0.1000    0.0345\n",
      "     3        1.1418             nan     0.1000    0.0283\n",
      "     4        1.0940             nan     0.1000    0.0245\n",
      "     5        1.0515             nan     0.1000    0.0199\n",
      "     6        1.0167             nan     0.1000    0.0176\n",
      "     7        0.9859             nan     0.1000    0.0147\n",
      "     8        0.9594             nan     0.1000    0.0127\n",
      "     9        0.9389             nan     0.1000    0.0105\n",
      "    10        0.9198             nan     0.1000    0.0095\n",
      "    20        0.8186             nan     0.1000    0.0025\n",
      "    40        0.7668             nan     0.1000    0.0001\n",
      "    60        0.7545             nan     0.1000    0.0000\n",
      "    80        0.7470             nan     0.1000   -0.0001\n",
      "   100        0.7419             nan     0.1000   -0.0003\n",
      "   120        0.7373             nan     0.1000   -0.0002\n",
      "   140        0.7334             nan     0.1000    0.0001\n",
      "   150        0.7316             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2625             nan     0.1000    0.0459\n",
      "     2        1.1870             nan     0.1000    0.0366\n",
      "     3        1.1245             nan     0.1000    0.0303\n",
      "     4        1.0735             nan     0.1000    0.0240\n",
      "     5        1.0304             nan     0.1000    0.0220\n",
      "     6        0.9939             nan     0.1000    0.0181\n",
      "     7        0.9623             nan     0.1000    0.0150\n",
      "     8        0.9373             nan     0.1000    0.0119\n",
      "     9        0.9146             nan     0.1000    0.0103\n",
      "    10        0.8958             nan     0.1000    0.0098\n",
      "    20        0.7963             nan     0.1000    0.0016\n",
      "    40        0.7481             nan     0.1000    0.0004\n",
      "    60        0.7294             nan     0.1000   -0.0002\n",
      "    80        0.7178             nan     0.1000    0.0002\n",
      "   100        0.7071             nan     0.1000   -0.0003\n",
      "   120        0.6979             nan     0.1000   -0.0003\n",
      "   140        0.6901             nan     0.1000   -0.0006\n",
      "   150        0.6855             nan     0.1000    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2627             nan     0.1000    0.0463\n",
      "     2        1.1849             nan     0.1000    0.0389\n",
      "     3        1.1204             nan     0.1000    0.0315\n",
      "     4        1.0668             nan     0.1000    0.0253\n",
      "     5        1.0226             nan     0.1000    0.0209\n",
      "     6        0.9861             nan     0.1000    0.0178\n",
      "     7        0.9552             nan     0.1000    0.0147\n",
      "     8        0.9269             nan     0.1000    0.0135\n",
      "     9        0.9034             nan     0.1000    0.0114\n",
      "    10        0.8839             nan     0.1000    0.0096\n",
      "    20        0.7829             nan     0.1000    0.0026\n",
      "    40        0.7301             nan     0.1000    0.0000\n",
      "    60        0.7067             nan     0.1000   -0.0003\n",
      "    80        0.6880             nan     0.1000   -0.0003\n",
      "   100        0.6734             nan     0.1000   -0.0000\n",
      "   120        0.6600             nan     0.1000   -0.0002\n",
      "   140        0.6481             nan     0.1000   -0.0002\n",
      "   150        0.6427             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2677             nan     0.1000    0.0417\n",
      "     2        1.1968             nan     0.1000    0.0346\n",
      "     3        1.1392             nan     0.1000    0.0278\n",
      "     4        1.0897             nan     0.1000    0.0240\n",
      "     5        1.0495             nan     0.1000    0.0199\n",
      "     6        1.0154             nan     0.1000    0.0169\n",
      "     7        0.9846             nan     0.1000    0.0143\n",
      "     8        0.9601             nan     0.1000    0.0120\n",
      "     9        0.9383             nan     0.1000    0.0102\n",
      "    10        0.9188             nan     0.1000    0.0093\n",
      "    20        0.8201             nan     0.1000    0.0022\n",
      "    40        0.7689             nan     0.1000    0.0002\n",
      "    60        0.7578             nan     0.1000   -0.0000\n",
      "    80        0.7504             nan     0.1000   -0.0002\n",
      "   100        0.7459             nan     0.1000   -0.0001\n",
      "   120        0.7405             nan     0.1000    0.0000\n",
      "   140        0.7367             nan     0.1000   -0.0003\n",
      "   150        0.7347             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2621             nan     0.1000    0.0452\n",
      "     2        1.1905             nan     0.1000    0.0356\n",
      "     3        1.1284             nan     0.1000    0.0302\n",
      "     4        1.0768             nan     0.1000    0.0259\n",
      "     5        1.0332             nan     0.1000    0.0213\n",
      "     6        0.9964             nan     0.1000    0.0182\n",
      "     7        0.9658             nan     0.1000    0.0152\n",
      "     8        0.9384             nan     0.1000    0.0125\n",
      "     9        0.9148             nan     0.1000    0.0112\n",
      "    10        0.8950             nan     0.1000    0.0097\n",
      "    20        0.7985             nan     0.1000    0.0019\n",
      "    40        0.7502             nan     0.1000    0.0002\n",
      "    60        0.7322             nan     0.1000   -0.0003\n",
      "    80        0.7209             nan     0.1000   -0.0001\n",
      "   100        0.7108             nan     0.1000   -0.0002\n",
      "   120        0.7024             nan     0.1000   -0.0006\n",
      "   140        0.6940             nan     0.1000   -0.0001\n",
      "   150        0.6894             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2573             nan     0.1000    0.0460\n",
      "     2        1.1810             nan     0.1000    0.0376\n",
      "     3        1.1194             nan     0.1000    0.0298\n",
      "     4        1.0669             nan     0.1000    0.0252\n",
      "     5        1.0238             nan     0.1000    0.0211\n",
      "     6        0.9877             nan     0.1000    0.0184\n",
      "     7        0.9556             nan     0.1000    0.0156\n",
      "     8        0.9284             nan     0.1000    0.0129\n",
      "     9        0.9039             nan     0.1000    0.0114\n",
      "    10        0.8843             nan     0.1000    0.0102\n",
      "    20        0.7861             nan     0.1000    0.0023\n",
      "    40        0.7284             nan     0.1000   -0.0000\n",
      "    60        0.7036             nan     0.1000   -0.0006\n",
      "    80        0.6865             nan     0.1000   -0.0006\n",
      "   100        0.6704             nan     0.1000   -0.0004\n",
      "   120        0.6576             nan     0.1000   -0.0002\n",
      "   140        0.6465             nan     0.1000   -0.0003\n",
      "   150        0.6387             nan     0.1000   -0.0008\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2655             nan     0.1000    0.0429\n",
      "     2        1.1961             nan     0.1000    0.0339\n",
      "     3        1.1389             nan     0.1000    0.0281\n",
      "     4        1.0898             nan     0.1000    0.0232\n",
      "     5        1.0509             nan     0.1000    0.0193\n",
      "     6        1.0154             nan     0.1000    0.0173\n",
      "     7        0.9859             nan     0.1000    0.0141\n",
      "     8        0.9608             nan     0.1000    0.0125\n",
      "     9        0.9402             nan     0.1000    0.0103\n",
      "    10        0.9213             nan     0.1000    0.0084\n",
      "    20        0.8206             nan     0.1000    0.0021\n",
      "    40        0.7715             nan     0.1000    0.0005\n",
      "    60        0.7593             nan     0.1000    0.0001\n",
      "    80        0.7526             nan     0.1000   -0.0001\n",
      "   100        0.7474             nan     0.1000   -0.0001\n",
      "   120        0.7430             nan     0.1000   -0.0001\n",
      "   140        0.7389             nan     0.1000   -0.0000\n",
      "   150        0.7371             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2622             nan     0.1000    0.0465\n",
      "     2        1.1900             nan     0.1000    0.0362\n",
      "     3        1.1294             nan     0.1000    0.0296\n",
      "     4        1.0789             nan     0.1000    0.0244\n",
      "     5        1.0355             nan     0.1000    0.0210\n",
      "     6        0.9970             nan     0.1000    0.0184\n",
      "     7        0.9664             nan     0.1000    0.0145\n",
      "     8        0.9403             nan     0.1000    0.0123\n",
      "     9        0.9174             nan     0.1000    0.0114\n",
      "    10        0.8978             nan     0.1000    0.0096\n",
      "    20        0.7981             nan     0.1000    0.0025\n",
      "    40        0.7524             nan     0.1000   -0.0001\n",
      "    60        0.7338             nan     0.1000   -0.0001\n",
      "    80        0.7226             nan     0.1000   -0.0001\n",
      "   100        0.7096             nan     0.1000   -0.0002\n",
      "   120        0.6998             nan     0.1000   -0.0005\n",
      "   140        0.6918             nan     0.1000   -0.0001\n",
      "   150        0.6866             nan     0.1000   -0.0006\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2622             nan     0.1000    0.0475\n",
      "     2        1.1870             nan     0.1000    0.0375\n",
      "     3        1.1210             nan     0.1000    0.0312\n",
      "     4        1.0684             nan     0.1000    0.0258\n",
      "     5        1.0240             nan     0.1000    0.0216\n",
      "     6        0.9866             nan     0.1000    0.0177\n",
      "     7        0.9546             nan     0.1000    0.0148\n",
      "     8        0.9275             nan     0.1000    0.0123\n",
      "     9        0.9041             nan     0.1000    0.0113\n",
      "    10        0.8864             nan     0.1000    0.0085\n",
      "    20        0.7864             nan     0.1000    0.0020\n",
      "    40        0.7329             nan     0.1000    0.0002\n",
      "    60        0.7116             nan     0.1000   -0.0002\n",
      "    80        0.6944             nan     0.1000    0.0000\n",
      "   100        0.6790             nan     0.1000    0.0003\n",
      "   120        0.6644             nan     0.1000   -0.0009\n",
      "   140        0.6516             nan     0.1000   -0.0004\n",
      "   150        0.6454             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2679             nan     0.1000    0.0430\n",
      "     2        1.1958             nan     0.1000    0.0351\n",
      "     3        1.1379             nan     0.1000    0.0287\n",
      "     4        1.0896             nan     0.1000    0.0247\n",
      "     5        1.0484             nan     0.1000    0.0203\n",
      "     6        1.0107             nan     0.1000    0.0176\n",
      "     7        0.9792             nan     0.1000    0.0153\n",
      "     8        0.9543             nan     0.1000    0.0121\n",
      "     9        0.9313             nan     0.1000    0.0111\n",
      "    10        0.9135             nan     0.1000    0.0092\n",
      "    20        0.8128             nan     0.1000    0.0025\n",
      "    40        0.7583             nan     0.1000    0.0003\n",
      "    60        0.7437             nan     0.1000    0.0001\n",
      "    80        0.7371             nan     0.1000    0.0000\n",
      "   100        0.7313             nan     0.1000    0.0001\n",
      "   120        0.7269             nan     0.1000   -0.0003\n",
      "   140        0.7231             nan     0.1000   -0.0002\n",
      "   150        0.7212             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2634             nan     0.1000    0.0463\n",
      "     2        1.1896             nan     0.1000    0.0376\n",
      "     3        1.1268             nan     0.1000    0.0312\n",
      "     4        1.0729             nan     0.1000    0.0263\n",
      "     5        1.0301             nan     0.1000    0.0211\n",
      "     6        0.9933             nan     0.1000    0.0183\n",
      "     7        0.9621             nan     0.1000    0.0154\n",
      "     8        0.9343             nan     0.1000    0.0133\n",
      "     9        0.9108             nan     0.1000    0.0117\n",
      "    10        0.8914             nan     0.1000    0.0095\n",
      "    20        0.7871             nan     0.1000    0.0027\n",
      "    40        0.7410             nan     0.1000    0.0005\n",
      "    60        0.7222             nan     0.1000    0.0000\n",
      "    80        0.7098             nan     0.1000   -0.0003\n",
      "   100        0.6991             nan     0.1000   -0.0003\n",
      "   120        0.6896             nan     0.1000    0.0000\n",
      "   140        0.6812             nan     0.1000   -0.0002\n",
      "   150        0.6770             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2595             nan     0.1000    0.0462\n",
      "     2        1.1825             nan     0.1000    0.0394\n",
      "     3        1.1180             nan     0.1000    0.0308\n",
      "     4        1.0637             nan     0.1000    0.0269\n",
      "     5        1.0187             nan     0.1000    0.0220\n",
      "     6        0.9809             nan     0.1000    0.0181\n",
      "     7        0.9503             nan     0.1000    0.0151\n",
      "     8        0.9226             nan     0.1000    0.0134\n",
      "     9        0.8997             nan     0.1000    0.0116\n",
      "    10        0.8801             nan     0.1000    0.0098\n",
      "    20        0.7757             nan     0.1000    0.0019\n",
      "    40        0.7210             nan     0.1000   -0.0003\n",
      "    60        0.7007             nan     0.1000    0.0000\n",
      "    80        0.6858             nan     0.1000    0.0002\n",
      "   100        0.6673             nan     0.1000    0.0000\n",
      "   120        0.6543             nan     0.1000   -0.0001\n",
      "   140        0.6449             nan     0.1000   -0.0001\n",
      "   150        0.6410             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2696             nan     0.1000    0.0427\n",
      "     2        1.1981             nan     0.1000    0.0354\n",
      "     3        1.1373             nan     0.1000    0.0281\n",
      "     4        1.0907             nan     0.1000    0.0231\n",
      "     5        1.0488             nan     0.1000    0.0206\n",
      "     6        1.0146             nan     0.1000    0.0167\n",
      "     7        0.9846             nan     0.1000    0.0147\n",
      "     8        0.9592             nan     0.1000    0.0116\n",
      "     9        0.9370             nan     0.1000    0.0107\n",
      "    10        0.9171             nan     0.1000    0.0098\n",
      "    20        0.8155             nan     0.1000    0.0022\n",
      "    40        0.7634             nan     0.1000    0.0003\n",
      "    60        0.7513             nan     0.1000    0.0000\n",
      "    80        0.7440             nan     0.1000   -0.0000\n",
      "   100        0.7396             nan     0.1000    0.0001\n",
      "   120        0.7353             nan     0.1000   -0.0004\n",
      "   140        0.7319             nan     0.1000   -0.0003\n",
      "   150        0.7299             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2630             nan     0.1000    0.0453\n",
      "     2        1.1871             nan     0.1000    0.0375\n",
      "     3        1.1261             nan     0.1000    0.0302\n",
      "     4        1.0739             nan     0.1000    0.0255\n",
      "     5        1.0295             nan     0.1000    0.0218\n",
      "     6        0.9940             nan     0.1000    0.0177\n",
      "     7        0.9635             nan     0.1000    0.0149\n",
      "     8        0.9373             nan     0.1000    0.0122\n",
      "     9        0.9140             nan     0.1000    0.0108\n",
      "    10        0.8928             nan     0.1000    0.0102\n",
      "    20        0.7910             nan     0.1000    0.0024\n",
      "    40        0.7464             nan     0.1000    0.0000\n",
      "    60        0.7295             nan     0.1000   -0.0001\n",
      "    80        0.7167             nan     0.1000    0.0001\n",
      "   100        0.7057             nan     0.1000   -0.0001\n",
      "   120        0.6969             nan     0.1000   -0.0002\n",
      "   140        0.6869             nan     0.1000   -0.0002\n",
      "   150        0.6824             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2589             nan     0.1000    0.0473\n",
      "     2        1.1836             nan     0.1000    0.0379\n",
      "     3        1.1188             nan     0.1000    0.0312\n",
      "     4        1.0673             nan     0.1000    0.0250\n",
      "     5        1.0219             nan     0.1000    0.0212\n",
      "     6        0.9826             nan     0.1000    0.0180\n",
      "     7        0.9510             nan     0.1000    0.0162\n",
      "     8        0.9227             nan     0.1000    0.0127\n",
      "     9        0.8999             nan     0.1000    0.0110\n",
      "    10        0.8802             nan     0.1000    0.0096\n",
      "    20        0.7771             nan     0.1000    0.0017\n",
      "    40        0.7282             nan     0.1000    0.0000\n",
      "    60        0.7088             nan     0.1000    0.0002\n",
      "    80        0.6910             nan     0.1000   -0.0003\n",
      "   100        0.6741             nan     0.1000    0.0000\n",
      "   120        0.6620             nan     0.1000   -0.0006\n",
      "   140        0.6508             nan     0.1000   -0.0002\n",
      "   150        0.6445             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2688             nan     0.1000    0.0422\n",
      "     2        1.1993             nan     0.1000    0.0347\n",
      "     3        1.1444             nan     0.1000    0.0286\n",
      "     4        1.0971             nan     0.1000    0.0248\n",
      "     5        1.0573             nan     0.1000    0.0199\n",
      "     6        1.0201             nan     0.1000    0.0178\n",
      "     7        0.9899             nan     0.1000    0.0144\n",
      "     8        0.9651             nan     0.1000    0.0124\n",
      "     9        0.9420             nan     0.1000    0.0116\n",
      "    10        0.9221             nan     0.1000    0.0088\n",
      "    20        0.8208             nan     0.1000    0.0027\n",
      "    40        0.7678             nan     0.1000    0.0004\n",
      "    60        0.7542             nan     0.1000    0.0000\n",
      "    80        0.7471             nan     0.1000   -0.0002\n",
      "   100        0.7420             nan     0.1000   -0.0001\n",
      "   120        0.7373             nan     0.1000   -0.0000\n",
      "   140        0.7340             nan     0.1000   -0.0001\n",
      "   150        0.7324             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2634             nan     0.1000    0.0453\n",
      "     2        1.1870             nan     0.1000    0.0374\n",
      "     3        1.1238             nan     0.1000    0.0300\n",
      "     4        1.0724             nan     0.1000    0.0257\n",
      "     5        1.0288             nan     0.1000    0.0206\n",
      "     6        0.9937             nan     0.1000    0.0172\n",
      "     7        0.9641             nan     0.1000    0.0147\n",
      "     8        0.9361             nan     0.1000    0.0137\n",
      "     9        0.9136             nan     0.1000    0.0110\n",
      "    10        0.8941             nan     0.1000    0.0098\n",
      "    20        0.7955             nan     0.1000    0.0012\n",
      "    40        0.7461             nan     0.1000    0.0002\n",
      "    60        0.7266             nan     0.1000   -0.0003\n",
      "    80        0.7118             nan     0.1000   -0.0002\n",
      "   100        0.7008             nan     0.1000   -0.0003\n",
      "   120        0.6929             nan     0.1000   -0.0000\n",
      "   140        0.6859             nan     0.1000   -0.0001\n",
      "   150        0.6818             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2624             nan     0.1000    0.0470\n",
      "     2        1.1855             nan     0.1000    0.0386\n",
      "     3        1.1217             nan     0.1000    0.0305\n",
      "     4        1.0684             nan     0.1000    0.0256\n",
      "     5        1.0242             nan     0.1000    0.0218\n",
      "     6        0.9868             nan     0.1000    0.0178\n",
      "     7        0.9546             nan     0.1000    0.0154\n",
      "     8        0.9263             nan     0.1000    0.0133\n",
      "     9        0.9038             nan     0.1000    0.0110\n",
      "    10        0.8852             nan     0.1000    0.0085\n",
      "    20        0.7798             nan     0.1000    0.0024\n",
      "    40        0.7271             nan     0.1000   -0.0000\n",
      "    60        0.7052             nan     0.1000   -0.0001\n",
      "    80        0.6866             nan     0.1000   -0.0000\n",
      "   100        0.6730             nan     0.1000    0.0000\n",
      "   120        0.6594             nan     0.1000   -0.0001\n",
      "   140        0.6458             nan     0.1000   -0.0002\n",
      "   150        0.6407             nan     0.1000    0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2667             nan     0.1000    0.0436\n",
      "     2        1.1955             nan     0.1000    0.0364\n",
      "     3        1.1370             nan     0.1000    0.0288\n",
      "     4        1.0861             nan     0.1000    0.0252\n",
      "     5        1.0428             nan     0.1000    0.0215\n",
      "     6        1.0075             nan     0.1000    0.0180\n",
      "     7        0.9759             nan     0.1000    0.0153\n",
      "     8        0.9487             nan     0.1000    0.0130\n",
      "     9        0.9248             nan     0.1000    0.0111\n",
      "    10        0.9057             nan     0.1000    0.0096\n",
      "    20        0.8004             nan     0.1000    0.0029\n",
      "    40        0.7474             nan     0.1000    0.0006\n",
      "    60        0.7351             nan     0.1000   -0.0002\n",
      "    80        0.7279             nan     0.1000   -0.0002\n",
      "   100        0.7226             nan     0.1000   -0.0001\n",
      "   120        0.7180             nan     0.1000   -0.0001\n",
      "   140        0.7149             nan     0.1000   -0.0005\n",
      "   150        0.7131             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2567             nan     0.1000    0.0470\n",
      "     2        1.1798             nan     0.1000    0.0375\n",
      "     3        1.1169             nan     0.1000    0.0310\n",
      "     4        1.0627             nan     0.1000    0.0254\n",
      "     5        1.0198             nan     0.1000    0.0210\n",
      "     6        0.9823             nan     0.1000    0.0185\n",
      "     7        0.9497             nan     0.1000    0.0156\n",
      "     8        0.9237             nan     0.1000    0.0131\n",
      "     9        0.9009             nan     0.1000    0.0106\n",
      "    10        0.8798             nan     0.1000    0.0104\n",
      "    20        0.7780             nan     0.1000    0.0025\n",
      "    40        0.7272             nan     0.1000    0.0002\n",
      "    60        0.7079             nan     0.1000   -0.0002\n",
      "    80        0.6969             nan     0.1000   -0.0002\n",
      "   100        0.6863             nan     0.1000   -0.0000\n",
      "   120        0.6769             nan     0.1000   -0.0001\n",
      "   140        0.6692             nan     0.1000   -0.0006\n",
      "   150        0.6650             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2576             nan     0.1000    0.0478\n",
      "     2        1.1792             nan     0.1000    0.0377\n",
      "     3        1.1148             nan     0.1000    0.0313\n",
      "     4        1.0599             nan     0.1000    0.0267\n",
      "     5        1.0137             nan     0.1000    0.0219\n",
      "     6        0.9745             nan     0.1000    0.0188\n",
      "     7        0.9412             nan     0.1000    0.0160\n",
      "     8        0.9128             nan     0.1000    0.0134\n",
      "     9        0.8887             nan     0.1000    0.0116\n",
      "    10        0.8680             nan     0.1000    0.0098\n",
      "    20        0.7619             nan     0.1000    0.0023\n",
      "    40        0.7116             nan     0.1000   -0.0001\n",
      "    60        0.6896             nan     0.1000   -0.0003\n",
      "    80        0.6719             nan     0.1000   -0.0006\n",
      "   100        0.6593             nan     0.1000   -0.0004\n",
      "   120        0.6455             nan     0.1000   -0.0004\n",
      "   140        0.6332             nan     0.1000   -0.0002\n",
      "   150        0.6273             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2672             nan     0.1000    0.0420\n",
      "     2        1.1979             nan     0.1000    0.0339\n",
      "     3        1.1427             nan     0.1000    0.0284\n",
      "     4        1.0940             nan     0.1000    0.0248\n",
      "     5        1.0536             nan     0.1000    0.0207\n",
      "     6        1.0175             nan     0.1000    0.0175\n",
      "     7        0.9878             nan     0.1000    0.0146\n",
      "     8        0.9613             nan     0.1000    0.0133\n",
      "     9        0.9419             nan     0.1000    0.0097\n",
      "    10        0.9226             nan     0.1000    0.0099\n",
      "    20        0.8160             nan     0.1000    0.0026\n",
      "    40        0.7601             nan     0.1000    0.0005\n",
      "    60        0.7467             nan     0.1000   -0.0000\n",
      "    80        0.7397             nan     0.1000   -0.0003\n",
      "   100        0.7344             nan     0.1000   -0.0002\n",
      "   120        0.7302             nan     0.1000   -0.0002\n",
      "   140        0.7261             nan     0.1000   -0.0001\n",
      "   150        0.7245             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2600             nan     0.1000    0.0464\n",
      "     2        1.1842             nan     0.1000    0.0370\n",
      "     3        1.1240             nan     0.1000    0.0294\n",
      "     4        1.0750             nan     0.1000    0.0244\n",
      "     5        1.0325             nan     0.1000    0.0212\n",
      "     6        0.9935             nan     0.1000    0.0187\n",
      "     7        0.9610             nan     0.1000    0.0158\n",
      "     8        0.9339             nan     0.1000    0.0131\n",
      "     9        0.9114             nan     0.1000    0.0112\n",
      "    10        0.8909             nan     0.1000    0.0090\n",
      "    20        0.7899             nan     0.1000    0.0020\n",
      "    40        0.7409             nan     0.1000    0.0005\n",
      "    60        0.7244             nan     0.1000    0.0001\n",
      "    80        0.7127             nan     0.1000   -0.0001\n",
      "   100        0.7022             nan     0.1000    0.0001\n",
      "   120        0.6928             nan     0.1000   -0.0001\n",
      "   140        0.6843             nan     0.1000   -0.0003\n",
      "   150        0.6810             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2591             nan     0.1000    0.0456\n",
      "     2        1.1828             nan     0.1000    0.0377\n",
      "     3        1.1200             nan     0.1000    0.0313\n",
      "     4        1.0657             nan     0.1000    0.0266\n",
      "     5        1.0209             nan     0.1000    0.0215\n",
      "     6        0.9850             nan     0.1000    0.0178\n",
      "     7        0.9543             nan     0.1000    0.0151\n",
      "     8        0.9266             nan     0.1000    0.0136\n",
      "     9        0.9030             nan     0.1000    0.0114\n",
      "    10        0.8823             nan     0.1000    0.0094\n",
      "    20        0.7762             nan     0.1000    0.0028\n",
      "    40        0.7212             nan     0.1000   -0.0004\n",
      "    60        0.7010             nan     0.1000   -0.0003\n",
      "    80        0.6817             nan     0.1000   -0.0003\n",
      "   100        0.6665             nan     0.1000   -0.0002\n",
      "   120        0.6534             nan     0.1000   -0.0005\n",
      "   140        0.6408             nan     0.1000   -0.0002\n",
      "   150        0.6347             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2659             nan     0.1000    0.0431\n",
      "     2        1.1967             nan     0.1000    0.0339\n",
      "     3        1.1386             nan     0.1000    0.0289\n",
      "     4        1.0895             nan     0.1000    0.0238\n",
      "     5        1.0480             nan     0.1000    0.0216\n",
      "     6        1.0128             nan     0.1000    0.0170\n",
      "     7        0.9810             nan     0.1000    0.0157\n",
      "     8        0.9540             nan     0.1000    0.0130\n",
      "     9        0.9306             nan     0.1000    0.0112\n",
      "    10        0.9111             nan     0.1000    0.0090\n",
      "    20        0.8100             nan     0.1000    0.0025\n",
      "    40        0.7562             nan     0.1000    0.0006\n",
      "    60        0.7430             nan     0.1000    0.0000\n",
      "    80        0.7353             nan     0.1000   -0.0000\n",
      "   100        0.7305             nan     0.1000   -0.0001\n",
      "   120        0.7270             nan     0.1000   -0.0004\n",
      "   140        0.7241             nan     0.1000   -0.0005\n",
      "   150        0.7221             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2589             nan     0.1000    0.0474\n",
      "     2        1.1837             nan     0.1000    0.0378\n",
      "     3        1.1210             nan     0.1000    0.0309\n",
      "     4        1.0698             nan     0.1000    0.0257\n",
      "     5        1.0260             nan     0.1000    0.0205\n",
      "     6        0.9897             nan     0.1000    0.0177\n",
      "     7        0.9581             nan     0.1000    0.0156\n",
      "     8        0.9326             nan     0.1000    0.0126\n",
      "     9        0.9089             nan     0.1000    0.0116\n",
      "    10        0.8882             nan     0.1000    0.0100\n",
      "    20        0.7871             nan     0.1000    0.0013\n",
      "    40        0.7371             nan     0.1000    0.0000\n",
      "    60        0.7193             nan     0.1000   -0.0005\n",
      "    80        0.7054             nan     0.1000   -0.0002\n",
      "   100        0.6968             nan     0.1000   -0.0003\n",
      "   120        0.6887             nan     0.1000   -0.0005\n",
      "   140        0.6805             nan     0.1000   -0.0003\n",
      "   150        0.6768             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2587             nan     0.1000    0.0473\n",
      "     2        1.1806             nan     0.1000    0.0380\n",
      "     3        1.1156             nan     0.1000    0.0318\n",
      "     4        1.0616             nan     0.1000    0.0264\n",
      "     5        1.0176             nan     0.1000    0.0221\n",
      "     6        0.9807             nan     0.1000    0.0186\n",
      "     7        0.9481             nan     0.1000    0.0158\n",
      "     8        0.9206             nan     0.1000    0.0133\n",
      "     9        0.8966             nan     0.1000    0.0111\n",
      "    10        0.8776             nan     0.1000    0.0095\n",
      "    20        0.7718             nan     0.1000    0.0012\n",
      "    40        0.7203             nan     0.1000   -0.0002\n",
      "    60        0.6978             nan     0.1000   -0.0001\n",
      "    80        0.6796             nan     0.1000    0.0001\n",
      "   100        0.6659             nan     0.1000   -0.0002\n",
      "   120        0.6530             nan     0.1000   -0.0003\n",
      "   140        0.6403             nan     0.1000   -0.0003\n",
      "   150        0.6353             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2680             nan     0.1000    0.0427\n",
      "     2        1.1977             nan     0.1000    0.0350\n",
      "     3        1.1381             nan     0.1000    0.0288\n",
      "     4        1.0893             nan     0.1000    0.0239\n",
      "     5        1.0477             nan     0.1000    0.0200\n",
      "     6        1.0157             nan     0.1000    0.0164\n",
      "     7        0.9861             nan     0.1000    0.0151\n",
      "     8        0.9598             nan     0.1000    0.0129\n",
      "     9        0.9369             nan     0.1000    0.0107\n",
      "    10        0.9180             nan     0.1000    0.0087\n",
      "    20        0.8165             nan     0.1000    0.0026\n",
      "    40        0.7646             nan     0.1000    0.0003\n",
      "    60        0.7513             nan     0.1000   -0.0001\n",
      "    80        0.7444             nan     0.1000   -0.0003\n",
      "   100        0.7392             nan     0.1000   -0.0000\n",
      "   120        0.7354             nan     0.1000   -0.0002\n",
      "   140        0.7321             nan     0.1000   -0.0005\n",
      "   150        0.7302             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2649             nan     0.1000    0.0442\n",
      "     2        1.1883             nan     0.1000    0.0379\n",
      "     3        1.1273             nan     0.1000    0.0310\n",
      "     4        1.0750             nan     0.1000    0.0259\n",
      "     5        1.0303             nan     0.1000    0.0217\n",
      "     6        0.9949             nan     0.1000    0.0171\n",
      "     7        0.9607             nan     0.1000    0.0154\n",
      "     8        0.9353             nan     0.1000    0.0124\n",
      "     9        0.9125             nan     0.1000    0.0110\n",
      "    10        0.8921             nan     0.1000    0.0097\n",
      "    20        0.7911             nan     0.1000    0.0021\n",
      "    40        0.7455             nan     0.1000    0.0003\n",
      "    60        0.7247             nan     0.1000    0.0001\n",
      "    80        0.7134             nan     0.1000   -0.0000\n",
      "   100        0.7025             nan     0.1000   -0.0006\n",
      "   120        0.6931             nan     0.1000   -0.0002\n",
      "   140        0.6835             nan     0.1000   -0.0002\n",
      "   150        0.6796             nan     0.1000    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2574             nan     0.1000    0.0467\n",
      "     2        1.1821             nan     0.1000    0.0378\n",
      "     3        1.1190             nan     0.1000    0.0305\n",
      "     4        1.0670             nan     0.1000    0.0255\n",
      "     5        1.0213             nan     0.1000    0.0220\n",
      "     6        0.9831             nan     0.1000    0.0182\n",
      "     7        0.9512             nan     0.1000    0.0150\n",
      "     8        0.9234             nan     0.1000    0.0130\n",
      "     9        0.8998             nan     0.1000    0.0113\n",
      "    10        0.8798             nan     0.1000    0.0099\n",
      "    20        0.7789             nan     0.1000    0.0018\n",
      "    40        0.7279             nan     0.1000    0.0003\n",
      "    60        0.7023             nan     0.1000   -0.0000\n",
      "    80        0.6850             nan     0.1000   -0.0007\n",
      "   100        0.6705             nan     0.1000   -0.0007\n",
      "   120        0.6550             nan     0.1000   -0.0002\n",
      "   140        0.6430             nan     0.1000   -0.0001\n",
      "   150        0.6370             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2703             nan     0.1000    0.0422\n",
      "     2        1.1968             nan     0.1000    0.0352\n",
      "     3        1.1407             nan     0.1000    0.0283\n",
      "     4        1.0935             nan     0.1000    0.0238\n",
      "     5        1.0524             nan     0.1000    0.0207\n",
      "     6        1.0173             nan     0.1000    0.0173\n",
      "     7        0.9869             nan     0.1000    0.0144\n",
      "     8        0.9614             nan     0.1000    0.0123\n",
      "     9        0.9370             nan     0.1000    0.0115\n",
      "    10        0.9173             nan     0.1000    0.0096\n",
      "    20        0.8176             nan     0.1000    0.0027\n",
      "    40        0.7650             nan     0.1000    0.0004\n",
      "    60        0.7531             nan     0.1000   -0.0001\n",
      "    80        0.7449             nan     0.1000   -0.0000\n",
      "   100        0.7393             nan     0.1000   -0.0002\n",
      "   120        0.7349             nan     0.1000   -0.0002\n",
      "   140        0.7312             nan     0.1000   -0.0005\n",
      "   150        0.7294             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2609             nan     0.1000    0.0461\n",
      "     2        1.1870             nan     0.1000    0.0368\n",
      "     3        1.1231             nan     0.1000    0.0311\n",
      "     4        1.0735             nan     0.1000    0.0248\n",
      "     5        1.0302             nan     0.1000    0.0216\n",
      "     6        0.9928             nan     0.1000    0.0180\n",
      "     7        0.9620             nan     0.1000    0.0151\n",
      "     8        0.9356             nan     0.1000    0.0126\n",
      "     9        0.9135             nan     0.1000    0.0101\n",
      "    10        0.8940             nan     0.1000    0.0095\n",
      "    20        0.7932             nan     0.1000    0.0016\n",
      "    40        0.7438             nan     0.1000    0.0003\n",
      "    60        0.7258             nan     0.1000   -0.0001\n",
      "    80        0.7120             nan     0.1000   -0.0001\n",
      "   100        0.7009             nan     0.1000   -0.0002\n",
      "   120        0.6906             nan     0.1000   -0.0000\n",
      "   140        0.6830             nan     0.1000   -0.0001\n",
      "   150        0.6781             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2605             nan     0.1000    0.0470\n",
      "     2        1.1837             nan     0.1000    0.0380\n",
      "     3        1.1199             nan     0.1000    0.0307\n",
      "     4        1.0688             nan     0.1000    0.0259\n",
      "     5        1.0234             nan     0.1000    0.0227\n",
      "     6        0.9858             nan     0.1000    0.0171\n",
      "     7        0.9535             nan     0.1000    0.0158\n",
      "     8        0.9269             nan     0.1000    0.0133\n",
      "     9        0.9035             nan     0.1000    0.0116\n",
      "    10        0.8833             nan     0.1000    0.0103\n",
      "    20        0.7803             nan     0.1000    0.0020\n",
      "    40        0.7293             nan     0.1000    0.0001\n",
      "    60        0.7022             nan     0.1000    0.0001\n",
      "    80        0.6844             nan     0.1000   -0.0003\n",
      "   100        0.6653             nan     0.1000   -0.0000\n",
      "   120        0.6509             nan     0.1000   -0.0004\n",
      "   140        0.6392             nan     0.1000   -0.0003\n",
      "   150        0.6344             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2637             nan     0.1000    0.0440\n",
      "     2        1.1929             nan     0.1000    0.0348\n",
      "     3        1.1356             nan     0.1000    0.0291\n",
      "     4        1.0877             nan     0.1000    0.0241\n",
      "     5        1.0477             nan     0.1000    0.0209\n",
      "     6        1.0118             nan     0.1000    0.0176\n",
      "     7        0.9807             nan     0.1000    0.0148\n",
      "     8        0.9562             nan     0.1000    0.0126\n",
      "     9        0.9354             nan     0.1000    0.0113\n",
      "    10        0.9142             nan     0.1000    0.0102\n",
      "    20        0.8116             nan     0.1000    0.0025\n",
      "    40        0.7560             nan     0.1000    0.0003\n",
      "    60        0.7417             nan     0.1000   -0.0002\n",
      "    80        0.7344             nan     0.1000   -0.0005\n",
      "   100        0.7297             nan     0.1000   -0.0002\n",
      "   120        0.7254             nan     0.1000   -0.0002\n",
      "   140        0.7224             nan     0.1000   -0.0004\n",
      "   150        0.7211             nan     0.1000    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2607             nan     0.1000    0.0468\n",
      "     2        1.1874             nan     0.1000    0.0375\n",
      "     3        1.1247             nan     0.1000    0.0306\n",
      "     4        1.0714             nan     0.1000    0.0249\n",
      "     5        1.0276             nan     0.1000    0.0221\n",
      "     6        0.9914             nan     0.1000    0.0180\n",
      "     7        0.9605             nan     0.1000    0.0152\n",
      "     8        0.9335             nan     0.1000    0.0134\n",
      "     9        0.9091             nan     0.1000    0.0115\n",
      "    10        0.8881             nan     0.1000    0.0102\n",
      "    20        0.7850             nan     0.1000    0.0022\n",
      "    40        0.7374             nan     0.1000    0.0001\n",
      "    60        0.7175             nan     0.1000    0.0001\n",
      "    80        0.7049             nan     0.1000   -0.0001\n",
      "   100        0.6918             nan     0.1000   -0.0003\n",
      "   120        0.6822             nan     0.1000   -0.0008\n",
      "   140        0.6743             nan     0.1000   -0.0002\n",
      "   150        0.6705             nan     0.1000    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2611             nan     0.1000    0.0469\n",
      "     2        1.1832             nan     0.1000    0.0389\n",
      "     3        1.1161             nan     0.1000    0.0321\n",
      "     4        1.0622             nan     0.1000    0.0257\n",
      "     5        1.0173             nan     0.1000    0.0218\n",
      "     6        0.9769             nan     0.1000    0.0190\n",
      "     7        0.9454             nan     0.1000    0.0155\n",
      "     8        0.9185             nan     0.1000    0.0134\n",
      "     9        0.8941             nan     0.1000    0.0115\n",
      "    10        0.8740             nan     0.1000    0.0098\n",
      "    20        0.7690             nan     0.1000    0.0015\n",
      "    40        0.7145             nan     0.1000    0.0000\n",
      "    60        0.6920             nan     0.1000   -0.0002\n",
      "    80        0.6746             nan     0.1000   -0.0005\n",
      "   100        0.6622             nan     0.1000   -0.0002\n",
      "   120        0.6483             nan     0.1000   -0.0002\n",
      "   140        0.6359             nan     0.1000    0.0002\n",
      "   150        0.6309             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2625             nan     0.1000    0.0444\n",
      "     2        1.1908             nan     0.1000    0.0354\n",
      "     3        1.1316             nan     0.1000    0.0294\n",
      "     4        1.0817             nan     0.1000    0.0246\n",
      "     5        1.0379             nan     0.1000    0.0209\n",
      "     6        1.0040             nan     0.1000    0.0170\n",
      "     7        0.9729             nan     0.1000    0.0150\n",
      "     8        0.9455             nan     0.1000    0.0126\n",
      "     9        0.9241             nan     0.1000    0.0109\n",
      "    10        0.9060             nan     0.1000    0.0095\n",
      "    20        0.8041             nan     0.1000    0.0022\n",
      "    40        0.7507             nan     0.1000    0.0005\n",
      "    60        0.7393             nan     0.1000    0.0001\n",
      "    80        0.7324             nan     0.1000   -0.0002\n",
      "   100        0.7280             nan     0.1000   -0.0000\n",
      "   120        0.7233             nan     0.1000   -0.0001\n",
      "   140        0.7203             nan     0.1000   -0.0001\n",
      "   150        0.7186             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2590             nan     0.1000    0.0473\n",
      "     2        1.1809             nan     0.1000    0.0384\n",
      "     3        1.1200             nan     0.1000    0.0309\n",
      "     4        1.0700             nan     0.1000    0.0257\n",
      "     5        1.0250             nan     0.1000    0.0216\n",
      "     6        0.9882             nan     0.1000    0.0178\n",
      "     7        0.9546             nan     0.1000    0.0160\n",
      "     8        0.9269             nan     0.1000    0.0140\n",
      "     9        0.9036             nan     0.1000    0.0111\n",
      "    10        0.8830             nan     0.1000    0.0099\n",
      "    20        0.7779             nan     0.1000    0.0026\n",
      "    40        0.7335             nan     0.1000    0.0000\n",
      "    60        0.7157             nan     0.1000   -0.0000\n",
      "    80        0.7052             nan     0.1000   -0.0003\n",
      "   100        0.6951             nan     0.1000   -0.0002\n",
      "   120        0.6862             nan     0.1000   -0.0000\n",
      "   140        0.6788             nan     0.1000   -0.0002\n",
      "   150        0.6758             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2575             nan     0.1000    0.0479\n",
      "     2        1.1813             nan     0.1000    0.0378\n",
      "     3        1.1170             nan     0.1000    0.0316\n",
      "     4        1.0631             nan     0.1000    0.0261\n",
      "     5        1.0158             nan     0.1000    0.0229\n",
      "     6        0.9762             nan     0.1000    0.0187\n",
      "     7        0.9439             nan     0.1000    0.0157\n",
      "     8        0.9157             nan     0.1000    0.0137\n",
      "     9        0.8928             nan     0.1000    0.0106\n",
      "    10        0.8727             nan     0.1000    0.0091\n",
      "    20        0.7685             nan     0.1000    0.0014\n",
      "    40        0.7166             nan     0.1000    0.0003\n",
      "    60        0.6920             nan     0.1000   -0.0000\n",
      "    80        0.6755             nan     0.1000   -0.0001\n",
      "   100        0.6622             nan     0.1000   -0.0002\n",
      "   120        0.6471             nan     0.1000   -0.0008\n",
      "   140        0.6343             nan     0.1000   -0.0002\n",
      "   150        0.6295             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2670             nan     0.1000    0.0429\n",
      "     2        1.1955             nan     0.1000    0.0352\n",
      "     3        1.1392             nan     0.1000    0.0280\n",
      "     4        1.0884             nan     0.1000    0.0245\n",
      "     5        1.0478             nan     0.1000    0.0201\n",
      "     6        1.0135             nan     0.1000    0.0169\n",
      "     7        0.9813             nan     0.1000    0.0152\n",
      "     8        0.9556             nan     0.1000    0.0124\n",
      "     9        0.9332             nan     0.1000    0.0109\n",
      "    10        0.9132             nan     0.1000    0.0092\n",
      "    20        0.8122             nan     0.1000    0.0025\n",
      "    40        0.7604             nan     0.1000    0.0002\n",
      "    60        0.7480             nan     0.1000   -0.0004\n",
      "    80        0.7410             nan     0.1000   -0.0001\n",
      "   100        0.7357             nan     0.1000   -0.0001\n",
      "   120        0.7318             nan     0.1000    0.0000\n",
      "   140        0.7284             nan     0.1000   -0.0000\n",
      "   150        0.7270             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2611             nan     0.1000    0.0465\n",
      "     2        1.1842             nan     0.1000    0.0375\n",
      "     3        1.1229             nan     0.1000    0.0306\n",
      "     4        1.0715             nan     0.1000    0.0251\n",
      "     5        1.0294             nan     0.1000    0.0216\n",
      "     6        0.9947             nan     0.1000    0.0174\n",
      "     7        0.9632             nan     0.1000    0.0152\n",
      "     8        0.9354             nan     0.1000    0.0123\n",
      "     9        0.9125             nan     0.1000    0.0112\n",
      "    10        0.8930             nan     0.1000    0.0094\n",
      "    20        0.7889             nan     0.1000    0.0015\n",
      "    40        0.7422             nan     0.1000    0.0002\n",
      "    60        0.7240             nan     0.1000   -0.0005\n",
      "    80        0.7102             nan     0.1000   -0.0001\n",
      "   100        0.7012             nan     0.1000   -0.0005\n",
      "   120        0.6921             nan     0.1000   -0.0003\n",
      "   140        0.6842             nan     0.1000   -0.0002\n",
      "   150        0.6801             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2568             nan     0.1000    0.0474\n",
      "     2        1.1806             nan     0.1000    0.0377\n",
      "     3        1.1177             nan     0.1000    0.0316\n",
      "     4        1.0650             nan     0.1000    0.0256\n",
      "     5        1.0222             nan     0.1000    0.0210\n",
      "     6        0.9836             nan     0.1000    0.0187\n",
      "     7        0.9510             nan     0.1000    0.0156\n",
      "     8        0.9246             nan     0.1000    0.0123\n",
      "     9        0.9002             nan     0.1000    0.0118\n",
      "    10        0.8794             nan     0.1000    0.0102\n",
      "    20        0.7761             nan     0.1000    0.0023\n",
      "    40        0.7231             nan     0.1000    0.0002\n",
      "    60        0.6998             nan     0.1000   -0.0003\n",
      "    80        0.6826             nan     0.1000   -0.0006\n",
      "   100        0.6679             nan     0.1000   -0.0001\n",
      "   120        0.6547             nan     0.1000   -0.0001\n",
      "   140        0.6409             nan     0.1000   -0.0001\n",
      "   150        0.6375             nan     0.1000   -0.0011\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2685             nan     0.1000    0.0417\n",
      "     2        1.1992             nan     0.1000    0.0343\n",
      "     3        1.1421             nan     0.1000    0.0278\n",
      "     4        1.0936             nan     0.1000    0.0237\n",
      "     5        1.0532             nan     0.1000    0.0200\n",
      "     6        1.0169             nan     0.1000    0.0174\n",
      "     7        0.9863             nan     0.1000    0.0143\n",
      "     8        0.9606             nan     0.1000    0.0120\n",
      "     9        0.9387             nan     0.1000    0.0103\n",
      "    10        0.9195             nan     0.1000    0.0091\n",
      "    20        0.8242             nan     0.1000    0.0020\n",
      "    40        0.7713             nan     0.1000    0.0005\n",
      "    60        0.7588             nan     0.1000    0.0001\n",
      "    80        0.7514             nan     0.1000   -0.0002\n",
      "   100        0.7461             nan     0.1000    0.0000\n",
      "   120        0.7421             nan     0.1000   -0.0001\n",
      "   140        0.7384             nan     0.1000   -0.0003\n",
      "   150        0.7369             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2619             nan     0.1000    0.0454\n",
      "     2        1.1882             nan     0.1000    0.0365\n",
      "     3        1.1257             nan     0.1000    0.0300\n",
      "     4        1.0752             nan     0.1000    0.0244\n",
      "     5        1.0342             nan     0.1000    0.0197\n",
      "     6        1.0004             nan     0.1000    0.0175\n",
      "     7        0.9688             nan     0.1000    0.0155\n",
      "     8        0.9423             nan     0.1000    0.0121\n",
      "     9        0.9193             nan     0.1000    0.0115\n",
      "    10        0.9002             nan     0.1000    0.0089\n",
      "    20        0.8011             nan     0.1000    0.0017\n",
      "    40        0.7558             nan     0.1000    0.0006\n",
      "    60        0.7397             nan     0.1000   -0.0004\n",
      "    80        0.7276             nan     0.1000    0.0005\n",
      "   100        0.7173             nan     0.1000   -0.0002\n",
      "   120        0.7078             nan     0.1000   -0.0001\n",
      "   140        0.6999             nan     0.1000   -0.0000\n",
      "   150        0.6962             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2604             nan     0.1000    0.0466\n",
      "     2        1.1843             nan     0.1000    0.0371\n",
      "     3        1.1240             nan     0.1000    0.0300\n",
      "     4        1.0704             nan     0.1000    0.0258\n",
      "     5        1.0281             nan     0.1000    0.0213\n",
      "     6        0.9913             nan     0.1000    0.0191\n",
      "     7        0.9588             nan     0.1000    0.0155\n",
      "     8        0.9329             nan     0.1000    0.0132\n",
      "     9        0.9098             nan     0.1000    0.0115\n",
      "    10        0.8893             nan     0.1000    0.0099\n",
      "    20        0.7850             nan     0.1000    0.0017\n",
      "    40        0.7346             nan     0.1000   -0.0003\n",
      "    60        0.7106             nan     0.1000   -0.0004\n",
      "    80        0.6934             nan     0.1000    0.0002\n",
      "   100        0.6784             nan     0.1000   -0.0001\n",
      "   120        0.6653             nan     0.1000   -0.0004\n",
      "   140        0.6546             nan     0.1000   -0.0003\n",
      "   150        0.6494             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2638             nan     0.1000    0.0442\n",
      "     2        1.1932             nan     0.1000    0.0348\n",
      "     3        1.1355             nan     0.1000    0.0277\n",
      "     4        1.0855             nan     0.1000    0.0236\n",
      "     5        1.0444             nan     0.1000    0.0211\n",
      "     6        1.0089             nan     0.1000    0.0174\n",
      "     7        0.9798             nan     0.1000    0.0154\n",
      "     8        0.9548             nan     0.1000    0.0128\n",
      "     9        0.9315             nan     0.1000    0.0113\n",
      "    10        0.9124             nan     0.1000    0.0092\n",
      "    20        0.8101             nan     0.1000    0.0025\n",
      "    40        0.7565             nan     0.1000    0.0004\n",
      "    60        0.7465             nan     0.1000   -0.0002\n",
      "    80        0.7385             nan     0.1000   -0.0002\n",
      "   100        0.7329             nan     0.1000    0.0000\n",
      "   120        0.7293             nan     0.1000   -0.0002\n",
      "   140        0.7253             nan     0.1000   -0.0001\n",
      "   150        0.7237             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2601             nan     0.1000    0.0470\n",
      "     2        1.1831             nan     0.1000    0.0377\n",
      "     3        1.1200             nan     0.1000    0.0299\n",
      "     4        1.0685             nan     0.1000    0.0261\n",
      "     5        1.0245             nan     0.1000    0.0215\n",
      "     6        0.9861             nan     0.1000    0.0181\n",
      "     7        0.9565             nan     0.1000    0.0152\n",
      "     8        0.9298             nan     0.1000    0.0132\n",
      "     9        0.9065             nan     0.1000    0.0108\n",
      "    10        0.8857             nan     0.1000    0.0101\n",
      "    20        0.7826             nan     0.1000    0.0027\n",
      "    40        0.7367             nan     0.1000    0.0002\n",
      "    60        0.7215             nan     0.1000    0.0001\n",
      "    80        0.7088             nan     0.1000    0.0000\n",
      "   100        0.6968             nan     0.1000   -0.0002\n",
      "   120        0.6855             nan     0.1000    0.0001\n",
      "   140        0.6781             nan     0.1000   -0.0001\n",
      "   150        0.6739             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2587             nan     0.1000    0.0470\n",
      "     2        1.1796             nan     0.1000    0.0387\n",
      "     3        1.1141             nan     0.1000    0.0316\n",
      "     4        1.0614             nan     0.1000    0.0260\n",
      "     5        1.0158             nan     0.1000    0.0210\n",
      "     6        0.9775             nan     0.1000    0.0185\n",
      "     7        0.9451             nan     0.1000    0.0151\n",
      "     8        0.9175             nan     0.1000    0.0131\n",
      "     9        0.8933             nan     0.1000    0.0107\n",
      "    10        0.8745             nan     0.1000    0.0093\n",
      "    20        0.7723             nan     0.1000    0.0018\n",
      "    40        0.7210             nan     0.1000    0.0000\n",
      "    60        0.6953             nan     0.1000    0.0002\n",
      "    80        0.6759             nan     0.1000   -0.0002\n",
      "   100        0.6623             nan     0.1000   -0.0005\n",
      "   120        0.6472             nan     0.1000   -0.0001\n",
      "   140        0.6366             nan     0.1000   -0.0002\n",
      "   150        0.6319             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2654             nan     0.1000    0.0430\n",
      "     2        1.1956             nan     0.1000    0.0346\n",
      "     3        1.1379             nan     0.1000    0.0283\n",
      "     4        1.0908             nan     0.1000    0.0234\n",
      "     5        1.0470             nan     0.1000    0.0205\n",
      "     6        1.0104             nan     0.1000    0.0181\n",
      "     7        0.9800             nan     0.1000    0.0143\n",
      "     8        0.9534             nan     0.1000    0.0129\n",
      "     9        0.9316             nan     0.1000    0.0105\n",
      "    10        0.9124             nan     0.1000    0.0091\n",
      "    20        0.8117             nan     0.1000    0.0027\n",
      "    40        0.7596             nan     0.1000    0.0005\n",
      "    60        0.7475             nan     0.1000    0.0000\n",
      "    80        0.7400             nan     0.1000   -0.0002\n",
      "   100        0.7338             nan     0.1000   -0.0001\n",
      "   120        0.7298             nan     0.1000   -0.0002\n",
      "   140        0.7262             nan     0.1000   -0.0004\n",
      "   150        0.7249             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2598             nan     0.1000    0.0475\n",
      "     2        1.1849             nan     0.1000    0.0379\n",
      "     3        1.1211             nan     0.1000    0.0313\n",
      "     4        1.0690             nan     0.1000    0.0251\n",
      "     5        1.0268             nan     0.1000    0.0206\n",
      "     6        0.9915             nan     0.1000    0.0172\n",
      "     7        0.9601             nan     0.1000    0.0146\n",
      "     8        0.9341             nan     0.1000    0.0123\n",
      "     9        0.9099             nan     0.1000    0.0111\n",
      "    10        0.8889             nan     0.1000    0.0099\n",
      "    20        0.7892             nan     0.1000    0.0020\n",
      "    40        0.7408             nan     0.1000    0.0005\n",
      "    60        0.7217             nan     0.1000    0.0001\n",
      "    80        0.7102             nan     0.1000   -0.0001\n",
      "   100        0.7003             nan     0.1000   -0.0001\n",
      "   120        0.6918             nan     0.1000   -0.0003\n",
      "   140        0.6838             nan     0.1000    0.0001\n",
      "   150        0.6797             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2594             nan     0.1000    0.0463\n",
      "     2        1.1823             nan     0.1000    0.0390\n",
      "     3        1.1174             nan     0.1000    0.0320\n",
      "     4        1.0640             nan     0.1000    0.0271\n",
      "     5        1.0190             nan     0.1000    0.0215\n",
      "     6        0.9812             nan     0.1000    0.0182\n",
      "     7        0.9505             nan     0.1000    0.0150\n",
      "     8        0.9236             nan     0.1000    0.0131\n",
      "     9        0.8989             nan     0.1000    0.0116\n",
      "    10        0.8795             nan     0.1000    0.0096\n",
      "    20        0.7769             nan     0.1000    0.0022\n",
      "    40        0.7206             nan     0.1000   -0.0003\n",
      "    60        0.6970             nan     0.1000    0.0001\n",
      "    80        0.6804             nan     0.1000   -0.0001\n",
      "   100        0.6664             nan     0.1000    0.0002\n",
      "   120        0.6529             nan     0.1000   -0.0004\n",
      "   140        0.6407             nan     0.1000    0.0001\n",
      "   150        0.6361             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2684             nan     0.1000    0.0424\n",
      "     2        1.2008             nan     0.1000    0.0341\n",
      "     3        1.1431             nan     0.1000    0.0280\n",
      "     4        1.0958             nan     0.1000    0.0235\n",
      "     5        1.0558             nan     0.1000    0.0203\n",
      "     6        1.0209             nan     0.1000    0.0173\n",
      "     7        0.9920             nan     0.1000    0.0144\n",
      "     8        0.9652             nan     0.1000    0.0130\n",
      "     9        0.9428             nan     0.1000    0.0105\n",
      "    10        0.9239             nan     0.1000    0.0086\n",
      "    20        0.8253             nan     0.1000    0.0025\n",
      "    40        0.7735             nan     0.1000    0.0006\n",
      "    60        0.7603             nan     0.1000   -0.0001\n",
      "    80        0.7524             nan     0.1000   -0.0000\n",
      "   100        0.7474             nan     0.1000   -0.0000\n",
      "   120        0.7424             nan     0.1000   -0.0002\n",
      "   140        0.7391             nan     0.1000   -0.0002\n",
      "   150        0.7374             nan     0.1000    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2656             nan     0.1000    0.0432\n",
      "     2        1.1904             nan     0.1000    0.0366\n",
      "     3        1.1304             nan     0.1000    0.0289\n",
      "     4        1.0784             nan     0.1000    0.0254\n",
      "     5        1.0357             nan     0.1000    0.0208\n",
      "     6        1.0001             nan     0.1000    0.0171\n",
      "     7        0.9687             nan     0.1000    0.0159\n",
      "     8        0.9413             nan     0.1000    0.0128\n",
      "     9        0.9177             nan     0.1000    0.0116\n",
      "    10        0.8975             nan     0.1000    0.0097\n",
      "    20        0.7993             nan     0.1000    0.0019\n",
      "    40        0.7508             nan     0.1000    0.0003\n",
      "    60        0.7322             nan     0.1000   -0.0001\n",
      "    80        0.7174             nan     0.1000   -0.0002\n",
      "   100        0.7072             nan     0.1000    0.0002\n",
      "   120        0.6987             nan     0.1000   -0.0001\n",
      "   140        0.6901             nan     0.1000   -0.0004\n",
      "   150        0.6865             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2596             nan     0.1000    0.0462\n",
      "     2        1.1846             nan     0.1000    0.0374\n",
      "     3        1.1224             nan     0.1000    0.0305\n",
      "     4        1.0707             nan     0.1000    0.0258\n",
      "     5        1.0272             nan     0.1000    0.0216\n",
      "     6        0.9897             nan     0.1000    0.0185\n",
      "     7        0.9571             nan     0.1000    0.0156\n",
      "     8        0.9299             nan     0.1000    0.0133\n",
      "     9        0.9072             nan     0.1000    0.0107\n",
      "    10        0.8875             nan     0.1000    0.0097\n",
      "    20        0.7857             nan     0.1000    0.0019\n",
      "    40        0.7353             nan     0.1000    0.0002\n",
      "    60        0.7114             nan     0.1000   -0.0006\n",
      "    80        0.6952             nan     0.1000   -0.0003\n",
      "   100        0.6801             nan     0.1000   -0.0003\n",
      "   120        0.6685             nan     0.1000   -0.0002\n",
      "   140        0.6568             nan     0.1000   -0.0001\n",
      "   150        0.6526             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2671             nan     0.1000    0.0421\n",
      "     2        1.1997             nan     0.1000    0.0348\n",
      "     3        1.1424             nan     0.1000    0.0279\n",
      "     4        1.0953             nan     0.1000    0.0235\n",
      "     5        1.0521             nan     0.1000    0.0207\n",
      "     6        1.0169             nan     0.1000    0.0170\n",
      "     7        0.9880             nan     0.1000    0.0148\n",
      "     8        0.9610             nan     0.1000    0.0127\n",
      "     9        0.9393             nan     0.1000    0.0107\n",
      "    10        0.9208             nan     0.1000    0.0088\n",
      "    20        0.8215             nan     0.1000    0.0021\n",
      "    40        0.7677             nan     0.1000    0.0003\n",
      "    60        0.7556             nan     0.1000   -0.0002\n",
      "    80        0.7480             nan     0.1000   -0.0001\n",
      "   100        0.7431             nan     0.1000   -0.0002\n",
      "   120        0.7381             nan     0.1000   -0.0001\n",
      "   140        0.7343             nan     0.1000   -0.0001\n",
      "   150        0.7329             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2612             nan     0.1000    0.0459\n",
      "     2        1.1872             nan     0.1000    0.0371\n",
      "     3        1.1255             nan     0.1000    0.0299\n",
      "     4        1.0735             nan     0.1000    0.0246\n",
      "     5        1.0290             nan     0.1000    0.0214\n",
      "     6        0.9929             nan     0.1000    0.0176\n",
      "     7        0.9635             nan     0.1000    0.0145\n",
      "     8        0.9371             nan     0.1000    0.0131\n",
      "     9        0.9147             nan     0.1000    0.0110\n",
      "    10        0.8958             nan     0.1000    0.0092\n",
      "    20        0.7964             nan     0.1000    0.0027\n",
      "    40        0.7521             nan     0.1000    0.0002\n",
      "    60        0.7319             nan     0.1000   -0.0001\n",
      "    80        0.7200             nan     0.1000    0.0003\n",
      "   100        0.7088             nan     0.1000    0.0001\n",
      "   120        0.6988             nan     0.1000   -0.0003\n",
      "   140        0.6899             nan     0.1000   -0.0001\n",
      "   150        0.6856             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2586             nan     0.1000    0.0468\n",
      "     2        1.1818             nan     0.1000    0.0371\n",
      "     3        1.1192             nan     0.1000    0.0308\n",
      "     4        1.0675             nan     0.1000    0.0256\n",
      "     5        1.0219             nan     0.1000    0.0219\n",
      "     6        0.9836             nan     0.1000    0.0176\n",
      "     7        0.9512             nan     0.1000    0.0150\n",
      "     8        0.9241             nan     0.1000    0.0132\n",
      "     9        0.9024             nan     0.1000    0.0107\n",
      "    10        0.8824             nan     0.1000    0.0094\n",
      "    20        0.7838             nan     0.1000    0.0013\n",
      "    40        0.7300             nan     0.1000    0.0003\n",
      "    60        0.7069             nan     0.1000   -0.0002\n",
      "    80        0.6921             nan     0.1000   -0.0001\n",
      "   100        0.6773             nan     0.1000   -0.0004\n",
      "   120        0.6651             nan     0.1000   -0.0001\n",
      "   140        0.6539             nan     0.1000   -0.0003\n",
      "   150        0.6487             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2681             nan     0.1000    0.0430\n",
      "     2        1.1990             nan     0.1000    0.0348\n",
      "     3        1.1432             nan     0.1000    0.0288\n",
      "     4        1.0935             nan     0.1000    0.0246\n",
      "     5        1.0504             nan     0.1000    0.0206\n",
      "     6        1.0154             nan     0.1000    0.0167\n",
      "     7        0.9831             nan     0.1000    0.0151\n",
      "     8        0.9581             nan     0.1000    0.0119\n",
      "     9        0.9355             nan     0.1000    0.0101\n",
      "    10        0.9157             nan     0.1000    0.0099\n",
      "    20        0.8155             nan     0.1000    0.0025\n",
      "    40        0.7636             nan     0.1000    0.0003\n",
      "    60        0.7509             nan     0.1000   -0.0002\n",
      "    80        0.7434             nan     0.1000   -0.0001\n",
      "   100        0.7382             nan     0.1000   -0.0001\n",
      "   120        0.7346             nan     0.1000   -0.0001\n",
      "   140        0.7309             nan     0.1000   -0.0001\n",
      "   150        0.7295             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2598             nan     0.1000    0.0463\n",
      "     2        1.1838             nan     0.1000    0.0374\n",
      "     3        1.1212             nan     0.1000    0.0298\n",
      "     4        1.0702             nan     0.1000    0.0252\n",
      "     5        1.0279             nan     0.1000    0.0210\n",
      "     6        0.9905             nan     0.1000    0.0179\n",
      "     7        0.9588             nan     0.1000    0.0147\n",
      "     8        0.9315             nan     0.1000    0.0124\n",
      "     9        0.9084             nan     0.1000    0.0115\n",
      "    10        0.8886             nan     0.1000    0.0094\n",
      "    20        0.7900             nan     0.1000    0.0022\n",
      "    40        0.7436             nan     0.1000   -0.0001\n",
      "    60        0.7254             nan     0.1000   -0.0004\n",
      "    80        0.7126             nan     0.1000    0.0001\n",
      "   100        0.7022             nan     0.1000   -0.0000\n",
      "   120        0.6947             nan     0.1000   -0.0002\n",
      "   140        0.6867             nan     0.1000   -0.0009\n",
      "   150        0.6831             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2563             nan     0.1000    0.0472\n",
      "     2        1.1786             nan     0.1000    0.0378\n",
      "     3        1.1159             nan     0.1000    0.0312\n",
      "     4        1.0635             nan     0.1000    0.0253\n",
      "     5        1.0174             nan     0.1000    0.0217\n",
      "     6        0.9814             nan     0.1000    0.0177\n",
      "     7        0.9487             nan     0.1000    0.0155\n",
      "     8        0.9221             nan     0.1000    0.0126\n",
      "     9        0.8982             nan     0.1000    0.0111\n",
      "    10        0.8776             nan     0.1000    0.0090\n",
      "    20        0.7769             nan     0.1000    0.0025\n",
      "    40        0.7270             nan     0.1000    0.0002\n",
      "    60        0.7036             nan     0.1000   -0.0001\n",
      "    80        0.6850             nan     0.1000    0.0002\n",
      "   100        0.6695             nan     0.1000    0.0004\n",
      "   120        0.6579             nan     0.1000   -0.0003\n",
      "   140        0.6473             nan     0.1000   -0.0002\n",
      "   150        0.6429             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2717             nan     0.1000    0.0413\n",
      "     2        1.1986             nan     0.1000    0.0351\n",
      "     3        1.1429             nan     0.1000    0.0279\n",
      "     4        1.0925             nan     0.1000    0.0250\n",
      "     5        1.0506             nan     0.1000    0.0202\n",
      "     6        1.0152             nan     0.1000    0.0169\n",
      "     7        0.9856             nan     0.1000    0.0149\n",
      "     8        0.9609             nan     0.1000    0.0121\n",
      "     9        0.9393             nan     0.1000    0.0103\n",
      "    10        0.9202             nan     0.1000    0.0095\n",
      "    20        0.8217             nan     0.1000    0.0026\n",
      "    40        0.7683             nan     0.1000    0.0002\n",
      "    60        0.7553             nan     0.1000    0.0001\n",
      "    80        0.7482             nan     0.1000    0.0000\n",
      "   100        0.7430             nan     0.1000   -0.0001\n",
      "   120        0.7395             nan     0.1000   -0.0001\n",
      "   140        0.7364             nan     0.1000   -0.0001\n",
      "   150        0.7351             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2654             nan     0.1000    0.0450\n",
      "     2        1.1896             nan     0.1000    0.0380\n",
      "     3        1.1278             nan     0.1000    0.0291\n",
      "     4        1.0776             nan     0.1000    0.0248\n",
      "     5        1.0341             nan     0.1000    0.0213\n",
      "     6        0.9976             nan     0.1000    0.0173\n",
      "     7        0.9662             nan     0.1000    0.0148\n",
      "     8        0.9400             nan     0.1000    0.0119\n",
      "     9        0.9160             nan     0.1000    0.0118\n",
      "    10        0.8970             nan     0.1000    0.0086\n",
      "    20        0.7978             nan     0.1000    0.0018\n",
      "    40        0.7511             nan     0.1000    0.0003\n",
      "    60        0.7337             nan     0.1000   -0.0003\n",
      "    80        0.7194             nan     0.1000   -0.0002\n",
      "   100        0.7082             nan     0.1000   -0.0001\n",
      "   120        0.6996             nan     0.1000   -0.0002\n",
      "   140        0.6914             nan     0.1000    0.0002\n",
      "   150        0.6874             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2589             nan     0.1000    0.0466\n",
      "     2        1.1843             nan     0.1000    0.0385\n",
      "     3        1.1210             nan     0.1000    0.0312\n",
      "     4        1.0682             nan     0.1000    0.0254\n",
      "     5        1.0245             nan     0.1000    0.0211\n",
      "     6        0.9865             nan     0.1000    0.0179\n",
      "     7        0.9566             nan     0.1000    0.0155\n",
      "     8        0.9287             nan     0.1000    0.0132\n",
      "     9        0.9066             nan     0.1000    0.0103\n",
      "    10        0.8869             nan     0.1000    0.0093\n",
      "    20        0.7836             nan     0.1000    0.0020\n",
      "    40        0.7291             nan     0.1000   -0.0000\n",
      "    60        0.7063             nan     0.1000   -0.0002\n",
      "    80        0.6900             nan     0.1000   -0.0000\n",
      "   100        0.6750             nan     0.1000   -0.0002\n",
      "   120        0.6635             nan     0.1000   -0.0001\n",
      "   140        0.6540             nan     0.1000   -0.0002\n",
      "   150        0.6478             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2668             nan     0.1000    0.0429\n",
      "     2        1.1960             nan     0.1000    0.0345\n",
      "     3        1.1395             nan     0.1000    0.0282\n",
      "     4        1.0908             nan     0.1000    0.0241\n",
      "     5        1.0473             nan     0.1000    0.0207\n",
      "     6        1.0144             nan     0.1000    0.0171\n",
      "     7        0.9852             nan     0.1000    0.0143\n",
      "     8        0.9591             nan     0.1000    0.0134\n",
      "     9        0.9368             nan     0.1000    0.0112\n",
      "    10        0.9190             nan     0.1000    0.0095\n",
      "    20        0.8169             nan     0.1000    0.0027\n",
      "    40        0.7638             nan     0.1000    0.0004\n",
      "    60        0.7514             nan     0.1000    0.0001\n",
      "    80        0.7437             nan     0.1000   -0.0001\n",
      "   100        0.7382             nan     0.1000   -0.0003\n",
      "   120        0.7333             nan     0.1000   -0.0001\n",
      "   140        0.7293             nan     0.1000   -0.0001\n",
      "   150        0.7271             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2626             nan     0.1000    0.0450\n",
      "     2        1.1859             nan     0.1000    0.0378\n",
      "     3        1.1248             nan     0.1000    0.0295\n",
      "     4        1.0731             nan     0.1000    0.0255\n",
      "     5        1.0283             nan     0.1000    0.0211\n",
      "     6        0.9923             nan     0.1000    0.0181\n",
      "     7        0.9613             nan     0.1000    0.0153\n",
      "     8        0.9361             nan     0.1000    0.0127\n",
      "     9        0.9126             nan     0.1000    0.0112\n",
      "    10        0.8926             nan     0.1000    0.0096\n",
      "    20        0.7906             nan     0.1000    0.0034\n",
      "    40        0.7417             nan     0.1000    0.0000\n",
      "    60        0.7233             nan     0.1000    0.0001\n",
      "    80        0.7103             nan     0.1000   -0.0001\n",
      "   100        0.7009             nan     0.1000   -0.0004\n",
      "   120        0.6917             nan     0.1000    0.0000\n",
      "   140        0.6825             nan     0.1000   -0.0002\n",
      "   150        0.6785             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2577             nan     0.1000    0.0462\n",
      "     2        1.1798             nan     0.1000    0.0369\n",
      "     3        1.1167             nan     0.1000    0.0312\n",
      "     4        1.0633             nan     0.1000    0.0258\n",
      "     5        1.0195             nan     0.1000    0.0217\n",
      "     6        0.9807             nan     0.1000    0.0178\n",
      "     7        0.9481             nan     0.1000    0.0152\n",
      "     8        0.9212             nan     0.1000    0.0123\n",
      "     9        0.8975             nan     0.1000    0.0112\n",
      "    10        0.8772             nan     0.1000    0.0094\n",
      "    20        0.7745             nan     0.1000    0.0023\n",
      "    40        0.7232             nan     0.1000    0.0005\n",
      "    60        0.7020             nan     0.1000   -0.0001\n",
      "    80        0.6853             nan     0.1000   -0.0003\n",
      "   100        0.6694             nan     0.1000   -0.0003\n",
      "   120        0.6550             nan     0.1000   -0.0005\n",
      "   140        0.6441             nan     0.1000   -0.0001\n",
      "   150        0.6396             nan     0.1000   -0.0005\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2652             nan     0.1000    0.0425\n",
      "     2        1.1937             nan     0.1000    0.0344\n",
      "     3        1.1387             nan     0.1000    0.0275\n",
      "     4        1.0889             nan     0.1000    0.0232\n",
      "     5        1.0478             nan     0.1000    0.0205\n",
      "     6        1.0128             nan     0.1000    0.0179\n",
      "     7        0.9825             nan     0.1000    0.0147\n",
      "     8        0.9559             nan     0.1000    0.0114\n",
      "     9        0.9333             nan     0.1000    0.0101\n",
      "    10        0.9138             nan     0.1000    0.0093\n",
      "    20        0.8152             nan     0.1000    0.0025\n",
      "    40        0.7616             nan     0.1000    0.0005\n",
      "    60        0.7472             nan     0.1000    0.0001\n",
      "    80        0.7397             nan     0.1000    0.0000\n",
      "   100        0.7343             nan     0.1000   -0.0001\n",
      "   120        0.7300             nan     0.1000   -0.0004\n",
      "   140        0.7255             nan     0.1000   -0.0001\n",
      "   150        0.7238             nan     0.1000    0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2627             nan     0.1000    0.0443\n",
      "     2        1.1868             nan     0.1000    0.0378\n",
      "     3        1.1233             nan     0.1000    0.0313\n",
      "     4        1.0713             nan     0.1000    0.0248\n",
      "     5        1.0286             nan     0.1000    0.0210\n",
      "     6        0.9943             nan     0.1000    0.0171\n",
      "     7        0.9629             nan     0.1000    0.0161\n",
      "     8        0.9342             nan     0.1000    0.0132\n",
      "     9        0.9120             nan     0.1000    0.0108\n",
      "    10        0.8902             nan     0.1000    0.0091\n",
      "    20        0.7881             nan     0.1000    0.0026\n",
      "    40        0.7412             nan     0.1000    0.0002\n",
      "    60        0.7196             nan     0.1000    0.0001\n",
      "    80        0.7073             nan     0.1000   -0.0002\n",
      "   100        0.6970             nan     0.1000   -0.0004\n",
      "   120        0.6892             nan     0.1000   -0.0002\n",
      "   140        0.6782             nan     0.1000   -0.0003\n",
      "   150        0.6750             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2598             nan     0.1000    0.0467\n",
      "     2        1.1817             nan     0.1000    0.0378\n",
      "     3        1.1198             nan     0.1000    0.0305\n",
      "     4        1.0664             nan     0.1000    0.0260\n",
      "     5        1.0188             nan     0.1000    0.0217\n",
      "     6        0.9820             nan     0.1000    0.0179\n",
      "     7        0.9490             nan     0.1000    0.0154\n",
      "     8        0.9217             nan     0.1000    0.0133\n",
      "     9        0.8990             nan     0.1000    0.0111\n",
      "    10        0.8788             nan     0.1000    0.0095\n",
      "    20        0.7778             nan     0.1000    0.0020\n",
      "    40        0.7241             nan     0.1000    0.0007\n",
      "    60        0.7008             nan     0.1000   -0.0003\n",
      "    80        0.6837             nan     0.1000   -0.0002\n",
      "   100        0.6667             nan     0.1000    0.0001\n",
      "   120        0.6534             nan     0.1000   -0.0002\n",
      "   140        0.6402             nan     0.1000   -0.0002\n",
      "   150        0.6332             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2697             nan     0.1000    0.0433\n",
      "     2        1.1983             nan     0.1000    0.0355\n",
      "     3        1.1370             nan     0.1000    0.0280\n",
      "     4        1.0892             nan     0.1000    0.0239\n",
      "     5        1.0445             nan     0.1000    0.0209\n",
      "     6        1.0098             nan     0.1000    0.0165\n",
      "     7        0.9806             nan     0.1000    0.0137\n",
      "     8        0.9530             nan     0.1000    0.0132\n",
      "     9        0.9311             nan     0.1000    0.0108\n",
      "    10        0.9116             nan     0.1000    0.0089\n",
      "    20        0.8135             nan     0.1000    0.0025\n",
      "    40        0.7617             nan     0.1000    0.0007\n",
      "    60        0.7485             nan     0.1000    0.0002\n",
      "    80        0.7416             nan     0.1000   -0.0000\n",
      "   100        0.7353             nan     0.1000    0.0000\n",
      "   120        0.7312             nan     0.1000   -0.0002\n",
      "   140        0.7281             nan     0.1000   -0.0001\n",
      "   150        0.7266             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2606             nan     0.1000    0.0456\n",
      "     2        1.1873             nan     0.1000    0.0355\n",
      "     3        1.1225             nan     0.1000    0.0318\n",
      "     4        1.0709             nan     0.1000    0.0254\n",
      "     5        1.0285             nan     0.1000    0.0204\n",
      "     6        0.9912             nan     0.1000    0.0180\n",
      "     7        0.9609             nan     0.1000    0.0153\n",
      "     8        0.9344             nan     0.1000    0.0127\n",
      "     9        0.9099             nan     0.1000    0.0120\n",
      "    10        0.8891             nan     0.1000    0.0101\n",
      "    20        0.7882             nan     0.1000    0.0027\n",
      "    40        0.7416             nan     0.1000   -0.0003\n",
      "    60        0.7223             nan     0.1000    0.0001\n",
      "    80        0.7088             nan     0.1000   -0.0001\n",
      "   100        0.6977             nan     0.1000   -0.0002\n",
      "   120        0.6880             nan     0.1000   -0.0003\n",
      "   140        0.6809             nan     0.1000    0.0000\n",
      "   150        0.6767             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2579             nan     0.1000    0.0480\n",
      "     2        1.1807             nan     0.1000    0.0382\n",
      "     3        1.1177             nan     0.1000    0.0309\n",
      "     4        1.0646             nan     0.1000    0.0257\n",
      "     5        1.0200             nan     0.1000    0.0218\n",
      "     6        0.9825             nan     0.1000    0.0179\n",
      "     7        0.9509             nan     0.1000    0.0158\n",
      "     8        0.9239             nan     0.1000    0.0137\n",
      "     9        0.9006             nan     0.1000    0.0111\n",
      "    10        0.8797             nan     0.1000    0.0093\n",
      "    20        0.7770             nan     0.1000    0.0023\n",
      "    40        0.7233             nan     0.1000    0.0006\n",
      "    60        0.6987             nan     0.1000   -0.0000\n",
      "    80        0.6799             nan     0.1000   -0.0002\n",
      "   100        0.6657             nan     0.1000   -0.0003\n",
      "   120        0.6541             nan     0.1000    0.0001\n",
      "   140        0.6432             nan     0.1000   -0.0005\n",
      "   150        0.6382             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2683             nan     0.1000    0.0422\n",
      "     2        1.1968             nan     0.1000    0.0348\n",
      "     3        1.1403             nan     0.1000    0.0294\n",
      "     4        1.0923             nan     0.1000    0.0234\n",
      "     5        1.0495             nan     0.1000    0.0205\n",
      "     6        1.0139             nan     0.1000    0.0168\n",
      "     7        0.9835             nan     0.1000    0.0143\n",
      "     8        0.9579             nan     0.1000    0.0124\n",
      "     9        0.9370             nan     0.1000    0.0100\n",
      "    10        0.9183             nan     0.1000    0.0089\n",
      "    20        0.8184             nan     0.1000    0.0027\n",
      "    40        0.7657             nan     0.1000    0.0000\n",
      "    60        0.7536             nan     0.1000    0.0001\n",
      "    80        0.7463             nan     0.1000   -0.0003\n",
      "   100        0.7411             nan     0.1000   -0.0000\n",
      "   120        0.7361             nan     0.1000   -0.0000\n",
      "   140        0.7329             nan     0.1000   -0.0002\n",
      "   150        0.7315             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2652             nan     0.1000    0.0445\n",
      "     2        1.1883             nan     0.1000    0.0377\n",
      "     3        1.1286             nan     0.1000    0.0302\n",
      "     4        1.0751             nan     0.1000    0.0263\n",
      "     5        1.0329             nan     0.1000    0.0213\n",
      "     6        0.9980             nan     0.1000    0.0185\n",
      "     7        0.9665             nan     0.1000    0.0151\n",
      "     8        0.9383             nan     0.1000    0.0131\n",
      "     9        0.9153             nan     0.1000    0.0116\n",
      "    10        0.8965             nan     0.1000    0.0093\n",
      "    20        0.7926             nan     0.1000    0.0029\n",
      "    40        0.7453             nan     0.1000   -0.0005\n",
      "    60        0.7292             nan     0.1000   -0.0000\n",
      "    80        0.7148             nan     0.1000   -0.0003\n",
      "   100        0.7051             nan     0.1000   -0.0003\n",
      "   120        0.6960             nan     0.1000   -0.0000\n",
      "   140        0.6887             nan     0.1000    0.0000\n",
      "   150        0.6858             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2599             nan     0.1000    0.0475\n",
      "     2        1.1848             nan     0.1000    0.0386\n",
      "     3        1.1192             nan     0.1000    0.0314\n",
      "     4        1.0665             nan     0.1000    0.0251\n",
      "     5        1.0219             nan     0.1000    0.0216\n",
      "     6        0.9835             nan     0.1000    0.0187\n",
      "     7        0.9498             nan     0.1000    0.0159\n",
      "     8        0.9222             nan     0.1000    0.0131\n",
      "     9        0.8988             nan     0.1000    0.0110\n",
      "    10        0.8783             nan     0.1000    0.0095\n",
      "    20        0.7747             nan     0.1000    0.0017\n",
      "    40        0.7226             nan     0.1000   -0.0002\n",
      "    60        0.7010             nan     0.1000    0.0000\n",
      "    80        0.6834             nan     0.1000   -0.0004\n",
      "   100        0.6672             nan     0.1000   -0.0002\n",
      "   120        0.6561             nan     0.1000   -0.0001\n",
      "   140        0.6443             nan     0.1000   -0.0001\n",
      "   150        0.6394             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2643             nan     0.1000    0.0445\n",
      "     2        1.1916             nan     0.1000    0.0358\n",
      "     3        1.1337             nan     0.1000    0.0294\n",
      "     4        1.0836             nan     0.1000    0.0240\n",
      "     5        1.0397             nan     0.1000    0.0212\n",
      "     6        1.0053             nan     0.1000    0.0175\n",
      "     7        0.9758             nan     0.1000    0.0145\n",
      "     8        0.9485             nan     0.1000    0.0136\n",
      "     9        0.9239             nan     0.1000    0.0118\n",
      "    10        0.9043             nan     0.1000    0.0098\n",
      "    20        0.8018             nan     0.1000    0.0027\n",
      "    40        0.7515             nan     0.1000    0.0007\n",
      "    60        0.7391             nan     0.1000   -0.0000\n",
      "    80        0.7326             nan     0.1000   -0.0003\n",
      "   100        0.7276             nan     0.1000   -0.0003\n",
      "   120        0.7232             nan     0.1000   -0.0002\n",
      "   140        0.7200             nan     0.1000   -0.0002\n",
      "   150        0.7183             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2626             nan     0.1000    0.0461\n",
      "     2        1.1849             nan     0.1000    0.0385\n",
      "     3        1.1206             nan     0.1000    0.0317\n",
      "     4        1.0674             nan     0.1000    0.0258\n",
      "     5        1.0208             nan     0.1000    0.0219\n",
      "     6        0.9823             nan     0.1000    0.0182\n",
      "     7        0.9510             nan     0.1000    0.0156\n",
      "     8        0.9242             nan     0.1000    0.0133\n",
      "     9        0.9014             nan     0.1000    0.0112\n",
      "    10        0.8818             nan     0.1000    0.0088\n",
      "    20        0.7816             nan     0.1000    0.0022\n",
      "    40        0.7345             nan     0.1000   -0.0001\n",
      "    60        0.7164             nan     0.1000   -0.0001\n",
      "    80        0.7023             nan     0.1000   -0.0001\n",
      "   100        0.6919             nan     0.1000   -0.0003\n",
      "   120        0.6826             nan     0.1000   -0.0003\n",
      "   140        0.6746             nan     0.1000   -0.0001\n",
      "   150        0.6710             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2587             nan     0.1000    0.0477\n",
      "     2        1.1800             nan     0.1000    0.0392\n",
      "     3        1.1149             nan     0.1000    0.0321\n",
      "     4        1.0611             nan     0.1000    0.0260\n",
      "     5        1.0172             nan     0.1000    0.0221\n",
      "     6        0.9791             nan     0.1000    0.0189\n",
      "     7        0.9461             nan     0.1000    0.0161\n",
      "     8        0.9180             nan     0.1000    0.0134\n",
      "     9        0.8928             nan     0.1000    0.0122\n",
      "    10        0.8710             nan     0.1000    0.0104\n",
      "    20        0.7669             nan     0.1000    0.0017\n",
      "    40        0.7172             nan     0.1000   -0.0001\n",
      "    60        0.6940             nan     0.1000   -0.0003\n",
      "    80        0.6765             nan     0.1000   -0.0002\n",
      "   100        0.6632             nan     0.1000    0.0002\n",
      "   120        0.6528             nan     0.1000   -0.0006\n",
      "   140        0.6424             nan     0.1000   -0.0005\n",
      "   150        0.6369             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2673             nan     0.1000    0.0419\n",
      "     2        1.1982             nan     0.1000    0.0344\n",
      "     3        1.1432             nan     0.1000    0.0284\n",
      "     4        1.0963             nan     0.1000    0.0230\n",
      "     5        1.0535             nan     0.1000    0.0207\n",
      "     6        1.0154             nan     0.1000    0.0181\n",
      "     7        0.9850             nan     0.1000    0.0146\n",
      "     8        0.9590             nan     0.1000    0.0119\n",
      "     9        0.9357             nan     0.1000    0.0114\n",
      "    10        0.9151             nan     0.1000    0.0093\n",
      "    20        0.8171             nan     0.1000    0.0024\n",
      "    40        0.7665             nan     0.1000   -0.0001\n",
      "    60        0.7537             nan     0.1000   -0.0001\n",
      "    80        0.7465             nan     0.1000   -0.0001\n",
      "   100        0.7405             nan     0.1000   -0.0002\n",
      "   120        0.7358             nan     0.1000   -0.0002\n",
      "   140        0.7314             nan     0.1000   -0.0001\n",
      "   150        0.7298             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2635             nan     0.1000    0.0451\n",
      "     2        1.1869             nan     0.1000    0.0372\n",
      "     3        1.1244             nan     0.1000    0.0299\n",
      "     4        1.0737             nan     0.1000    0.0243\n",
      "     5        1.0317             nan     0.1000    0.0213\n",
      "     6        0.9944             nan     0.1000    0.0181\n",
      "     7        0.9639             nan     0.1000    0.0148\n",
      "     8        0.9371             nan     0.1000    0.0128\n",
      "     9        0.9150             nan     0.1000    0.0113\n",
      "    10        0.8969             nan     0.1000    0.0090\n",
      "    20        0.7945             nan     0.1000    0.0019\n",
      "    40        0.7443             nan     0.1000    0.0001\n",
      "    60        0.7280             nan     0.1000   -0.0001\n",
      "    80        0.7166             nan     0.1000   -0.0003\n",
      "   100        0.7065             nan     0.1000   -0.0001\n",
      "   120        0.6983             nan     0.1000   -0.0004\n",
      "   140        0.6898             nan     0.1000   -0.0003\n",
      "   150        0.6855             nan     0.1000    0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2607             nan     0.1000    0.0463\n",
      "     2        1.1818             nan     0.1000    0.0387\n",
      "     3        1.1162             nan     0.1000    0.0306\n",
      "     4        1.0646             nan     0.1000    0.0265\n",
      "     5        1.0219             nan     0.1000    0.0214\n",
      "     6        0.9840             nan     0.1000    0.0182\n",
      "     7        0.9527             nan     0.1000    0.0155\n",
      "     8        0.9270             nan     0.1000    0.0131\n",
      "     9        0.9032             nan     0.1000    0.0114\n",
      "    10        0.8828             nan     0.1000    0.0104\n",
      "    20        0.7777             nan     0.1000    0.0025\n",
      "    40        0.7252             nan     0.1000   -0.0001\n",
      "    60        0.7016             nan     0.1000    0.0000\n",
      "    80        0.6828             nan     0.1000    0.0000\n",
      "   100        0.6706             nan     0.1000   -0.0003\n",
      "   120        0.6598             nan     0.1000   -0.0001\n",
      "   140        0.6475             nan     0.1000    0.0004\n",
      "   150        0.6409             nan     0.1000   -0.0004\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2680             nan     0.1000    0.0443\n",
      "     2        1.1980             nan     0.1000    0.0354\n",
      "     3        1.1377             nan     0.1000    0.0278\n",
      "     4        1.0876             nan     0.1000    0.0242\n",
      "     5        1.0476             nan     0.1000    0.0206\n",
      "     6        1.0119             nan     0.1000    0.0176\n",
      "     7        0.9810             nan     0.1000    0.0152\n",
      "     8        0.9564             nan     0.1000    0.0126\n",
      "     9        0.9350             nan     0.1000    0.0107\n",
      "    10        0.9157             nan     0.1000    0.0091\n",
      "    20        0.8133             nan     0.1000    0.0030\n",
      "    40        0.7585             nan     0.1000    0.0002\n",
      "    60        0.7441             nan     0.1000    0.0001\n",
      "    80        0.7386             nan     0.1000   -0.0000\n",
      "   100        0.7322             nan     0.1000   -0.0001\n",
      "   120        0.7281             nan     0.1000    0.0000\n",
      "   140        0.7251             nan     0.1000   -0.0002\n",
      "   150        0.7231             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2597             nan     0.1000    0.0474\n",
      "     2        1.1842             nan     0.1000    0.0372\n",
      "     3        1.1242             nan     0.1000    0.0300\n",
      "     4        1.0742             nan     0.1000    0.0251\n",
      "     5        1.0302             nan     0.1000    0.0224\n",
      "     6        0.9930             nan     0.1000    0.0177\n",
      "     7        0.9602             nan     0.1000    0.0154\n",
      "     8        0.9320             nan     0.1000    0.0135\n",
      "     9        0.9088             nan     0.1000    0.0116\n",
      "    10        0.8887             nan     0.1000    0.0096\n",
      "    20        0.7853             nan     0.1000    0.0024\n",
      "    40        0.7359             nan     0.1000    0.0003\n",
      "    60        0.7205             nan     0.1000   -0.0004\n",
      "    80        0.7100             nan     0.1000   -0.0002\n",
      "   100        0.6988             nan     0.1000    0.0001\n",
      "   120        0.6915             nan     0.1000   -0.0002\n",
      "   140        0.6804             nan     0.1000    0.0001\n",
      "   150        0.6778             nan     0.1000   -0.0003\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2570             nan     0.1000    0.0471\n",
      "     2        1.1815             nan     0.1000    0.0365\n",
      "     3        1.1187             nan     0.1000    0.0325\n",
      "     4        1.0649             nan     0.1000    0.0260\n",
      "     5        1.0211             nan     0.1000    0.0217\n",
      "     6        0.9822             nan     0.1000    0.0182\n",
      "     7        0.9505             nan     0.1000    0.0165\n",
      "     8        0.9218             nan     0.1000    0.0137\n",
      "     9        0.8970             nan     0.1000    0.0115\n",
      "    10        0.8767             nan     0.1000    0.0097\n",
      "    20        0.7697             nan     0.1000    0.0030\n",
      "    40        0.7175             nan     0.1000    0.0003\n",
      "    60        0.6923             nan     0.1000   -0.0000\n",
      "    80        0.6768             nan     0.1000    0.0000\n",
      "   100        0.6648             nan     0.1000   -0.0004\n",
      "   120        0.6524             nan     0.1000   -0.0007\n",
      "   140        0.6408             nan     0.1000   -0.0001\n",
      "   150        0.6345             nan     0.1000   -0.0000\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2685             nan     0.1000    0.0417\n",
      "     2        1.2002             nan     0.1000    0.0323\n",
      "     3        1.1423             nan     0.1000    0.0285\n",
      "     4        1.0933             nan     0.1000    0.0235\n",
      "     5        1.0517             nan     0.1000    0.0199\n",
      "     6        1.0162             nan     0.1000    0.0169\n",
      "     7        0.9878             nan     0.1000    0.0142\n",
      "     8        0.9627             nan     0.1000    0.0119\n",
      "     9        0.9401             nan     0.1000    0.0107\n",
      "    10        0.9221             nan     0.1000    0.0088\n",
      "    20        0.8248             nan     0.1000    0.0026\n",
      "    40        0.7725             nan     0.1000    0.0003\n",
      "    60        0.7598             nan     0.1000   -0.0000\n",
      "    80        0.7525             nan     0.1000    0.0000\n",
      "   100        0.7469             nan     0.1000   -0.0000\n",
      "   120        0.7431             nan     0.1000   -0.0000\n",
      "   140        0.7394             nan     0.1000   -0.0001\n",
      "   150        0.7375             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2602             nan     0.1000    0.0438\n",
      "     2        1.1853             nan     0.1000    0.0353\n",
      "     3        1.1245             nan     0.1000    0.0304\n",
      "     4        1.0754             nan     0.1000    0.0242\n",
      "     5        1.0340             nan     0.1000    0.0210\n",
      "     6        0.9988             nan     0.1000    0.0173\n",
      "     7        0.9678             nan     0.1000    0.0156\n",
      "     8        0.9408             nan     0.1000    0.0131\n",
      "     9        0.9194             nan     0.1000    0.0109\n",
      "    10        0.8994             nan     0.1000    0.0102\n",
      "    20        0.8006             nan     0.1000    0.0019\n",
      "    40        0.7542             nan     0.1000    0.0002\n",
      "    60        0.7370             nan     0.1000   -0.0003\n",
      "    80        0.7240             nan     0.1000   -0.0001\n",
      "   100        0.7126             nan     0.1000    0.0000\n",
      "   120        0.7034             nan     0.1000    0.0000\n",
      "   140        0.6939             nan     0.1000   -0.0003\n",
      "   150        0.6902             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2591             nan     0.1000    0.0460\n",
      "     2        1.1829             nan     0.1000    0.0376\n",
      "     3        1.1210             nan     0.1000    0.0313\n",
      "     4        1.0689             nan     0.1000    0.0250\n",
      "     5        1.0251             nan     0.1000    0.0208\n",
      "     6        0.9878             nan     0.1000    0.0176\n",
      "     7        0.9566             nan     0.1000    0.0144\n",
      "     8        0.9315             nan     0.1000    0.0123\n",
      "     9        0.9088             nan     0.1000    0.0107\n",
      "    10        0.8889             nan     0.1000    0.0095\n",
      "    20        0.7871             nan     0.1000    0.0019\n",
      "    40        0.7380             nan     0.1000    0.0000\n",
      "    60        0.7108             nan     0.1000   -0.0004\n",
      "    80        0.6923             nan     0.1000   -0.0004\n",
      "   100        0.6764             nan     0.1000   -0.0004\n",
      "   120        0.6630             nan     0.1000   -0.0006\n",
      "   140        0.6515             nan     0.1000   -0.0004\n",
      "   150        0.6458             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2665             nan     0.1000    0.0427\n",
      "     2        1.1946             nan     0.1000    0.0350\n",
      "     3        1.1359             nan     0.1000    0.0290\n",
      "     4        1.0854             nan     0.1000    0.0239\n",
      "     5        1.0434             nan     0.1000    0.0208\n",
      "     6        1.0076             nan     0.1000    0.0168\n",
      "     7        0.9787             nan     0.1000    0.0140\n",
      "     8        0.9517             nan     0.1000    0.0130\n",
      "     9        0.9295             nan     0.1000    0.0110\n",
      "    10        0.9107             nan     0.1000    0.0095\n",
      "    20        0.8096             nan     0.1000    0.0024\n",
      "    40        0.7581             nan     0.1000    0.0002\n",
      "    60        0.7455             nan     0.1000    0.0001\n",
      "    80        0.7371             nan     0.1000   -0.0001\n",
      "   100        0.7322             nan     0.1000   -0.0001\n",
      "   120        0.7280             nan     0.1000   -0.0000\n",
      "   140        0.7242             nan     0.1000   -0.0001\n",
      "   150        0.7226             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2598             nan     0.1000    0.0467\n",
      "     2        1.1844             nan     0.1000    0.0377\n",
      "     3        1.1234             nan     0.1000    0.0310\n",
      "     4        1.0711             nan     0.1000    0.0252\n",
      "     5        1.0239             nan     0.1000    0.0215\n",
      "     6        0.9862             nan     0.1000    0.0181\n",
      "     7        0.9559             nan     0.1000    0.0153\n",
      "     8        0.9289             nan     0.1000    0.0128\n",
      "     9        0.9068             nan     0.1000    0.0109\n",
      "    10        0.8880             nan     0.1000    0.0094\n",
      "    20        0.7877             nan     0.1000    0.0022\n",
      "    40        0.7405             nan     0.1000    0.0000\n",
      "    60        0.7220             nan     0.1000   -0.0002\n",
      "    80        0.7088             nan     0.1000    0.0000\n",
      "   100        0.6982             nan     0.1000   -0.0001\n",
      "   120        0.6892             nan     0.1000   -0.0001\n",
      "   140        0.6816             nan     0.1000   -0.0002\n",
      "   150        0.6776             nan     0.1000   -0.0001\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2569             nan     0.1000    0.0470\n",
      "     2        1.1802             nan     0.1000    0.0382\n",
      "     3        1.1162             nan     0.1000    0.0310\n",
      "     4        1.0630             nan     0.1000    0.0261\n",
      "     5        1.0193             nan     0.1000    0.0221\n",
      "     6        0.9816             nan     0.1000    0.0185\n",
      "     7        0.9497             nan     0.1000    0.0154\n",
      "     8        0.9216             nan     0.1000    0.0133\n",
      "     9        0.8974             nan     0.1000    0.0111\n",
      "    10        0.8772             nan     0.1000    0.0093\n",
      "    20        0.7761             nan     0.1000    0.0018\n",
      "    40        0.7204             nan     0.1000    0.0005\n",
      "    60        0.7004             nan     0.1000   -0.0006\n",
      "    80        0.6830             nan     0.1000   -0.0005\n",
      "   100        0.6660             nan     0.1000   -0.0002\n",
      "   120        0.6534             nan     0.1000   -0.0006\n",
      "   140        0.6403             nan     0.1000   -0.0002\n",
      "   150        0.6359             nan     0.1000   -0.0002\n",
      "\n",
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.2568             nan     0.1000    0.0471\n",
      "     2        1.1783             nan     0.1000    0.0377\n",
      "     3        1.1155             nan     0.1000    0.0304\n",
      "     4        1.0632             nan     0.1000    0.0256\n",
      "     5        1.0193             nan     0.1000    0.0218\n",
      "     6        0.9832             nan     0.1000    0.0182\n",
      "     7        0.9522             nan     0.1000    0.0153\n",
      "     8        0.9239             nan     0.1000    0.0136\n",
      "     9        0.9013             nan     0.1000    0.0114\n",
      "    10        0.8816             nan     0.1000    0.0098\n",
      "    20        0.7767             nan     0.1000    0.0017\n",
      "    40        0.7258             nan     0.1000   -0.0001\n",
      "    60        0.7080             nan     0.1000   -0.0001\n",
      "    80        0.6890             nan     0.1000   -0.0003\n",
      "   100        0.6752             nan     0.1000   -0.0005\n",
      "   120        0.6612             nan     0.1000   -0.0003\n",
      "   140        0.6495             nan     0.1000   -0.0002\n",
      "   150        0.6419             nan     0.1000   -0.0003\n",
      "\n",
      "A gbm ensemble of 2 base models: gbm, rpart, glm, knn, svmRadial\n",
      "\n",
      "Ensemble results:\n",
      "Stochastic Gradient Boosting \n",
      "\n",
      "3927 samples\n",
      "   5 predictor\n",
      "   2 classes: 'X0', 'X1' \n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 3 times) \n",
      "Summary of sample sizes: 3534, 3534, 3535, 3534, 3535, 3535, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  interaction.depth  n.trees  Accuracy   Kappa    \n",
      "  1                   50      0.8437288  0.6722852\n",
      "  1                  100      0.8431355  0.6702889\n",
      "  1                  150      0.8433909  0.6705606\n",
      "  2                   50      0.8435607  0.6711502\n",
      "  2                  100      0.8421195  0.6682282\n",
      "  2                  150      0.8444104  0.6733636\n",
      "  3                   50      0.8430537  0.6705324\n",
      "  3                  100      0.8450080  0.6750843\n",
      "  3                  150      0.8480640  0.6819467\n",
      "\n",
      "Tuning parameter 'shrinkage' was held constant at a value of 0.1\n",
      "\n",
      "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
      "Accuracy was used to select the optimal model using  the largest value.\n",
      "The final values used for the model were n.trees = 150, interaction.depth =\n",
      " 3, shrinkage = 0.1 and n.minobsinnode = 10. \n"
     ]
    }
   ],
   "source": [
    "# stack using gbm\n",
    "stackControl <- trainControl(method=\"repeatedcv\", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)\n",
    "set.seed(seed)\n",
    "stack.gbm <- caretStack(models, method=\"gbm\", metric=\"Accuracy\", trControl=stackControl)\n",
    "print(stack.gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A rf ensemble of 2 base models: gbm, rpart, glm, knn, svmRadial\n",
      "\n",
      "Ensemble results:\n",
      "Random Forest \n",
      "\n",
      "3927 samples\n",
      "   5 predictor\n",
      "   2 classes: 'X0', 'X1' \n",
      "\n",
      "No pre-processing\n",
      "Resampling: Cross-Validated (10 fold, repeated 3 times) \n",
      "Summary of sample sizes: 3534, 3534, 3535, 3534, 3535, 3535, ... \n",
      "Resampling results across tuning parameters:\n",
      "\n",
      "  mtry  Accuracy   Kappa    \n",
      "  2     0.8544234  0.6961648\n",
      "  3     0.8521312  0.6916363\n",
      "  5     0.8524728  0.6923262\n",
      "\n",
      "Accuracy was used to select the optimal model using  the largest value.\n",
      "The final value used for the model was mtry = 2. \n"
     ]
    }
   ],
   "source": [
    "# stack using random forest\n",
    "set.seed(seed)\n",
    "stack.rf <- caretStack(models, method=\"rf\", metric=\"Accuracy\", trControl=stackControl)\n",
    "print(stack.rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack submodels using glm: 84,81% (n.trees=150, int.depth=3)\n",
    "Stack submodels using random forest: 85,45%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t418 obs. of  11 variables:\n",
      " $ Survived: Factor w/ 2 levels \"X0\",\"X1\": 1 2 1 1 1 1 2 2 2 1 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:2, 1] 0 1\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"X0\" \"X1\"\n",
      "  .. .. ..$ : chr \"2\"\n",
      " $ Pclass  : Factor w/ 3 levels \"X1\",\"X2\",\"X3\": 3 3 2 3 3 3 3 2 3 3 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:3, 1:2] 0 1 0 0 0 1\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"X1\" \"X2\" \"X3\"\n",
      "  .. .. ..$ : chr  \"2\" \"3\"\n",
      " $ Sex     : Factor w/ 2 levels \"female\",\"male\": 2 1 2 2 1 2 1 2 1 2 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:2, 1] 0 1\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"female\" \"male\"\n",
      "  .. .. ..$ : chr \"2\"\n",
      " $ SibSp   : Factor w/ 7 levels \"X0\",\"X1\",\"X2\",..: 1 2 1 1 2 1 1 2 1 3 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:7, 1:6] 0 1 0 0 0 0 0 0 0 1 ...\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"X0\" \"X1\" \"X2\" \"X3\" ...\n",
      "  .. .. ..$ : chr  \"2\" \"3\" \"4\" \"5\" ...\n",
      " $ Parch   : Factor w/ 8 levels \"X0\",\"X1\",\"X2\",..: 1 1 1 1 2 1 1 2 1 1 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:8, 1:7] 0 1 0 0 0 0 0 0 0 0 ...\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"X0\" \"X1\" \"X2\" \"X3\" ...\n",
      "  .. .. ..$ : chr  \"2\" \"3\" \"4\" \"5\" ...\n",
      " $ Fare    : num  7.83 7 9.69 8.66 12.29 ...\n",
      " $ Embarked: Factor w/ 3 levels \"C\",\"Q\",\"S\": 2 3 2 3 3 3 2 3 1 3 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:3, 1:2] 0 1 0 0 0 1\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"C\" \"Q\" \"S\"\n",
      "  .. .. ..$ : chr  \"2\" \"3\"\n",
      " $ Title   : Factor w/ 18 levels \"Capt\",\"Col\",\"Countess\",..: 14 15 14 14 15 14 11 14 15 14 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:18, 1:17] 0 1 0 0 0 0 0 0 0 0 ...\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"Capt\" \"Col\" \"Countess\" \"Don\" ...\n",
      "  .. .. ..$ : chr  \"2\" \"3\" \"4\" \"5\" ...\n",
      " $ AgeD    : Factor w/ 4 levels \"Bebé\",\"Niño\",..: 3 3 4 3 3 2 3 3 3 3 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:4, 1:3] 0 1 0 0 0 0 1 0 0 0 ...\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"Bebé\" \"Niño\" \"Adulto\" \"Anciano\"\n",
      "  .. .. ..$ : chr  \"2\" \"3\" \"4\"\n",
      " $ FamSize : Factor w/ 9 levels \"X1\",\"X11\",\"X2\",..: 1 3 1 1 4 1 1 4 1 4 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:9, 1:8] 0 1 0 0 0 0 0 0 0 0 ...\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"X1\" \"X11\" \"X2\" \"X3\" ...\n",
      "  .. .. ..$ : chr  \"2\" \"3\" \"4\" \"5\" ...\n",
      " $ Deck    : Factor w/ 8 levels \"A\",\"B\",\"C\",\"D\",..: 6 6 5 6 5 5 6 6 6 7 ...\n",
      "  ..- attr(*, \"contrasts\")= num [1:8, 1:7] 0 1 0 0 0 0 0 0 0 0 ...\n",
      "  .. ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. .. ..$ : chr  \"A\" \"B\" \"C\" \"D\" ...\n",
      "  .. .. ..$ : chr  \"2\" \"3\" \"4\" \"5\" ...\n"
     ]
    }
   ],
   "source": [
    "#Test set\n",
    "n <- nrow(read.csv(\"train.csv\", na.strings = c(\"\", \"NA\")))\n",
    "df_test <- read.csv(\"test.csv\", na.strings = c(\"\", \"NA\"))\n",
    "\n",
    "id_passengers <- df_test[,1] \n",
    "\n",
    "df_test <- dataset[id_passengers,]\n",
    "str(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test$Survived <- NULL\n",
    "\n",
    "fit2.gbm <- train(Survived ~ Pclass + Sex + Title + Fare, data=dataset, method=\"gbm\", trControl=control, verbose=FALSE)\n",
    "\n",
    "predictions <- predict(fit2.gbm, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions <- as.character(predictions)\n",
    "predictions <- substring(predictions, 2)\n",
    "\n",
    "ids <- read.csv(\"test.csv\")\n",
    "ids <- ids[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit <- data.frame(PassengerId = ids, Survived = predictions)\n",
    "write.csv(submit, file = \"tercersubmit.csv\", row.names = FALSE, quote = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Attribute importance\n",
    "res <- gain.ratio(Survived ~ ., data = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>attr_importance</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Pclass</th><td>0.033727941</td></tr>\n",
       "\t<tr><th scope=row>Sex</th><td>0.220687629</td></tr>\n",
       "\t<tr><th scope=row>SibSp</th><td>0.020291450</td></tr>\n",
       "\t<tr><th scope=row>Parch</th><td>0.021087213</td></tr>\n",
       "\t<tr><th scope=row>Fare</th><td>0.036491953</td></tr>\n",
       "\t<tr><th scope=row>Embarked</th><td>0.013236849</td></tr>\n",
       "\t<tr><th scope=row>Title</th><td>0.140877042</td></tr>\n",
       "\t<tr><th scope=row>AgeD</th><td>0.003585263</td></tr>\n",
       "\t<tr><th scope=row>FamSize</th><td>0.031074759</td></tr>\n",
       "\t<tr><th scope=row>Deck</th><td>0.014196818</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & attr\\_importance\\\\\n",
       "\\hline\n",
       "\tPclass & 0.033727941\\\\\n",
       "\tSex & 0.220687629\\\\\n",
       "\tSibSp & 0.020291450\\\\\n",
       "\tParch & 0.021087213\\\\\n",
       "\tFare & 0.036491953\\\\\n",
       "\tEmbarked & 0.013236849\\\\\n",
       "\tTitle & 0.140877042\\\\\n",
       "\tAgeD & 0.003585263\\\\\n",
       "\tFamSize & 0.031074759\\\\\n",
       "\tDeck & 0.014196818\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | attr_importance | \n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| Pclass | 0.033727941 | \n",
       "| Sex | 0.220687629 | \n",
       "| SibSp | 0.020291450 | \n",
       "| Parch | 0.021087213 | \n",
       "| Fare | 0.036491953 | \n",
       "| Embarked | 0.013236849 | \n",
       "| Title | 0.140877042 | \n",
       "| AgeD | 0.003585263 | \n",
       "| FamSize | 0.031074759 | \n",
       "| Deck | 0.014196818 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "         attr_importance\n",
       "Pclass   0.033727941    \n",
       "Sex      0.220687629    \n",
       "SibSp    0.020291450    \n",
       "Parch    0.021087213    \n",
       "Fare     0.036491953    \n",
       "Embarked 0.013236849    \n",
       "Title    0.140877042    \n",
       "AgeD     0.003585263    \n",
       "FamSize  0.031074759    \n",
       "Deck     0.014196818    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xgboost\n",
    "sparse_matrix <- sparse.model.matrix(Survived ~ .-Survived, data = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formal class 'dgCMatrix' [package \"Matrix\"] with 6 slots\n",
      "  ..@ i       : int [1:10332] 0 1 2 3 4 5 6 7 8 9 ...\n",
      "  ..@ p       : int [1:56] 0 1309 1586 2295 3138 3457 3499 3519 3541 3547 ...\n",
      "  ..@ Dim     : int [1:2] 1309 55\n",
      "  ..@ Dimnames:List of 2\n",
      "  .. ..$ : chr [1:1309] \"1\" \"2\" \"3\" \"4\" ...\n",
      "  .. ..$ : chr [1:55] \"(Intercept)\" \"Pclass2\" \"Pclass3\" \"Sex2\" ...\n",
      "  ..@ x       : num [1:10332] 1 1 1 1 1 1 1 1 1 1 ...\n",
      "  ..@ factors : list()\n"
     ]
    }
   ],
   "source": [
    "output_vector = dataset[, response] == \"Responder\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
